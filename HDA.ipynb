{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tlc/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "from speech_commands import input_data\n",
    "from speech_commands import models\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "FLAGS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz' #Location of speech training data archive on the web.\n",
    "data_dir = 'dataset/' #Where to download the speech training data to.\n",
    "background_volume = 0.1 #How loud the background noise should be, between 0 and 1.\n",
    "background_frequency = 0.8 #How many of the training samples have background noise mixed in.\n",
    "silence_percentage = 10.0 #How much of the training data should be silence.\n",
    "unknown_percentage = 10.0 #How much of the training data should be unknown words.\n",
    "time_shift_ms = 100.0 #Range to randomly shift the training audio by in time.\n",
    "testing_percentage = 10 #What percentage of wavs to use as a test set.\n",
    "validation_percentage = 10 #What percentage of wavs to use as a validation set.\n",
    "sample_rate = 16000 #Expected sample rate of the wavs\n",
    "clip_duration_ms = 1000 #Expected duration in milliseconds of the wavs\n",
    "window_size_ms = 30.0 #How long each spectrogram timeslice is.\n",
    "window_stride_ms = 10.0 #How far to move in time between spectogram timeslices.\n",
    "dct_coefficient_count = 40 #How many bins to use for the MFCC fingerprint\n",
    "how_many_training_steps = '15000,3000'#How many training loops to run\n",
    "eval_step_interval = 400 #How often to evaluate the training results.\n",
    "learning_rate = '0.001,0.0001' #How large a learning rate to use when training.\n",
    "batch_size = 100 #How many items to train with at once'\n",
    "summaries_dir = 'log/retrain_logs' #Where to save summary logs for TensorBoard.\n",
    "wanted_words = 'yes,no,up,down,left,right,on,off,stop,go' #Words to use (others will be added to an unknown label)\n",
    "train_dir = 'log/train_dir' #Directory to write event logs and checkpoint.\n",
    "save_step_interval = 100 #Save model checkpoint every save_steps.\n",
    "start_checkpoint = '' #If specified, restore this pretrained model before any training.\n",
    "model_architecture = 'conv' #What model architecture to use\n",
    "check_nans = False #Whether to check for invalid numbers during processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Downloading speech_commands_v0.01.tar.gz 99.9%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Training from step: 1 \n"
     ]
    }
   ],
   "source": [
    "# We want to see all the logging messages for this tutorial.\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Start a new TensorFlow session.\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Begin by making sure we have the training data we need. If you already have\n",
    "# training data of your own, use `--data_url= ` on the command line to avoid\n",
    "# downloading.\n",
    "model_settings = models.prepare_model_settings(\n",
    "  len(input_data.prepare_words_list(wanted_words.split(','))),\n",
    "  sample_rate, clip_duration_ms, window_size_ms,\n",
    "  window_stride_ms, dct_coefficient_count)\n",
    "audio_processor = input_data.AudioProcessor(\n",
    "  data_url, data_dir, silence_percentage,\n",
    "  unknown_percentage,\n",
    "  wanted_words.split(','), validation_percentage,\n",
    "  testing_percentage, model_settings)\n",
    "fingerprint_size = model_settings['fingerprint_size']\n",
    "label_count = model_settings['label_count']\n",
    "time_shift_samples = int((time_shift_ms * sample_rate) / 1000)\n",
    "# Figure out the learning rates for each training phase. Since it's often\n",
    "# effective to have high learning rates at the start of training, followed by\n",
    "# lower levels towards the end, the number of steps and learning rates can be\n",
    "# specified as comma-separated lists to define the rate at each stage. For\n",
    "# example --how_many_training_steps=10000,3000 --learning_rate=0.001,0.0001\n",
    "# will run 13,000 training loops in total, with a rate of 0.001 for the first\n",
    "# 10,000, and 0.0001 for the final 3,000.\n",
    "training_steps_list = list(map(int, how_many_training_steps.split(',')))\n",
    "learning_rates_list = list(map(float, learning_rate.split(',')))\n",
    "if len(training_steps_list) != len(learning_rates_list):\n",
    "    raise Exception('--how_many_training_steps and --learning_rate must be equal length '\n",
    "                    'lists, but are %d and %d long instead' % (len(training_steps_list),\n",
    "                    len(learning_rates_list)))\n",
    "\n",
    "fingerprint_input = tf.placeholder(\n",
    "  tf.float32, [None, fingerprint_size], name='fingerprint_input')\n",
    "\n",
    "logits, dropout_prob = models.create_model(fingerprint_input, model_settings, model_architecture, is_training=True)\n",
    "\n",
    "# Define loss and optimizer\n",
    "ground_truth_input = tf.placeholder(tf.int64, [None], name='groundtruth_input')\n",
    "\n",
    "# Optionally we can add runtime checks to spot when NaNs or other symptoms of\n",
    "# numerical errors start occurring during training.\n",
    "control_dependencies = []\n",
    "if check_nans:\n",
    "    checks = tf.add_check_numerics_ops()\n",
    "    control_dependencies = [checks]\n",
    "\n",
    "# Create the back propagation and training evaluation machinery in the graph.\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy_mean = tf.losses.sparse_softmax_cross_entropy(labels=ground_truth_input, logits=logits)\n",
    "tf.summary.scalar('cross_entropy', cross_entropy_mean)\n",
    "with tf.name_scope('train'), tf.control_dependencies(control_dependencies):\n",
    "    learning_rate_input = tf.placeholder(tf.float32, [], name='learning_rate_input')\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate_input).minimize(cross_entropy_mean)\n",
    "predicted_indices = tf.argmax(logits, 1)\n",
    "correct_prediction = tf.equal(predicted_indices, ground_truth_input)\n",
    "confusion_matrix = tf.confusion_matrix(ground_truth_input, predicted_indices, num_classes=label_count)\n",
    "evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.summary.scalar('accuracy', evaluation_step)\n",
    "\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "increment_global_step = tf.assign(global_step, global_step + 1)\n",
    "\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "# Merge all the summaries and write them out to /tmp/retrain_logs (by default)\n",
    "merged_summaries = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(summaries_dir + '/train', sess.graph)\n",
    "validation_writer = tf.summary.FileWriter(summaries_dir + '/validation')\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "start_step = 1\n",
    "\n",
    "if start_checkpoint:\n",
    "    models.load_variables_from_checkpoint(sess, start_checkpoint)\n",
    "    start_step = global_step.eval(session=sess)\n",
    "\n",
    "tf.logging.info('Training from step: %d ', start_step)\n",
    "\n",
    "# Save graph.pbtxt.\n",
    "tf.train.write_graph(sess.graph_def, train_dir,  model_architecture + '.pbtxt')\n",
    "\n",
    "# Save list of words.\n",
    "with gfile.GFile(os.path.join(train_dir, model_architecture + '_labels.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(audio_processor.words_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #1: rate 0.001000, accuracy 8.0%, cross entropy 2.555859\n",
      "INFO:tensorflow:Step #2: rate 0.001000, accuracy 7.0%, cross entropy 2.568493\n",
      "INFO:tensorflow:Step #3: rate 0.001000, accuracy 4.0%, cross entropy 2.548818\n",
      "INFO:tensorflow:Step #4: rate 0.001000, accuracy 11.0%, cross entropy 2.525087\n",
      "INFO:tensorflow:Step #5: rate 0.001000, accuracy 10.0%, cross entropy 2.510934\n",
      "INFO:tensorflow:Step #6: rate 0.001000, accuracy 9.0%, cross entropy 2.569896\n",
      "INFO:tensorflow:Step #7: rate 0.001000, accuracy 4.0%, cross entropy 2.551708\n",
      "INFO:tensorflow:Step #8: rate 0.001000, accuracy 8.0%, cross entropy 2.492843\n",
      "INFO:tensorflow:Step #9: rate 0.001000, accuracy 6.0%, cross entropy 2.555687\n",
      "INFO:tensorflow:Step #10: rate 0.001000, accuracy 6.0%, cross entropy 2.531054\n",
      "INFO:tensorflow:Step #11: rate 0.001000, accuracy 11.0%, cross entropy 2.478223\n",
      "INFO:tensorflow:Step #12: rate 0.001000, accuracy 12.0%, cross entropy 2.510865\n",
      "INFO:tensorflow:Step #13: rate 0.001000, accuracy 11.0%, cross entropy 2.527192\n",
      "INFO:tensorflow:Step #14: rate 0.001000, accuracy 8.0%, cross entropy 2.563206\n",
      "INFO:tensorflow:Step #15: rate 0.001000, accuracy 2.0%, cross entropy 2.518091\n",
      "INFO:tensorflow:Step #16: rate 0.001000, accuracy 8.0%, cross entropy 2.542190\n",
      "INFO:tensorflow:Step #17: rate 0.001000, accuracy 9.0%, cross entropy 2.468449\n",
      "INFO:tensorflow:Step #18: rate 0.001000, accuracy 8.0%, cross entropy 2.518113\n",
      "INFO:tensorflow:Step #19: rate 0.001000, accuracy 11.0%, cross entropy 2.499242\n",
      "INFO:tensorflow:Step #20: rate 0.001000, accuracy 6.0%, cross entropy 2.475913\n",
      "INFO:tensorflow:Step #21: rate 0.001000, accuracy 15.0%, cross entropy 2.518856\n",
      "INFO:tensorflow:Step #22: rate 0.001000, accuracy 10.0%, cross entropy 2.521402\n",
      "INFO:tensorflow:Step #23: rate 0.001000, accuracy 8.0%, cross entropy 2.509596\n",
      "INFO:tensorflow:Step #24: rate 0.001000, accuracy 10.0%, cross entropy 2.542334\n",
      "INFO:tensorflow:Step #25: rate 0.001000, accuracy 8.0%, cross entropy 2.511021\n",
      "INFO:tensorflow:Step #26: rate 0.001000, accuracy 9.0%, cross entropy 2.445345\n",
      "INFO:tensorflow:Step #27: rate 0.001000, accuracy 7.0%, cross entropy 2.521109\n",
      "INFO:tensorflow:Step #28: rate 0.001000, accuracy 12.0%, cross entropy 2.496242\n",
      "INFO:tensorflow:Step #29: rate 0.001000, accuracy 8.0%, cross entropy 2.502070\n",
      "INFO:tensorflow:Step #30: rate 0.001000, accuracy 10.0%, cross entropy 2.503196\n",
      "INFO:tensorflow:Step #31: rate 0.001000, accuracy 13.0%, cross entropy 2.511732\n",
      "INFO:tensorflow:Step #32: rate 0.001000, accuracy 8.0%, cross entropy 2.509155\n",
      "INFO:tensorflow:Step #33: rate 0.001000, accuracy 5.0%, cross entropy 2.513388\n",
      "INFO:tensorflow:Step #34: rate 0.001000, accuracy 9.0%, cross entropy 2.537629\n",
      "INFO:tensorflow:Step #35: rate 0.001000, accuracy 9.0%, cross entropy 2.505980\n",
      "INFO:tensorflow:Step #36: rate 0.001000, accuracy 9.0%, cross entropy 2.502607\n",
      "INFO:tensorflow:Step #37: rate 0.001000, accuracy 12.0%, cross entropy 2.456955\n",
      "INFO:tensorflow:Step #38: rate 0.001000, accuracy 5.0%, cross entropy 2.522464\n",
      "INFO:tensorflow:Step #39: rate 0.001000, accuracy 8.0%, cross entropy 2.480822\n",
      "INFO:tensorflow:Step #40: rate 0.001000, accuracy 12.0%, cross entropy 2.492027\n",
      "INFO:tensorflow:Step #41: rate 0.001000, accuracy 12.0%, cross entropy 2.477315\n",
      "INFO:tensorflow:Step #42: rate 0.001000, accuracy 9.0%, cross entropy 2.468784\n",
      "INFO:tensorflow:Step #43: rate 0.001000, accuracy 13.0%, cross entropy 2.483392\n",
      "INFO:tensorflow:Step #44: rate 0.001000, accuracy 10.0%, cross entropy 2.499892\n",
      "INFO:tensorflow:Step #45: rate 0.001000, accuracy 8.0%, cross entropy 2.554376\n",
      "INFO:tensorflow:Step #46: rate 0.001000, accuracy 13.0%, cross entropy 2.471193\n",
      "INFO:tensorflow:Step #47: rate 0.001000, accuracy 7.0%, cross entropy 2.497276\n",
      "INFO:tensorflow:Step #48: rate 0.001000, accuracy 12.0%, cross entropy 2.509258\n",
      "INFO:tensorflow:Step #49: rate 0.001000, accuracy 12.0%, cross entropy 2.436613\n",
      "INFO:tensorflow:Step #50: rate 0.001000, accuracy 6.0%, cross entropy 2.444506\n",
      "INFO:tensorflow:Step #51: rate 0.001000, accuracy 5.0%, cross entropy 2.492336\n",
      "INFO:tensorflow:Step #52: rate 0.001000, accuracy 9.0%, cross entropy 2.464098\n",
      "INFO:tensorflow:Step #53: rate 0.001000, accuracy 12.0%, cross entropy 2.497421\n",
      "INFO:tensorflow:Step #54: rate 0.001000, accuracy 7.0%, cross entropy 2.573157\n",
      "INFO:tensorflow:Step #55: rate 0.001000, accuracy 11.0%, cross entropy 2.460248\n",
      "INFO:tensorflow:Step #56: rate 0.001000, accuracy 16.0%, cross entropy 2.417030\n",
      "INFO:tensorflow:Step #57: rate 0.001000, accuracy 12.0%, cross entropy 2.461865\n",
      "INFO:tensorflow:Step #58: rate 0.001000, accuracy 20.0%, cross entropy 2.464070\n",
      "INFO:tensorflow:Step #59: rate 0.001000, accuracy 21.0%, cross entropy 2.451660\n",
      "INFO:tensorflow:Step #60: rate 0.001000, accuracy 14.0%, cross entropy 2.508741\n",
      "INFO:tensorflow:Step #61: rate 0.001000, accuracy 7.0%, cross entropy 2.487614\n",
      "INFO:tensorflow:Step #62: rate 0.001000, accuracy 9.0%, cross entropy 2.519331\n",
      "INFO:tensorflow:Step #63: rate 0.001000, accuracy 6.0%, cross entropy 2.514899\n",
      "INFO:tensorflow:Step #64: rate 0.001000, accuracy 10.0%, cross entropy 2.489830\n",
      "INFO:tensorflow:Step #65: rate 0.001000, accuracy 13.0%, cross entropy 2.439372\n",
      "INFO:tensorflow:Step #66: rate 0.001000, accuracy 12.0%, cross entropy 2.445373\n",
      "INFO:tensorflow:Step #67: rate 0.001000, accuracy 9.0%, cross entropy 2.495929\n",
      "INFO:tensorflow:Step #68: rate 0.001000, accuracy 10.0%, cross entropy 2.469361\n",
      "INFO:tensorflow:Step #69: rate 0.001000, accuracy 9.0%, cross entropy 2.505813\n",
      "INFO:tensorflow:Step #70: rate 0.001000, accuracy 10.0%, cross entropy 2.456060\n",
      "INFO:tensorflow:Step #71: rate 0.001000, accuracy 6.0%, cross entropy 2.477844\n",
      "INFO:tensorflow:Step #72: rate 0.001000, accuracy 12.0%, cross entropy 2.467469\n",
      "INFO:tensorflow:Step #73: rate 0.001000, accuracy 11.0%, cross entropy 2.478897\n",
      "INFO:tensorflow:Step #74: rate 0.001000, accuracy 11.0%, cross entropy 2.452950\n",
      "INFO:tensorflow:Step #75: rate 0.001000, accuracy 12.0%, cross entropy 2.518103\n",
      "INFO:tensorflow:Step #76: rate 0.001000, accuracy 11.0%, cross entropy 2.498296\n",
      "INFO:tensorflow:Step #77: rate 0.001000, accuracy 17.0%, cross entropy 2.452003\n",
      "INFO:tensorflow:Step #78: rate 0.001000, accuracy 9.0%, cross entropy 2.488010\n",
      "INFO:tensorflow:Step #79: rate 0.001000, accuracy 9.0%, cross entropy 2.488482\n",
      "INFO:tensorflow:Step #80: rate 0.001000, accuracy 6.0%, cross entropy 2.480907\n",
      "INFO:tensorflow:Step #81: rate 0.001000, accuracy 16.0%, cross entropy 2.467408\n",
      "INFO:tensorflow:Step #82: rate 0.001000, accuracy 9.0%, cross entropy 2.493605\n",
      "INFO:tensorflow:Step #83: rate 0.001000, accuracy 12.0%, cross entropy 2.446010\n",
      "INFO:tensorflow:Step #84: rate 0.001000, accuracy 9.0%, cross entropy 2.499544\n",
      "INFO:tensorflow:Step #85: rate 0.001000, accuracy 9.0%, cross entropy 2.456722\n",
      "INFO:tensorflow:Step #86: rate 0.001000, accuracy 17.0%, cross entropy 2.447071\n",
      "INFO:tensorflow:Step #87: rate 0.001000, accuracy 11.0%, cross entropy 2.451149\n",
      "INFO:tensorflow:Step #88: rate 0.001000, accuracy 15.0%, cross entropy 2.433803\n",
      "INFO:tensorflow:Step #89: rate 0.001000, accuracy 12.0%, cross entropy 2.454445\n",
      "INFO:tensorflow:Step #90: rate 0.001000, accuracy 15.0%, cross entropy 2.458594\n",
      "INFO:tensorflow:Step #91: rate 0.001000, accuracy 16.0%, cross entropy 2.471078\n",
      "INFO:tensorflow:Step #92: rate 0.001000, accuracy 9.0%, cross entropy 2.485271\n",
      "INFO:tensorflow:Step #93: rate 0.001000, accuracy 12.0%, cross entropy 2.446486\n",
      "INFO:tensorflow:Step #94: rate 0.001000, accuracy 14.0%, cross entropy 2.485622\n",
      "INFO:tensorflow:Step #95: rate 0.001000, accuracy 11.0%, cross entropy 2.487122\n",
      "INFO:tensorflow:Step #96: rate 0.001000, accuracy 14.0%, cross entropy 2.458941\n",
      "INFO:tensorflow:Step #97: rate 0.001000, accuracy 15.0%, cross entropy 2.485904\n",
      "INFO:tensorflow:Step #98: rate 0.001000, accuracy 14.0%, cross entropy 2.451782\n",
      "INFO:tensorflow:Step #99: rate 0.001000, accuracy 13.0%, cross entropy 2.484048\n",
      "INFO:tensorflow:Step #100: rate 0.001000, accuracy 10.0%, cross entropy 2.460386\n",
      "INFO:tensorflow:Saving to \"log/train_dir/conv.ckpt-100\"\n",
      "INFO:tensorflow:Step #101: rate 0.001000, accuracy 19.0%, cross entropy 2.440284\n",
      "INFO:tensorflow:Step #102: rate 0.001000, accuracy 10.0%, cross entropy 2.459321\n",
      "INFO:tensorflow:Step #103: rate 0.001000, accuracy 17.0%, cross entropy 2.429391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #104: rate 0.001000, accuracy 15.0%, cross entropy 2.459380\n",
      "INFO:tensorflow:Step #105: rate 0.001000, accuracy 10.0%, cross entropy 2.395886\n",
      "INFO:tensorflow:Step #106: rate 0.001000, accuracy 13.0%, cross entropy 2.454031\n",
      "INFO:tensorflow:Step #107: rate 0.001000, accuracy 16.0%, cross entropy 2.406504\n",
      "INFO:tensorflow:Step #108: rate 0.001000, accuracy 12.0%, cross entropy 2.450357\n",
      "INFO:tensorflow:Step #109: rate 0.001000, accuracy 15.0%, cross entropy 2.405913\n",
      "INFO:tensorflow:Step #110: rate 0.001000, accuracy 10.0%, cross entropy 2.467561\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-820a4c42390a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     train_fingerprints, train_ground_truth = audio_processor.get_data(\n\u001b[1;32m     13\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground_frequency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         background_volume, time_shift_samples, 'training', sess)\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Run the graph with this batch of training data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mmerged_summaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincrement_global_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HDA/project/speech_commands/input_data.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, how_many, offset, model_settings, background_frequency, background_volume_range, time_shift, mode, sess)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforeground_volume_placeholder_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m       \u001b[0;31m# Run the graph to produce the output audio.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m       \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m       \u001b[0mlabel_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m       \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop.\n",
    "training_steps_max = np.sum(training_steps_list)\n",
    "for training_step in xrange(start_step, training_steps_max + 1):\n",
    "    # Figure out what the current learning rate is.\n",
    "    training_steps_sum = 0\n",
    "    for i in range(len(training_steps_list)):\n",
    "        training_steps_sum += training_steps_list[i]\n",
    "        if training_step <= training_steps_sum:\n",
    "            learning_rate_value = learning_rates_list[i]\n",
    "            break\n",
    "    # Pull the audio samples we'll use for training.\n",
    "    train_fingerprints, train_ground_truth = audio_processor.get_data(\n",
    "        batch_size, 0, model_settings, background_frequency,\n",
    "        background_volume, time_shift_samples, 'training', sess)\n",
    "    # Run the graph with this batch of training data.\n",
    "    parameters = [ merged_summaries, evaluation_step, cross_entropy_mean, train_step, increment_global_step]\n",
    "    feed_dict = {fingerprint_input: train_fingerprints, ground_truth_input: train_ground_truth,\n",
    "                 learning_rate_input: learning_rate_value, dropout_prob: 0.5 }\n",
    "    train_summary, train_accuracy, cross_entropy_value, _, _ = sess.run( parameters, feed_dict)\n",
    "    train_writer.add_summary(train_summary, training_step)\n",
    "    tf.logging.info('Step #%d: rate %f, accuracy %.1f%%, cross entropy %f' %\n",
    "                    (training_step, learning_rate_value, train_accuracy * 100,\n",
    "                     cross_entropy_value))\n",
    "    is_last_step = (training_step == training_steps_max)\n",
    "    if (training_step % eval_step_interval) == 0 or is_last_step:\n",
    "        set_size = audio_processor.set_size('validation')\n",
    "        total_accuracy = 0\n",
    "        total_conf_matrix = None\n",
    "        for i in xrange(0, set_size, batch_size):\n",
    "            validation_fingerprints, validation_ground_truth = (\n",
    "                audio_processor.get_data(batch_size, i, model_settings, 0.0,\n",
    "                                         0.0, 0, 'validation', sess))\n",
    "            # Run a validation step and capture training summaries for TensorBoard\n",
    "            # with the `merged` op.\n",
    "            parameters = [merged_summaries, evaluation_step, confusion_matrix]\n",
    "            feed_dict = { fingerprint_input: validation_fingerprints, ground_truth_input: validation_ground_truth,\n",
    "                    dropout_prob: 1.0 }\n",
    "            validation_summary, validation_accuracy, conf_matrix = sess.run(parameters, feed_dict)\n",
    "            validation_writer.add_summary(validation_summary, training_step)\n",
    "            batch_size = min(batch_size, set_size - i)\n",
    "            total_accuracy += (validation_accuracy * batch_size) / set_size\n",
    "            if total_conf_matrix is None:\n",
    "                total_conf_matrix = conf_matrix\n",
    "            else:\n",
    "                total_conf_matrix += conf_matrix\n",
    "        tf.logging.info('Confusion Matrix:\\n %s' % (total_conf_matrix))\n",
    "        tf.logging.info('Step %d: Validation accuracy = %.1f%% (N=%d)' %\n",
    "                      (training_step, total_accuracy * 100, set_size))\n",
    "\n",
    "    # Save the model checkpoint periodically.\n",
    "    if (training_step % save_step_interval == 0 or\n",
    "        training_step == training_steps_max):\n",
    "        checkpoint_path = os.path.join(train_dir, model_architecture + '.ckpt')\n",
    "        tf.logging.info('Saving to \"%s-%d\"', checkpoint_path, training_step)\n",
    "        saver.save(sess, checkpoint_path, global_step=training_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:set_size=3081\n",
      "INFO:tensorflow:Confusion Matrix:\n",
      " [[ 99   5  14   0  10   0   4   4 103  10   8   0]\n",
      " [  2  11   4  11  20  25  13  14 152   1   1   3]\n",
      " [  4   9   4  12  31  14  30  27 120   1   3   1]\n",
      " [  2   8   3  17  29  32  10  10 139   0   0   2]\n",
      " [  4   6   0   3  32   6  23   7 171   1  19   0]\n",
      " [  5   9   1  14  12  46   8  15 138   0   3   2]\n",
      " [  3   6   5  14  20  16  33  29 137   0   4   0]\n",
      " [  3   6   5  13  22  22  31  37 116   0   3   1]\n",
      " [  2   9   2  13  13  33   5   5 159   1   3   1]\n",
      " [  4   4   0   2  24  12  17  19 164   1  15   0]\n",
      " [  7  16   2   7  22   8  17   8 143   0  17   2]\n",
      " [  8   8   1  20  20  30   9  15 136   0   1   3]]\n",
      "INFO:tensorflow:Final test accuracy = 14.9% (N=3081)\n"
     ]
    }
   ],
   "source": [
    "set_size = audio_processor.set_size('testing')\n",
    "tf.logging.info('set_size=%d', set_size)\n",
    "total_accuracy = 0\n",
    "total_conf_matrix = None\n",
    "for i in xrange(0, set_size, batch_size):\n",
    "    test_fingerprints, test_ground_truth = audio_processor.get_data(\n",
    "        batch_size, i, model_settings, 0.0, 0.0, 0, 'testing', sess)\n",
    "    test_accuracy, conf_matrix = sess.run(\n",
    "        [evaluation_step, confusion_matrix],\n",
    "        feed_dict={\n",
    "            fingerprint_input: test_fingerprints,\n",
    "            ground_truth_input: test_ground_truth,\n",
    "            dropout_prob: 1.0\n",
    "        })\n",
    "    batch_size = min(batch_size, set_size - i)\n",
    "    total_accuracy += (test_accuracy * batch_size) / set_size\n",
    "    if total_conf_matrix is None:\n",
    "        total_conf_matrix = conf_matrix\n",
    "    else:\n",
    "        total_conf_matrix += conf_matrix\n",
    "tf.logging.info('Confusion Matrix:\\n %s' % (total_conf_matrix))\n",
    "tf.logging.info('Final test accuracy = %.1f%% (N=%d)' % (total_accuracy * 100,\n",
    "                                                       set_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
