{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "## save variables\n",
    "import pickle\n",
    "## folder names\n",
    "from glob import glob\n",
    "## standard libraries\n",
    "import numpy as np\n",
    "\n",
    "#!{sys.executable} -m pip install tensorflow-gpu --user\n",
    "#!{sys.executable} -m pip install keras --user\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "import keras\n",
    "from keras.optimizers import SGD, Adam\n",
    "#!{sys.executable} -m pip install hyperas --user\n",
    "#!{sys.executable} -m pip install networkx==1.11 --user\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "import os.path\n",
    "import datetime\n",
    "\n",
    "from dependencies import models\n",
    "from dependencies import functions\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose which dictionary to use\n",
    "choice =       'mfcc'# 'logfilter' #\n",
    "useDelta =  False\n",
    "\n",
    "data = {}\n",
    "\n",
    "\n",
    "    \n",
    "selected = 0\n",
    "\n",
    "if choice == 'mfcc':\n",
    "    #retrieving of used values for the computation of mfcc\n",
    "    with open('variables/mfccValues.pkl', 'rb') as f:  \n",
    "        values = pickle.load(f)\n",
    "    for index in range(4):\n",
    "        #name format of the selected data\n",
    "        if useDelta:\n",
    "            name = 'variables/mfccDictDD'+functions.getName(index)+'[nC='+str(values[selected][0])+' wL='+str(values[selected][2])+' wS='+str(values[selected][3])+'].pkl'\n",
    "        else:\n",
    "            name = 'variables/mfccDict'+functions.getName(index)+'[nC='+str(values[selected][0])+' wL='+str(values[selected][2])+' wS='+str(values[selected][3])+'].pkl'\n",
    "        #loading in usedDict of the mfcc dict\n",
    "        with open(name, 'rb') as f: \n",
    "            data[functions.getName(index)] = pickle.load(f)\n",
    "        print('Loaded '+name)\n",
    "\n",
    "elif choice == 'logfilter':\n",
    "    #retrieving of used values for the computation of mfcc\n",
    "    with open('variables/lfValues.pkl', 'rb') as f:  \n",
    "        values = pickle.load(f)\n",
    "    for index in range(4):\n",
    "        #name format of the selected data\n",
    "        if useDelta:\n",
    "            name = 'variables/logfiltDictDD'+functions.getName(index)+'[nF='+str(values[selected][0])+' wL='+str(values[selected][1])+' wS='+str(values[selected][2])+'].pkl'\n",
    "        else:\n",
    "            name = 'variables/logfiltDict'+functions.getName(index)+'[nF='+str(values[selected][0])+' wL='+str(values[selected][1])+' wS='+str(values[selected][2])+'].pkl'\n",
    "        #saving in usedDict of the logfilter dict\n",
    "        with open(name, 'rb') as f:  \n",
    "            data[functions.getName(index)] = pickle.load(f)\n",
    "        print('Loaded '+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#core words of the dataset\n",
    "coreKey = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"zero\",\n",
    "           \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
    "\n",
    "#split of the core set\n",
    "numbers = ['one', 'two', 'three','four','five','six','seven','eight','nine', \"zero\"]\n",
    "\n",
    "famolaSporca = ['yes', 'left', 'right', 'up', 'on', 'zero', 'one', 'three', 'seven', 'nine']\n",
    "\n",
    "words = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]\n",
    "\n",
    "#selecting the subset of words to predict\n",
    "usedLabels = words\n",
    "\n",
    "usedLabels.append('silence')\n",
    "\n",
    "unknownLabels = list(data['Train'].keys())\n",
    "for key in usedLabels:\n",
    "    try:\n",
    "        unknownLabels.remove(key)\n",
    "    except:\n",
    "        print(key, ' not in used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#divding between train and test with also scaling data\n",
    "functions.train_test_creator(\n",
    "    data,\n",
    "    usedLabels,\n",
    "    unknownLabels,\n",
    "    with_unknown = False,\n",
    "    scalerType = 'robust',\n",
    "    depth = (len(data['Train'][words[0]].shape)-3)*2 + 1,\n",
    "    unknown_percentage = 0.3)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f \n",
    "from IPython.display import Javascript\n",
    "Javascript(\"Jupyter.notebook.execute_cells([0])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, labels = functions.load_dataset()\n",
    "with open('variables/labelList.pkl', 'rb') as f: \n",
    "        labelList = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    " \n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a total 0.8 of the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    " \n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "epoch = 15\n",
    "epochSGD = 15\n",
    "\n",
    "epochs = [epoch, epochSGD]\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001/epoch, amsgrad=True)\n",
    "sgd = SGD(lr=0.001, decay=0.001/epochSGD, momentum=0.9, nesterov=True)\n",
    "\n",
    "optimizers = [adam, sgd]\n",
    "\n",
    "top3_acc = partial(keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "top3_acc.name = 'top3_acc'\n",
    "\n",
    "titles = ['Adam History', 'SGD History']\n",
    "\n",
    "dest_directory = 'model_backup/'\n",
    "if not os.path.exists(dest_directory):\n",
    "      os.makedirs(dest_directory)\n",
    "\n",
    "esCallBack = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1, mode='auto', baseline=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"MODEL1\")\n",
    "inputData, inputLabel, testData, testLabel, validData, validLabel, augmentedData, augmentedLabel, validation_data, loss_weights = functions.modelSelection('model1', dataset, labels)\n",
    "\n",
    "cnn = models.model1(inputData,inputLabel)\n",
    "\n",
    "fittedHistory = []\n",
    "\n",
    "for count, optimizer in enumerate(optimizers):\n",
    "    print('Using optimizer number ' + str(count))\n",
    "    cnn.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy', top3_acc ], loss_weights=loss_weights)\n",
    "    fittedHistory.append(cnn.fit(inputData, inputLabel,\n",
    "                         epochs=epochs[count],\n",
    "                         batch_size=round(inputData.shape[0]/400),\n",
    "                         shuffle=True,\n",
    "                         validation_data=validation_data,\n",
    "                         callbacks = [esCallBack]))\n",
    "\n",
    "functions.plotHistory(epochs, fittedHistory, 'Training History')\n",
    "\n",
    "preds = cnn.predict(testData)\n",
    "\n",
    "#Plot normalized confusion matrix\n",
    "functions.plot_confusion_matrix(preds, testLabel, classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "precision = cnn.evaluate(testData,  testLabel)\n",
    "print (\"Precision: \", round(precision[1]*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn = models.model1(inputData,inputLabel)\n",
    "\n",
    "print('Adding augmented dataset')\n",
    "inputData, inputLabel = functions.meltData(inputData, augmentedData, inputLabel, augmentedLabel, 0.7)\n",
    "\n",
    "fittedHistory = []\n",
    "\n",
    "for count, optimizer in enumerate(optimizers):\n",
    "    print('Using optimizer number ' + str(count))\n",
    "    cnn.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy', top3_acc ], loss_weights=loss_weights)\n",
    "    fittedHistory.append(cnn.fit(inputData, inputLabel,\n",
    "                         epochs=epochs[count],\n",
    "                         batch_size=round(inputData.shape[0]/400),\n",
    "                         shuffle=True,\n",
    "                         validation_data=validation_data,\n",
    "                         callbacks = [esCallBack]))\n",
    "    \n",
    "functions.plotHistory(epochs, fittedHistory, 'Training History')\n",
    "\n",
    "preds = cnn.predict(testData)\n",
    "#Plot normalized confusion matrix\n",
    "functions.plot_confusion_matrix(preds, testLabel, classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "precision = cnn.evaluate(testData,  testLabel)\n",
    "print (\"Precision: \", round(precision[1]*100,2),\"%\")\n",
    "\n",
    "name = 'cnn1.bak'\n",
    "#cnn.save(dest_directory + name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\nMODEL2\")\n",
    "inputData, inputLabel, testData, testLabel, validData, validLabel, augmentedData, augmentedLabel, validation_data, loss_weights = functions.modelSelection('model2', dataset, labels)\n",
    "\n",
    "cnn = models.model2(inputData,inputLabel, baseDim = 40)\n",
    "\n",
    "fittedHistory = []\n",
    "\n",
    "for count, optimizer in enumerate(optimizers):\n",
    "    print('Using optimizer number ' + str(count))\n",
    "    cnn.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy', top3_acc ], loss_weights=loss_weights)\n",
    "    fittedHistory.append(cnn.fit(inputData, inputLabel,\n",
    "                         epochs=epochs[count],\n",
    "                         batch_size=round(inputData.shape[0]/400),\n",
    "                         shuffle=True,\n",
    "                         validation_data=validation_data,\n",
    "                         callbacks = [esCallBack]))\n",
    "\n",
    "functions.plotHistory(epochs, fittedHistory, 'Training History')\n",
    "\n",
    "preds = cnn.predict(testData)\n",
    "\n",
    "#Plot normalized confusion matrix\n",
    "functions.plot_confusion_matrix(preds, testLabel, classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "precision = cnn.evaluate(testData,  testLabel)\n",
    "print (\"Precision: \", round(precision[1]*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn = models.model2(inputData,inputLabel, baseDim = 40 )\n",
    "\n",
    "print('Adding augmented dataset')\n",
    "inputData, inputLabel = functions.meltData(inputData, augmentedData, inputLabel, augmentedLabel, 0.7)\n",
    "\n",
    "fittedHistory = []\n",
    "\n",
    "for count, optimizer in enumerate(optimizers):\n",
    "    print('Using optimizer number ' + str(count))\n",
    "    cnn.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy', top3_acc ], loss_weights=loss_weights)\n",
    "    fittedHistory.append(cnn.fit(inputData, inputLabel,\n",
    "                         epochs=epochs[count],\n",
    "                         batch_size=round(inputData.shape[0]/400),\n",
    "                         shuffle=True,\n",
    "                         validation_data=validation_data,\n",
    "                         callbacks = [esCallBack]))\n",
    "functions.plotHistory(epochs, fittedHistory, 'Training History')\n",
    "\n",
    "preds = cnn.predict(testData)\n",
    "\n",
    "#Plot normalized confusion matrix\n",
    "functions.plot_confusion_matrix(preds, testLabel, classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "precision = cnn.evaluate(testData,  testLabel)\n",
    "print (\"Precision: \", round(precision[1]*100,2),\"%\")\n",
    "name = 'cnn2.bak'\n",
    "#cnn.save(dest_directory + name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TinyDarknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\nTINYDARKNET\")\n",
    "inputData, inputLabel, testData, testLabel, validData, validLabel, augmentedData, augmentedLabel, validation_data, loss_weights = functions.modelSelection('tinyDarknet', dataset, labels)\n",
    "\n",
    "cnn = models.tinyDarknet(inputData,inputLabel, dropout = 0.3)\n",
    "\n",
    "fittedHistory = []\n",
    "\n",
    "for count, optimizer in enumerate(optimizers):\n",
    "    print('Using optimizer number ' + str(count))\n",
    "    cnn.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy', top3_acc ], loss_weights=loss_weights)\n",
    "    fittedHistory.append(cnn.fit(inputData, inputLabel,\n",
    "                         epochs=epochs[count],\n",
    "                         batch_size=round(inputData.shape[0]/400),\n",
    "                         shuffle=True,\n",
    "                         validation_data=validation_data,\n",
    "                         callbacks = [esCallBack]))\n",
    "\n",
    "functions.plotHistory(epochs, fittedHistory, 'Training History')\n",
    "\n",
    "preds = cnn.predict(testData)\n",
    "\n",
    "#Plot normalized confusion matrix\n",
    "functions.plot_confusion_matrix(preds, testLabel, classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "precision = cnn.evaluate(testData,  testLabel)\n",
    "print (\"Precision: \", round(precision[1]*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn = models.tinyDarknet(inputData,inputLabel, dropout = 0.3)\n",
    "\n",
    "print('Adding augmented dataset')\n",
    "inputData, inputLabel = functions.meltData(inputData, augmentedData, inputLabel, augmentedLabel, 0.7)\n",
    "\n",
    "fittedHistory = []\n",
    "\n",
    "for count, optimizer in enumerate(optimizers):\n",
    "    print('Using optimizer number ' + str(count))\n",
    "    cnn.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy', top3_acc ], loss_weights=loss_weights)\n",
    "    fittedHistory.append(cnn.fit(inputData, inputLabel,\n",
    "                         epochs=epochs[count],\n",
    "                         batch_size=round(inputData.shape[0]/400),\n",
    "                         shuffle=True,\n",
    "                         validation_data=validation_data,\n",
    "                         callbacks = [esCallBack]))\n",
    "    \n",
    "functions.plotHistory(epochs, fittedHistory, 'Training History')\n",
    "\n",
    "preds = cnn.predict(testData)\n",
    "\n",
    "#Plot normalized confusion matrix\n",
    "functions.plot_confusion_matrix(preds, testLabel, classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "precision = cnn.evaluate(testData,  testLabel)\n",
    "print (\"Precision: \", round(precision[1]*100,2),\"%\")\n",
    "\n",
    "name = 'tinyDarknet.bak'\n",
    "#cnn.save(dest_directory + name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "inputData, inputLabel, testData, testLabel, validData, validLabel, augmentedData, augmentedLabel, validation_data, loss_weights = functions.modelSelection('SiSoInc', dataset, labels)\n",
    "\n",
    "cnn = models.SiSoInception(inputData,inputLabel)\n",
    "\n",
    "fittedHistory = []\n",
    "\n",
    "for count, optimizer in enumerate(optimizers):\n",
    "    print('Using optimizer number ' + str(count))\n",
    "    cnn.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy', top3_acc ], loss_weights=loss_weights)\n",
    "    fittedHistory.append(cnn.fit(inputData, inputLabel,\n",
    "                         epochs=epochs[count],\n",
    "                         batch_size=round(inputData.shape[0]/400),\n",
    "                         shuffle=True,\n",
    "                         validation_data=validation_data,\n",
    "                         callbacks = [esCallBack]))\n",
    "\n",
    "functions.plotHistory(epochs, fittedHistory, 'Training History')\n",
    "\n",
    "preds = cnn.predict(testData)\n",
    "\n",
    "#Plot normalized confusion matrix\n",
    "functions.plot_confusion_matrix(preds, testLabel, classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "precision = cnn.evaluate(testData,  testLabel)\n",
    "print (\"Precision: \", round(precision[1]*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn = models.SiSoInception(inputData,inputLabel, dropout = 0.5)\n",
    "\n",
    "print('Adding augmented dataset')\n",
    "inputData, inputLabel = functions.meltData(inputData, augmentedData, inputLabel, augmentedLabel, 0.7)\n",
    "\n",
    "fittedHistory = []\n",
    "\n",
    "for count, optimizer in enumerate(optimizers):\n",
    "    print('Using optimizer number ' + str(count))\n",
    "    cnn.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy', top3_acc ], loss_weights=loss_weights)\n",
    "    fittedHistory.append(cnn.fit(inputData, inputLabel,\n",
    "                         epochs=epochs[count],\n",
    "                         batch_size=round(inputData.shape[0]/400),\n",
    "                         shuffle=True,\n",
    "                         validation_data=validation_data,\n",
    "                         callbacks = [esCallBack]))\n",
    "    \n",
    "functions.plotHistory(epochs, fittedHistory, 'Training History')\n",
    "\n",
    "preds = cnn.predict(testData)\n",
    "\n",
    "#Plot normalized confusion matrix\n",
    "functions.plot_confusion_matrix(preds, testLabel, classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "precision = cnn.evaluate(testData,  testLabel)\n",
    "print (\"Precision: \", round(precision[1]*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "inputData, inputLabel, testData, testLabel, validData, validLabel, augmentedData, augmentedLabel, validation_data, loss_weights = functions.modelSelection('MiSoInc', dataset, labels)\n",
    "\n",
    "cnn = models.MiSoInception(inputData, inputLabel, dropout = 0.4)\n",
    "\n",
    "fittedHistory = []\n",
    "\n",
    "for count, optimizer in enumerate(optimizers):\n",
    "    print('Using optimizer number ' + str(count))\n",
    "    cnn.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy', top3_acc ], loss_weights=loss_weights)\n",
    "    fittedHistory.append(cnn.fit(inputData, inputLabel,\n",
    "                         epochs=epochs[count],\n",
    "                         batch_size=round(inputData[0].shape[0]/400),\n",
    "                         shuffle=True,\n",
    "                         validation_data=validation_data,\n",
    "                         callbacks = [esCallBack]))\n",
    "\n",
    "functions.plotHistory(epochs, fittedHistory, 'Training History')\n",
    "\n",
    "preds = cnn.predict(testData)\n",
    "\n",
    "#Plot normalized confusion matrix\n",
    "functions.plot_confusion_matrix(preds, testLabel, classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "precision = cnn.evaluate(testData,  testLabel)\n",
    "print (\"Precision: \", round(precision[1]*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn = models.MiSoInception(inputData,inputLabel, dropout = 0.4)\n",
    "\n",
    "print('Adding augmented dataset')\n",
    "inputData, inputLabel = functions.meltData(inputData, augmentedData, inputLabel, augmentedLabel, 0.7)\n",
    "\n",
    "fittedHistory = []\n",
    "\n",
    "for count, optimizer in enumerate(optimizers):\n",
    "    print('Using optimizer number ' + str(count))\n",
    "    cnn.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy', top3_acc ], loss_weights=loss_weights)\n",
    "    fittedHistory.append(cnn.fit(inputData, inputLabel,\n",
    "                         epochs=epochs[count],\n",
    "                         batch_size=round(inputData[0].shape[0]/400),\n",
    "                         shuffle=True,\n",
    "                         validation_data=validation_data,\n",
    "                         callbacks = [esCallBack]))\n",
    "    \n",
    "functions.plotHistory(epochs, fittedHistory, 'Training History')\n",
    "\n",
    "preds = cnn.predict(testData)\n",
    "\n",
    "#Plot normalized confusion matrix\n",
    "functions.plot_confusion_matrix(preds, testLabel, classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "precision = cnn.evaluate(testData,  testLabel)\n",
    "print (\"Precision: \", round(precision[1]*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "inputData, inputLabel, testData, testLabel, validData, validLabel, augmentedData, augmentedLabel, validation_data, loss_weights = functions.modelSelection('SiMoInc', dataset, labels)\n",
    "\n",
    "cnn = models.SiMoInception(inputData,inputLabel)\n",
    "fittedHistory = []\n",
    "\n",
    "for count, optimizer in enumerate(optimizers):\n",
    "    print('Using optimizer number ' + str(count))\n",
    "    cnn.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy', top3_acc ], loss_weights=loss_weights)\n",
    "    fittedHistory.append(cnn.fit(inputData, inputLabel,\n",
    "                         epochs=epochs[count],\n",
    "                         batch_size=round(inputData.shape[0]/400),\n",
    "                         shuffle=True,\n",
    "                         validation_data=validation_data,\n",
    "                         callbacks = [esCallBack]))\n",
    "\n",
    "functions.plotHistory(epochs, fittedHistory, 'Training History')\n",
    "\n",
    "preds = cnn.predict(testData)[0]\n",
    "\n",
    "\n",
    "#Plot normalized confusion matrix\n",
    "functions.plot_confusion_matrix(preds, testLabel[0], classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "precision = cnn.evaluate(testData,  testLabel)\n",
    "print (\"Precision: \", round(precision[4]*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn = models.SiMoInception(inputData,inputLabel)\n",
    "\n",
    "print('Adding augmented dataset')\n",
    "inputData, inputLabel = functions.meltData(inputData, augmentedData, inputLabel, augmentedLabel, 0.7)\n",
    "\n",
    "cnn = models.SiMoInception(inputData,inputLabel)\n",
    "fittedHistory = []\n",
    "\n",
    "for count, optimizer in enumerate(optimizers):\n",
    "    print('Using optimizer number ' + str(count))\n",
    "    cnn.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy', top3_acc ], loss_weights=loss_weights)\n",
    "    fittedHistory.append(cnn.fit(inputData, inputLabel,\n",
    "                         epochs=epochs[count],\n",
    "                         batch_size=round(inputData.shape[0]/400),\n",
    "                         shuffle=True,\n",
    "                         validation_data=validation_data))\n",
    "\n",
    "functions.plotHistory(epochs, fittedHistory, 'Training History')\n",
    "\n",
    "preds = cnn.predict(testData)[0]\n",
    "\n",
    "\n",
    "#Plot normalized confusion matrix\n",
    "functions.plot_confusion_matrix(preds, testLabel[0], classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "precision = cnn.evaluate(testData,  testLabel)\n",
    "print (\"Precision: \", round(precision[4]*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = k.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= k.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = k.clip(y_pred, k.epsilon(), 1 - k.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * k.log(y_pred) * weights\n",
    "        loss = -k.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#find prediction with test data\n",
    "%matplotlib notebook\n",
    "preds = cnn.predict(testData)\n",
    "#Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "functions.plot_confusion_matrix(preds, testLabel, classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "precision = cnn.evaluate(testData,  testLabel)\n",
    "print (\"Precision: \", round(precision[1]*100,2),\"%\")\n",
    "\n",
    "#print(list(used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = cnn.predict(validData)\n",
    "plt.figure()\n",
    "cm = functions.plot_confusion_matrix(preds[0], validLabel[0], classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix', plot = True)\n",
    "\n",
    "weights = np.diagonal(1 - cm).copy()\n",
    "#weights /= np.max(weights)\n",
    "\n",
    "weights = (1-weights) * 2\n",
    "\n",
    "print(weights/np.max(weights))\n",
    "\n",
    "ncce1 = weighted_categorical_crossentropy(weights)\n",
    "ncce1.__name__ ='w_categorical_crossentropy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiledSGD = cnn.compile(loss=ncce1, optimizer=sgd, metrics=['accuracy', top3_acc], loss_weights=loss_weights)\n",
    "fittedSGD = cnn.fit(inputData, inputLabel,\n",
    "                     epochs=epochSGD,\n",
    "                     batch_size=round(inputData.shape[0]/400),\n",
    "                     validation_data=validation_data,\n",
    "                     shuffle=True,\n",
    "                         callbacks = [esCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find prediction with test data\n",
    "%matplotlib notebook\n",
    "preds = cnn.predict(testData)\n",
    "#Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "functions.plot_confusion_matrix(preds, testLabel, classes=labelList, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "precision = cnn.evaluate(testData,  testLabel)\n",
    "print (\"Precision: \", round(precision[1]*100,2),\"%\")\n",
    "\n",
    "#print(list(used))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_directory = 'model_backup/'\n",
    "if not os.path.exists(dest_directory):\n",
    "      os.makedirs(dest_directory)\n",
    "name = 'cnn.bak'\n",
    "cnn.save(dest_directory + name)\n",
    "\n",
    "#bak = load_model(dest_directory + name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.activations import softmax\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Convolution2D, MaxPooling2D, AveragePooling2D, BatchNormalization\n",
    "trials = Trials()\n",
    "best_run, best_model = optim.minimize(model=functions.create_model, \n",
    "                                      data=functions.data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=100,\n",
    "                                      trials=trials,\n",
    "                                      notebook_name='ExtraCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_directory = 'model_backup/'\n",
    "'''\n",
    "best_model = load_model(dest_directory + 'best_model.bak')\n",
    "\n",
    "with open(dest_directory+'best_run.pkl', 'rb') as f:  \n",
    "    best_run = pickle.load(f)    \n",
    "'''\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(x_test, y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)\n",
    "best_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "dest_directory_temp =dest_directory + 'bestModel('+now.strftime(\"%m-%d %H.%M\")+\")\"\n",
    "if not os.path.exists(dest_directory_temp):\n",
    "      os.makedirs(dest_directory_temp)\n",
    "best_model.save(dest_directory_temp + '/best_model.bak')\n",
    "\n",
    "with open(dest_directory_temp + '/best_run.pkl', 'wb') as f:  \n",
    "    pickle.dump(best_run, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials.best_trial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
