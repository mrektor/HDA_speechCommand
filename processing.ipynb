{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tlc/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## save variables\n",
    "import pickle\n",
    "## folder names\n",
    "from glob import glob\n",
    "## standard libraries\n",
    "import numpy as np\n",
    "## division for train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "##\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.8.0-cp36-cp36m-linux_x86_64.whl --user\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout, MaxPooling1D ,Convolution2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Return a zero np.array with the only one in index position and with length given\n",
    "def labelCreator (index, dim):\n",
    "    try:\n",
    "        a = np.zeros(dim, dtype = 'int')\n",
    "        a [:,index] = 1\n",
    "        return a\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def xyCreator(dic):\n",
    "    X = []\n",
    "    Y = []\n",
    "    if type(dic)==dict:\n",
    "        length = len(dic)\n",
    "        for count, key in enumerate(dic):\n",
    "            tmp = dic[key]\n",
    "            label = labelCreator(count, [tmp.shape[0], length])\n",
    "            X.append(tmp)\n",
    "            Y.append(label)\n",
    "    else:\n",
    "        return -1\n",
    "    return np.vstack(X) , np.vstack(Y)  \n",
    "\n",
    "def xyCreatorCat(dic):\n",
    "    X = []\n",
    "    Y = []\n",
    "    if type(dic)==dict:\n",
    "        length = len(dic)\n",
    "        for count, key in enumerate(dic):\n",
    "            tmp = dic[key]\n",
    "            label = np.array(count)\n",
    "            label = np.resize(label, (tmp.shape[0],1))\n",
    "            #label = labelCreator(count, [tmp.shape[0], length])\n",
    "            X.append(tmp)\n",
    "            Y.append(label)\n",
    "    else:\n",
    "        return -1\n",
    "    return np.vstack(X) , np.vstack(Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('variables/rawDict.pkl', 'rb') as f:  \n",
    "    rawDict = pickle.load(f)\n",
    "with open('variables/noiseDict.pkl', 'rb') as f:  \n",
    "    noiseDict = pickle.load(f)    \n",
    "with open('variables/mfccDict.pkl', 'rb') as f:  \n",
    "    mfccDict = pickle.load(f)\n",
    "with open('variables/fbankDict.pkl', 'rb') as f:  \n",
    "    fbankDict = pickle.load(f)    \n",
    "    \n",
    "coreKey = [\"Yes\", \"No\", \"Up\", \"Down\", \"Left\", \"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\",\n",
    "           \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\"]\n",
    "#subdict = {k: bigdict[k] for k in bigdict.keys() & {'l', 'm', 'n'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before PCA: 1287\n",
      "Number of features after PCA at 95% of variance: 375\n",
      "(5679, 375) (5679, 1)\n",
      "(1420, 375) (1420, 1)\n"
     ]
    }
   ],
   "source": [
    "X , Y = xyCreatorCat({k: mfccDict[k] for k in mfccDict.keys() & {'one', 'two', 'three'}})\n",
    "\n",
    "X = normalize(X, axis=1)\n",
    "pca = PCA(n_components=0.95)\n",
    "print(\"Number of features before PCA:\", X.shape[1])\n",
    "X = pca.fit_transform(X)\n",
    "print(\"Number of features after PCA at 95% of variance:\", X.shape[1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = np_utils.to_categorical(y_train, 3)\n",
    "y_t = np_utils.to_categorical(y_test, 3)\n",
    "X_train_r = np.reshape(X_train, ( X_train.shape[0],1, X_train.shape[1],1))\n",
    "X_test_r = np.reshape(X_test, ( X_test.shape[0],1, X_test.shape[1],1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Convolution2D(64, 4,  strides = 1,\n",
    "    padding=\"same\",\n",
    "    activation=\"relu\",\n",
    "    input_shape=(1, X_train.shape[1], 1)))\n",
    "#cnn.add(Convolution2D(64, 4, strides = 1, padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,1)))\n",
    "\n",
    "#cnn.add(Convolution2D(128, 3, strides = 1, padding=\"same\", activation=\"relu\"))\n",
    "#cnn.add(Convolution2D(128, 3, strides =  1, padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(Convolution2D(128, 3,  strides = 1, padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,1)))\n",
    "   \n",
    "#cnn.add(Convolution2D(256, 3, strides =  1, padding=\"same\", activation=\"relu\"))\n",
    "#cnn.add(Convolution2D(256, 3,  strides = 1, padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(Convolution2D(256, 3,  strides = 1, padding=\"same\", activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,1)))\n",
    "   \n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation=\"relu\"))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(y_tr.shape[1], activation=\"softmax\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "\n",
    "cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5679 samples, validate on 1420 samples\n",
      "Epoch 1/20\n",
      "5679/5679 [==============================] - 32s 6ms/step - loss: 0.5614 - acc: 0.7260 - val_loss: 0.5379 - val_acc: 0.7592\n",
      "Epoch 2/20\n",
      "5679/5679 [==============================] - 32s 6ms/step - loss: 0.5214 - acc: 0.7598 - val_loss: 0.4833 - val_acc: 0.7951\n",
      "Epoch 3/20\n",
      "1440/5679 [======>.......................] - ETA: 20s - loss: 0.4462 - acc: 0.8125"
     ]
    }
   ],
   "source": [
    "nb_epoch = 20\n",
    "cnn.fit(X_train_r, y_tr, epochs=nb_epoch, validation_data=(X_test_r, y_t), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.6144356e-03 4.2727000e-01 5.6511557e-01]\n",
      " [6.0666510e-04 4.7464275e-01 5.2475065e-01]\n",
      " [1.6914908e-04 2.9235905e-01 7.0747179e-01]\n",
      " ...\n",
      " [8.3474112e-01 1.2958294e-01 3.5675924e-02]\n",
      " [1.5717975e-03 4.6157557e-01 5.3685266e-01]\n",
      " [3.7446126e-04 4.1551203e-01 5.8411348e-01]]\n",
      "Loss = [0.00761444 0.42727    0.5651156 ]\n",
      "Test Accuracy = [0.00060667 0.47464275 0.52475065]\n"
     ]
    }
   ],
   "source": [
    "preds = cnn.predict(X_test_r)\n",
    "\n",
    "### END CODE HERE ###\n",
    "print(preds)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
