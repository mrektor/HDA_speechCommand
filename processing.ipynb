{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "## save variables\n",
    "import pickle\n",
    "## folder names\n",
    "from glob import glob\n",
    "## standard libraries\n",
    "import numpy as np\n",
    "## division for train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "##\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from keras.activations import softmax\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Convolution2D, MaxPooling2D, AveragePooling2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import sys\n",
    "#!{sys.executable} -m pip install hyperas --user\n",
    "#!{sys.executable} -m pip install networkx==1.11 --user\n",
    "\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "import os.path\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No-K Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotConfusionMatrix(predictions, true_labels, labels):\n",
    "    k = true_labels.shape[1]\n",
    "    n = true_labels.shape[0]\n",
    "    confusion_matrix = np.zeros((k,k))\n",
    "\n",
    "    for l in range(n):\n",
    "        decision = np.zeros(k)\n",
    "        j = np.argmax(predictions[l])\n",
    "        decision[j] = 1\n",
    "        i = np.argmax(true_labels[l])\n",
    "        confusion_matrix[i,j] +=1\n",
    "        \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(confusion_matrix)\n",
    "    plt.title('Confusion matrix of the classifier')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels([''] + labels)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def train_test_creator(dic, test_size = 0.2):\n",
    "    X = []\n",
    "    Y = []\n",
    "    #create X and Y with corresponding index\n",
    "    if type(dic)==dict:\n",
    "        length = len(dic)\n",
    "        for count, key in enumerate(dic):\n",
    "            tmp = dic[key]\n",
    "            label = np.array(count)\n",
    "            label = np.resize(label, (tmp.shape[0],1))\n",
    "            X.append(tmp)\n",
    "            Y.append(label)\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    #transform X and Y (lists) in ndarray \n",
    "    X = np.vstack(X)\n",
    "    Y = np.vstack(Y)\n",
    "    \n",
    "    #transform Y into 1-hot array\n",
    "    Y = np_utils.to_categorical(Y, np.max(Y)+1)\n",
    "    \n",
    "    #split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)\n",
    "    \n",
    "    #reshape for conv2d layers\n",
    "    X_train = np.reshape(X_train, ( X_train.shape[0], X_train.shape[1], X_train.shape[2],1))\n",
    "    X_test = np.reshape(X_test, ( X_test.shape[0], X_test.shape[1], X_test.shape[2],1))\n",
    "    \n",
    "    #save used data for hyperas use\n",
    "    with open('variables/train_test_split.pkl', 'wb') as f:  \n",
    "        pickle.dump(X_train, f)\n",
    "        pickle.dump(y_train, f)\n",
    "        pickle.dump(X_test, f)\n",
    "        pickle.dump(y_test, f) \n",
    "        \n",
    "    return X_train, y_train, X_test, y_test \n",
    "\n",
    "\n",
    "def findScaler(x, scalerType='standard'):\n",
    "    #initialize the scaler\n",
    "    if scalerType == 'robust':\n",
    "        scaler = RobustScaler()\n",
    "    elif scalerType == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    temp = []\n",
    "    #online fit on all data reshaped as array\n",
    "    for count, sample in enumerate(x):\n",
    "        sample = np.reshape(sample,(sample.shape[0]*sample.shape[1])).reshape(1, -1)\n",
    "        temp.append(sample)\n",
    "    temp=np.vstack(temp)\n",
    "    scaler.fit(temp)\n",
    "    return scaler    \n",
    "\n",
    "def scale(x, scaler):\n",
    "    #scaling data with the trained scaler  \n",
    "    temp = []\n",
    "    for count, sample in enumerate(x):\n",
    "        sample = np.reshape(sample,(sample.shape[0]*sample.shape[1])).reshape(1, -1)\n",
    "        temp.append(sample)\n",
    "    temp=np.vstack(temp)\n",
    "    temp = scaler.transform(temp)\n",
    "    for count, sample in enumerate(temp):\n",
    "        x[count] = np.reshape(sample,(x.shape[1],x.shape[2],1))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded variables/mfccDict[nC=13 wL=0.025 wS=0.01].pkl\n"
     ]
    }
   ],
   "source": [
    "#choose which dictionary to use\n",
    "choice = 'mfcc'#'spectro'\n",
    "\n",
    "\n",
    "selected = 0\n",
    "if choice == 'mfcc':\n",
    "    \n",
    "    #retrieving of used values for the computation of mfcc\n",
    "    with open('variables/mfccValues.pkl', 'rb') as f:  \n",
    "        values = pickle.load(f)\n",
    "    \n",
    "    #name format of the selected data\n",
    "    name = 'variables/mfccDict[nC='+str(values[selected][0])+' wL='+str(values[selected][2])+' wS='+str(values[selected][3])+'].pkl'\n",
    "    \n",
    "    #saving in usedDict of the mfcc dict\n",
    "    with open(name, 'rb') as f: \n",
    "        usedDict = pickle.load(f)\n",
    "    print('Loaded '+name)\n",
    "\n",
    "elif choice == 'spectro':\n",
    "    \n",
    "    #saving in usedDict of the spectro dict\n",
    "    with open('variables/spectroDict.pkl', 'rb') as f:  \n",
    "        usedDict = pickle.load(f)\n",
    "    print('Loaded spectroram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#core words of the dataset\n",
    "coreKey = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"zero\",\n",
    "           \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
    "\n",
    "#split of the core set\n",
    "numbers = {'one', 'two', 'three','four','five','six','seven','eight','nine'}\n",
    "words = {\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"zero\"}\n",
    "\n",
    "test = [\"yes\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"zero\",\n",
    "           \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
    "\n",
    "#selecting the subset of words\n",
    "used = coreKey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione dataset non k-center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler found\n",
      "Data scaled\n"
     ]
    }
   ],
   "source": [
    "#divding between\n",
    "x_train, y_train, x_test, y_test = train_test_creator({k: usedDict[k] for k in usedDict.keys() & used })\n",
    "#find the scaler on train\n",
    "scaler = findScaler(x_train, 'robust')\n",
    "#print(scaler.mean_,' ',scaler.var_)\n",
    "print('Scaler found')\n",
    "#scale data\n",
    "scale(x_train, scaler)\n",
    "scale(x_test, scaler)\n",
    "print('Data scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A' mejo rete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 95, 10, 64)        1344      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 95, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 31, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 31, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 28, 4, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 28, 4, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 25, 2, 256)        196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 25, 2, 256)        1024      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 25, 2, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 5, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               256100    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 20)                2020      \n",
      "=================================================================\n",
      "Total params: 491,096\n",
      "Trainable params: 490,128\n",
      "Non-trainable params: 968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "\n",
    "cnn.add(Convolution2D(64, (5,4),  strides = (1,1), padding=\"valid\",  activation=\"softplus\",\n",
    "                      input_shape=(x_train.shape[1], x_train.shape[2],1)))\n",
    "cnn.add(BatchNormalization())\n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size=(3,2)))\n",
    "cnn.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "cnn.add(Convolution2D(64, (4,2),  strides = (1,1), padding=\"valid\", activation=\"softplus\"))\n",
    "cnn.add(BatchNormalization())\n",
    "\n",
    "cnn.add(Convolution2D(256, (4,3),  strides = (1,1), padding=\"valid\", activation=\"softplus\"))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(MaxPooling2D(pool_size=(5,1)))\n",
    "\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(100, activation=\"softplus\"))\n",
    "cnn.add(Dropout(0.7))\n",
    "cnn.add(BatchNormalization())\n",
    "\n",
    "cnn.add(Dense(y_train.shape[1], activation=\"sigmoid\"))\n",
    "\n",
    "# define optimizer and objective, compile cnn\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37878 samples, validate on 9470 samples\n",
      "Epoch 1/40\n",
      "37878/37878 [==============================] - 10s 256us/step - loss: 2.5427 - acc: 0.2826 - val_loss: 2.0092 - val_acc: 0.5846\n",
      "Epoch 2/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 1.6939 - acc: 0.5318 - val_loss: 1.1025 - val_acc: 0.6704\n",
      "Epoch 3/40\n",
      "37878/37878 [==============================] - 8s 216us/step - loss: 0.9944 - acc: 0.7170 - val_loss: 0.5620 - val_acc: 0.8579\n",
      "Epoch 4/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.7224 - acc: 0.7965 - val_loss: 0.4035 - val_acc: 0.8908\n",
      "Epoch 5/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.5901 - acc: 0.8359 - val_loss: 0.3165 - val_acc: 0.9137\n",
      "Epoch 6/40\n",
      "37878/37878 [==============================] - 8s 218us/step - loss: 0.5076 - acc: 0.8587 - val_loss: 0.2715 - val_acc: 0.9285\n",
      "Epoch 7/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.4591 - acc: 0.8719 - val_loss: 0.2639 - val_acc: 0.9238\n",
      "Epoch 8/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.4126 - acc: 0.8849 - val_loss: 0.2673 - val_acc: 0.9247\n",
      "Epoch 9/40\n",
      "37878/37878 [==============================] - 8s 224us/step - loss: 0.3917 - acc: 0.8911 - val_loss: 0.2224 - val_acc: 0.9379\n",
      "Epoch 10/40\n",
      "37878/37878 [==============================] - 8s 220us/step - loss: 0.3587 - acc: 0.9013 - val_loss: 0.2102 - val_acc: 0.9395\n",
      "Epoch 11/40\n",
      "37878/37878 [==============================] - 8s 218us/step - loss: 0.3349 - acc: 0.9045 - val_loss: 0.2068 - val_acc: 0.9386\n",
      "Epoch 12/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.3157 - acc: 0.9114 - val_loss: 0.2003 - val_acc: 0.9401\n",
      "Epoch 13/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.3007 - acc: 0.9137 - val_loss: 0.1994 - val_acc: 0.9400\n",
      "Epoch 14/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.2911 - acc: 0.9170 - val_loss: 0.1933 - val_acc: 0.9429\n",
      "Epoch 15/40\n",
      "37878/37878 [==============================] - 8s 218us/step - loss: 0.2781 - acc: 0.9200 - val_loss: 0.1875 - val_acc: 0.9447\n",
      "Epoch 16/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.2682 - acc: 0.9228 - val_loss: 0.1871 - val_acc: 0.9467\n",
      "Epoch 17/40\n",
      "37878/37878 [==============================] - 8s 219us/step - loss: 0.2624 - acc: 0.9227 - val_loss: 0.1902 - val_acc: 0.9439\n",
      "Epoch 18/40\n",
      "37878/37878 [==============================] - 9s 230us/step - loss: 0.2574 - acc: 0.9248 - val_loss: 0.1806 - val_acc: 0.9456\n",
      "Epoch 19/40\n",
      "37878/37878 [==============================] - 8s 219us/step - loss: 0.2485 - acc: 0.9267 - val_loss: 0.1920 - val_acc: 0.9444\n",
      "Epoch 20/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.2414 - acc: 0.9300 - val_loss: 0.1915 - val_acc: 0.9465\n",
      "Epoch 21/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.2291 - acc: 0.9323 - val_loss: 0.1763 - val_acc: 0.9480\n",
      "Epoch 22/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.2273 - acc: 0.9326 - val_loss: 0.1854 - val_acc: 0.9465\n",
      "Epoch 23/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.2234 - acc: 0.9338 - val_loss: 0.1955 - val_acc: 0.9438\n",
      "Epoch 24/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.2155 - acc: 0.9363 - val_loss: 0.1807 - val_acc: 0.9487\n",
      "Epoch 25/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.2151 - acc: 0.9356 - val_loss: 0.1802 - val_acc: 0.9506\n",
      "Epoch 26/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.2041 - acc: 0.9392 - val_loss: 0.1811 - val_acc: 0.9484\n",
      "Epoch 27/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.2024 - acc: 0.9401 - val_loss: 0.1806 - val_acc: 0.9493\n",
      "Epoch 28/40\n",
      "37878/37878 [==============================] - 8s 216us/step - loss: 0.2012 - acc: 0.9408 - val_loss: 0.1963 - val_acc: 0.9455\n",
      "Epoch 29/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.1970 - acc: 0.9416 - val_loss: 0.1834 - val_acc: 0.9487\n",
      "Epoch 30/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.1942 - acc: 0.9427 - val_loss: 0.1778 - val_acc: 0.9498\n",
      "Epoch 31/40\n",
      "37878/37878 [==============================] - 8s 218us/step - loss: 0.1887 - acc: 0.9433 - val_loss: 0.1720 - val_acc: 0.9533\n",
      "Epoch 32/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.1884 - acc: 0.9428 - val_loss: 0.1735 - val_acc: 0.9531\n",
      "Epoch 33/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.1837 - acc: 0.9442 - val_loss: 0.1811 - val_acc: 0.9510\n",
      "Epoch 34/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.1809 - acc: 0.9450 - val_loss: 0.1733 - val_acc: 0.9533\n",
      "Epoch 35/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.1769 - acc: 0.9473 - val_loss: 0.1797 - val_acc: 0.9511\n",
      "Epoch 36/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.1732 - acc: 0.9478 - val_loss: 0.1873 - val_acc: 0.9505\n",
      "Epoch 37/40\n",
      "37878/37878 [==============================] - 8s 218us/step - loss: 0.1662 - acc: 0.9499 - val_loss: 0.1817 - val_acc: 0.9516\n",
      "Epoch 38/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.1648 - acc: 0.9492 - val_loss: 0.1748 - val_acc: 0.9537\n",
      "Epoch 39/40\n",
      "37878/37878 [==============================] - 8s 217us/step - loss: 0.1661 - acc: 0.9499 - val_loss: 0.1723 - val_acc: 0.9537\n",
      "Epoch 40/40\n",
      "37878/37878 [==============================] - 8s 218us/step - loss: 0.1675 - acc: 0.9501 - val_loss: 0.1819 - val_acc: 0.9504\n"
     ]
    }
   ],
   "source": [
    "epoch = 40\n",
    "compiled = cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "fitted = cnn.fit(x_train, y_train, epochs=epoch, validation_data=(x_test, y_test), batch_size=round(x_train.shape[0]/250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ef66c1cd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9470/9470 [==============================] - 1s 123us/step\n",
      "Precision:  95.04 %\n"
     ]
    }
   ],
   "source": [
    "#find prediction with test data\n",
    "preds = cnn.predict(x_test)\n",
    "print(list(used))\n",
    "\n",
    "#plot confusion matrix\n",
    "plotConfusionMatrix(preds,y_test,list(used))\n",
    "loss, precision = cnn.evaluate(x_test,y_test)\n",
    "print (\"Precision: \", round(precision*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ee3eaa22b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = range(epoch)\n",
    "for key in fitted.history:\n",
    "    ax.plot(x,fitted.history[key],label=key)\n",
    "legend = ax.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "for label in legend.get_texts():\n",
    "    label.set_fontsize('large')\n",
    "\n",
    "for label in legend.get_lines():\n",
    "    label.set_linewidth(1.5)  # the legend line width\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_directory = 'model_backup/'\n",
    "if not os.path.exists(dest_directory):\n",
    "      os.makedirs(dest_directory)\n",
    "name = 'cnn.bak'\n",
    "cnn.save(dest_directory + name)\n",
    "\n",
    "#bak = load_model(dest_directory + name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data():\n",
    "    #load used data\n",
    "    with open('variables/train_test_split.pkl', 'rb') as f: \n",
    "        x_train = pickle.load(f)\n",
    "        y_train = pickle.load(f)\n",
    "        x_test = pickle.load(f)\n",
    "        y_test = pickle.load(f) \n",
    "    return x_train, y_train, x_test, y_test \n",
    "\n",
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    cnn = Sequential()\n",
    "    input_shape = (1, x_train.shape[2], x_train.shape[3])\n",
    "    cnn.add(Convolution2D({{choice([32,64,128])}}, (5,4),  strides = (1,1), padding=\"valid\", input_shape=input_shape))\n",
    "    cnn.add(Activation(\"softplus\"))\n",
    "    cnn.add(MaxPooling2D(pool_size=(3,2)))\n",
    "    cnn.add(Dropout({{uniform(0, 1)}}))\n",
    "\n",
    "    cnn.add(Convolution2D({{choice([64,128,256])}}, (4,2),  strides = (1,1), padding=\"valid\"))\n",
    "    cnn.add(Activation(\"softplus\"))\n",
    "    cnn.add(Convolution2D({{choice([64,128,256])}}, (4,3),  strides = (1,1), padding=\"valid\"))\n",
    "    cnn.add(Activation(\"softplus\"))\n",
    "    cnn.add(MaxPooling2D(pool_size=(5,1)))\n",
    "    cnn.add(Dropout({{uniform(0, 1)}}))\n",
    "\n",
    "    cnn.add(Flatten())\n",
    "\n",
    "    cnn.add(Dense({{choice([60, 80, 100])}}))\n",
    "    cnn.add(Activation(\"softplus\"))\n",
    "    cnn.add(Dropout({{uniform(0, 1)}}))\n",
    "\n",
    "    cnn.add(Dense(y_train.shape[1]))\n",
    "    cnn.add(Activation({{choice(['softmax', 'sigmoid'])}}))\n",
    "    cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "            \n",
    "    cnn.fit(x_train, y_train,\n",
    "              batch_size={{choice([128, 256])}},\n",
    "              epochs=10,\n",
    "              verbose=2,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score, acc = cnn.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': cnn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import sys\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pickle\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from glob import glob\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.decomposition import PCA\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import normalize\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.activations import softmax\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential, load_model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Activation, Flatten, Dropout, Convolution2D, MaxPooling2D, AveragePooling2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import SGD\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import sys\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os.path\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Convolution2D': hp.choice('Convolution2D', [16,32,64]),\n",
      "        'Dropout': hp.uniform('Dropout', 0, .5),\n",
      "        'Convolution2D_1': hp.choice('Convolution2D_1', [32,64,128]),\n",
      "        'Convolution2D_2': hp.choice('Convolution2D_2', [64,128,256]),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, .5),\n",
      "        'Dense': hp.choice('Dense', [40, 60, 80, 100]),\n",
      "        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n",
      "        'conditional': hp.choice('conditional', ['three', 'four']),\n",
      "        'Dense_1': hp.choice('Dense_1', [20, 30, 40]),\n",
      "        'Dropout_3': hp.uniform('Dropout_3', 0, .5),\n",
      "        'Activation': hp.choice('Activation', ['softmax', 'sigmoid']),\n",
      "        'batch_size': hp.choice('batch_size', [128, 256]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: with open('variables/train_test_split.pkl', 'rb') as f: \n",
      "  3:     x_train = pickle.load(f)\n",
      "  4:     y_train = pickle.load(f)\n",
      "  5:     x_test = pickle.load(f)\n",
      "  6:     y_test = pickle.load(f) \n",
      "  7: \n",
      "  8: \n",
      "  9: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     cnn = Sequential()\n",
      "   4:     input_shape = (1, x_train.shape[2], x_train.shape[3])\n",
      "   5:     cnn.add(Convolution2D(space['Convolution2D'], (5,4),  strides = (1,1), padding=\"valid\", input_shape=input_shape))\n",
      "   6:     cnn.add(Activation(\"softplus\"))\n",
      "   7:     cnn.add(MaxPooling2D(pool_size=(3,2)))\n",
      "   8:     cnn.add(Dropout(space['Dropout']))\n",
      "   9: \n",
      "  10:     cnn.add(Convolution2D(space['Convolution2D_1'], (4,2),  strides = (1,1), padding=\"valid\"))\n",
      "  11:     cnn.add(Activation(\"softplus\"))\n",
      "  12:     cnn.add(Convolution2D(space['Convolution2D_2'], (4,3),  strides = (1,1), padding=\"valid\"))\n",
      "  13:     cnn.add(Activation(\"softplus\"))\n",
      "  14:     cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
      "  15:     cnn.add(Dropout(space['Dropout_1']))\n",
      "  16: \n",
      "  17:     cnn.add(Flatten())\n",
      "  18: \n",
      "  19:     cnn.add(Dense(space['Dense']))\n",
      "  20:     cnn.add(Activation(\"softplus\"))\n",
      "  21:     cnn.add(Dropout(space['Dropout_2']))\n",
      "  22:             \n",
      "  23:     if conditional(space['conditional']) == 'four':\n",
      "  24:         cnn.add(Dense(space['Dense_1']))\n",
      "  25:         cnn.add(Activation(\"softplus\"))\n",
      "  26:         cnn.add(Dropout(space['Dropout_3']))\n",
      "  27: \n",
      "  28:     cnn.add(Dense(y_train.shape[1]))\n",
      "  29:     cnn.add(Activation(space['Activation']))\n",
      "  30:     cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adamax\", metrics=['accuracy'])\n",
      "  31:             \n",
      "  32:     cnn.fit(x_train, y_train,\n",
      "  33:               batch_size=space['batch_size'],\n",
      "  34:               epochs=40,\n",
      "  35:               verbose=2,\n",
      "  36:               validation_data=(x_test, y_test))\n",
      "  37:     score, acc = cnn.evaluate(x_test, y_test, verbose=0)\n",
      "  38:     print('Test accuracy:', acc)\n",
      "  39:     return {'loss': -acc, 'status': STATUS_OK, 'model': cnn}\n",
      "  40: \n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 3s - loss: 2.5532 - acc: 0.0885 - val_loss: 2.3976 - val_acc: 0.0877\n",
      "Epoch 2/40\n",
      " - 2s - loss: 2.3977 - acc: 0.0913 - val_loss: 2.3953 - val_acc: 0.0877\n",
      "Epoch 3/40\n",
      " - 2s - loss: 2.3972 - acc: 0.0995 - val_loss: 2.3937 - val_acc: 0.0884\n",
      "Epoch 4/40\n",
      " - 2s - loss: 2.3967 - acc: 0.1007 - val_loss: 2.3875 - val_acc: 0.1119\n",
      "Epoch 5/40\n",
      " - 2s - loss: 2.3935 - acc: 0.1017 - val_loss: 2.3668 - val_acc: 0.1378\n",
      "Epoch 6/40\n",
      " - 2s - loss: 2.3803 - acc: 0.1112 - val_loss: 2.3416 - val_acc: 0.1642\n",
      "Epoch 7/40\n",
      " - 2s - loss: 2.3633 - acc: 0.1179 - val_loss: 2.2945 - val_acc: 0.1719\n",
      "Epoch 8/40\n",
      " - 2s - loss: 2.3330 - acc: 0.1324 - val_loss: 2.2083 - val_acc: 0.2517\n",
      "Epoch 9/40\n",
      " - 2s - loss: 2.2698 - acc: 0.1624 - val_loss: 2.0943 - val_acc: 0.2968\n",
      "Epoch 10/40\n",
      " - 2s - loss: 2.1908 - acc: 0.2037 - val_loss: 1.9504 - val_acc: 0.3745\n",
      "Epoch 11/40\n",
      " - 2s - loss: 2.0769 - acc: 0.2603 - val_loss: 1.6930 - val_acc: 0.4398\n",
      "Epoch 12/40\n",
      " - 2s - loss: 1.9190 - acc: 0.3223 - val_loss: 1.4791 - val_acc: 0.5384\n",
      "Epoch 13/40\n",
      " - 2s - loss: 1.7923 - acc: 0.3807 - val_loss: 1.3005 - val_acc: 0.5837\n",
      "Epoch 14/40\n",
      " - 2s - loss: 1.6516 - acc: 0.4251 - val_loss: 1.1444 - val_acc: 0.6353\n",
      "Epoch 15/40\n",
      " - 2s - loss: 1.5387 - acc: 0.4676 - val_loss: 0.9825 - val_acc: 0.7026\n",
      "Epoch 16/40\n",
      " - 2s - loss: 1.4610 - acc: 0.5043 - val_loss: 0.9640 - val_acc: 0.7216\n",
      "Epoch 17/40\n",
      " - 2s - loss: 1.3572 - acc: 0.5384 - val_loss: 0.8493 - val_acc: 0.7500\n",
      "Epoch 18/40\n",
      " - 2s - loss: 1.2916 - acc: 0.5620 - val_loss: 0.8000 - val_acc: 0.7602\n",
      "Epoch 19/40\n",
      " - 2s - loss: 1.2214 - acc: 0.5820 - val_loss: 0.7397 - val_acc: 0.7843\n",
      "Epoch 20/40\n",
      " - 2s - loss: 1.1768 - acc: 0.5988 - val_loss: 0.6918 - val_acc: 0.7980\n",
      "Epoch 21/40\n",
      " - 2s - loss: 1.1366 - acc: 0.6117 - val_loss: 0.6762 - val_acc: 0.7983\n",
      "Epoch 22/40\n",
      " - 2s - loss: 1.0797 - acc: 0.6379 - val_loss: 0.6242 - val_acc: 0.8131\n",
      "Epoch 23/40\n",
      " - 2s - loss: 1.0480 - acc: 0.6477 - val_loss: 0.5884 - val_acc: 0.8225\n",
      "Epoch 24/40\n",
      " - 2s - loss: 1.0256 - acc: 0.6588 - val_loss: 0.5376 - val_acc: 0.8377\n",
      "Epoch 25/40\n",
      " - 2s - loss: 0.9788 - acc: 0.6723 - val_loss: 0.5183 - val_acc: 0.8432\n",
      "Epoch 26/40\n",
      " - 2s - loss: 0.9484 - acc: 0.6801 - val_loss: 0.5139 - val_acc: 0.8455\n",
      "Epoch 27/40\n",
      " - 2s - loss: 0.9156 - acc: 0.6931 - val_loss: 0.4749 - val_acc: 0.8584\n",
      "Epoch 28/40\n",
      " - 2s - loss: 0.9028 - acc: 0.6970 - val_loss: 0.4680 - val_acc: 0.8586\n",
      "Epoch 29/40\n",
      " - 2s - loss: 0.8819 - acc: 0.7044 - val_loss: 0.4643 - val_acc: 0.8582\n",
      "Epoch 30/40\n",
      " - 2s - loss: 0.8660 - acc: 0.7073 - val_loss: 0.4523 - val_acc: 0.8674\n",
      "Epoch 31/40\n",
      " - 2s - loss: 0.8329 - acc: 0.7195 - val_loss: 0.4360 - val_acc: 0.8682\n",
      "Epoch 32/40\n",
      " - 2s - loss: 0.8190 - acc: 0.7237 - val_loss: 0.4047 - val_acc: 0.8784\n",
      "Epoch 33/40\n",
      " - 2s - loss: 0.7978 - acc: 0.7353 - val_loss: 0.3952 - val_acc: 0.8818\n",
      "Epoch 34/40\n",
      " - 2s - loss: 0.7787 - acc: 0.7394 - val_loss: 0.3905 - val_acc: 0.8828\n",
      "Epoch 35/40\n",
      " - 2s - loss: 0.7622 - acc: 0.7446 - val_loss: 0.3777 - val_acc: 0.8849\n",
      "Epoch 36/40\n",
      " - 2s - loss: 0.7569 - acc: 0.7479 - val_loss: 0.3748 - val_acc: 0.8841\n",
      "Epoch 37/40\n",
      " - 2s - loss: 0.7541 - acc: 0.7506 - val_loss: 0.3656 - val_acc: 0.8881\n",
      "Epoch 38/40\n",
      " - 2s - loss: 0.7224 - acc: 0.7574 - val_loss: 0.3655 - val_acc: 0.8858\n",
      "Epoch 39/40\n",
      " - 2s - loss: 0.7141 - acc: 0.7608 - val_loss: 0.3573 - val_acc: 0.8901\n",
      "Epoch 40/40\n",
      " - 2s - loss: 0.7050 - acc: 0.7639 - val_loss: 0.3392 - val_acc: 0.8924\n",
      "Test accuracy: 0.892363775856021\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 2s - loss: 2.5455 - acc: 0.0974 - val_loss: 2.3728 - val_acc: 0.2218\n",
      "Epoch 2/40\n",
      " - 2s - loss: 2.3495 - acc: 0.1298 - val_loss: 2.2290 - val_acc: 0.2517\n",
      "Epoch 3/40\n",
      " - 2s - loss: 2.2647 - acc: 0.1563 - val_loss: 2.1221 - val_acc: 0.2795\n",
      "Epoch 4/40\n",
      " - 2s - loss: 2.1938 - acc: 0.1828 - val_loss: 2.0355 - val_acc: 0.3526\n",
      "Epoch 5/40\n",
      " - 2s - loss: 2.1317 - acc: 0.2102 - val_loss: 1.9619 - val_acc: 0.4123\n",
      "Epoch 6/40\n",
      " - 2s - loss: 2.0627 - acc: 0.2357 - val_loss: 1.8850 - val_acc: 0.4536\n",
      "Epoch 7/40\n",
      " - 2s - loss: 1.9837 - acc: 0.2639 - val_loss: 1.7145 - val_acc: 0.5274\n",
      "Epoch 8/40\n",
      " - 2s - loss: 1.8565 - acc: 0.3276 - val_loss: 1.4979 - val_acc: 0.6080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40\n",
      " - 2s - loss: 1.7344 - acc: 0.3794 - val_loss: 1.2899 - val_acc: 0.6942\n",
      "Epoch 10/40\n",
      " - 2s - loss: 1.5901 - acc: 0.4345 - val_loss: 1.1033 - val_acc: 0.7364\n",
      "Epoch 11/40\n",
      " - 2s - loss: 1.4845 - acc: 0.4744 - val_loss: 0.9851 - val_acc: 0.7665\n",
      "Epoch 12/40\n",
      " - 2s - loss: 1.3710 - acc: 0.5214 - val_loss: 0.8542 - val_acc: 0.7855\n",
      "Epoch 13/40\n",
      " - 2s - loss: 1.2582 - acc: 0.5582 - val_loss: 0.7552 - val_acc: 0.8010\n",
      "Epoch 14/40\n",
      " - 2s - loss: 1.1839 - acc: 0.5877 - val_loss: 0.6614 - val_acc: 0.8198\n",
      "Epoch 15/40\n",
      " - 2s - loss: 1.0875 - acc: 0.6210 - val_loss: 0.6244 - val_acc: 0.8183\n",
      "Epoch 16/40\n",
      " - 2s - loss: 1.0399 - acc: 0.6389 - val_loss: 0.5424 - val_acc: 0.8477\n",
      "Epoch 17/40\n",
      " - 2s - loss: 0.9572 - acc: 0.6692 - val_loss: 0.5030 - val_acc: 0.8540\n",
      "Epoch 18/40\n",
      " - 2s - loss: 0.9139 - acc: 0.6906 - val_loss: 0.4643 - val_acc: 0.8634\n",
      "Epoch 19/40\n",
      " - 2s - loss: 0.8753 - acc: 0.7030 - val_loss: 0.4593 - val_acc: 0.8605\n",
      "Epoch 20/40\n",
      " - 2s - loss: 0.8408 - acc: 0.7122 - val_loss: 0.4433 - val_acc: 0.8640\n",
      "Epoch 21/40\n",
      " - 2s - loss: 0.7996 - acc: 0.7295 - val_loss: 0.4214 - val_acc: 0.8695\n",
      "Epoch 22/40\n",
      " - 2s - loss: 0.7726 - acc: 0.7370 - val_loss: 0.3890 - val_acc: 0.8822\n",
      "Epoch 23/40\n",
      " - 2s - loss: 0.7490 - acc: 0.7506 - val_loss: 0.3708 - val_acc: 0.8856\n",
      "Epoch 24/40\n",
      " - 2s - loss: 0.7122 - acc: 0.7596 - val_loss: 0.3642 - val_acc: 0.8889\n",
      "Epoch 25/40\n",
      " - 2s - loss: 0.6958 - acc: 0.7676 - val_loss: 0.3438 - val_acc: 0.8956\n",
      "Epoch 26/40\n",
      " - 2s - loss: 0.6690 - acc: 0.7735 - val_loss: 0.3213 - val_acc: 0.9008\n",
      "Epoch 27/40\n",
      " - 2s - loss: 0.6571 - acc: 0.7749 - val_loss: 0.3244 - val_acc: 0.8985\n",
      "Epoch 28/40\n",
      " - 2s - loss: 0.6300 - acc: 0.7863 - val_loss: 0.3231 - val_acc: 0.9062\n",
      "Epoch 29/40\n",
      " - 2s - loss: 0.6202 - acc: 0.7918 - val_loss: 0.3004 - val_acc: 0.9060\n",
      "Epoch 30/40\n",
      " - 2s - loss: 0.6102 - acc: 0.7963 - val_loss: 0.3115 - val_acc: 0.9012\n",
      "Epoch 31/40\n",
      " - 2s - loss: 0.5859 - acc: 0.8032 - val_loss: 0.3059 - val_acc: 0.9033\n",
      "Epoch 32/40\n",
      " - 2s - loss: 0.5738 - acc: 0.8093 - val_loss: 0.2864 - val_acc: 0.9087\n",
      "Epoch 33/40\n",
      " - 2s - loss: 0.5563 - acc: 0.8129 - val_loss: 0.2856 - val_acc: 0.9102\n",
      "Epoch 34/40\n",
      " - 2s - loss: 0.5573 - acc: 0.8131 - val_loss: 0.3083 - val_acc: 0.9104\n",
      "Epoch 35/40\n",
      " - 2s - loss: 0.5378 - acc: 0.8232 - val_loss: 0.3005 - val_acc: 0.9029\n",
      "Epoch 36/40\n",
      " - 2s - loss: 0.5256 - acc: 0.8248 - val_loss: 0.2601 - val_acc: 0.9208\n",
      "Epoch 37/40\n",
      " - 2s - loss: 0.5086 - acc: 0.8313 - val_loss: 0.2673 - val_acc: 0.9163\n",
      "Epoch 38/40\n",
      " - 2s - loss: 0.5132 - acc: 0.8300 - val_loss: 0.2798 - val_acc: 0.9137\n",
      "Epoch 39/40\n",
      " - 2s - loss: 0.5027 - acc: 0.8365 - val_loss: 0.2757 - val_acc: 0.9171\n",
      "Epoch 40/40\n",
      " - 2s - loss: 0.4877 - acc: 0.8412 - val_loss: 0.2608 - val_acc: 0.9175\n",
      "Test accuracy: 0.9174980812134966\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 3s - loss: 2.7430 - acc: 0.0876 - val_loss: 2.5183 - val_acc: 0.0894\n",
      "Epoch 2/40\n",
      " - 2s - loss: 2.4504 - acc: 0.0898 - val_loss: 2.4003 - val_acc: 0.0894\n",
      "Epoch 3/40\n",
      " - 2s - loss: 2.4146 - acc: 0.0914 - val_loss: 2.3990 - val_acc: 0.0894\n",
      "Epoch 4/40\n",
      " - 2s - loss: 2.4108 - acc: 0.0924 - val_loss: 2.3987 - val_acc: 0.0894\n",
      "Epoch 5/40\n",
      " - 2s - loss: 2.4075 - acc: 0.0933 - val_loss: 2.3988 - val_acc: 0.0886\n",
      "Epoch 6/40\n",
      " - 2s - loss: 2.4098 - acc: 0.0901 - val_loss: 2.3986 - val_acc: 0.0846\n",
      "Epoch 7/40\n",
      " - 2s - loss: 2.4104 - acc: 0.0889 - val_loss: 2.3984 - val_acc: 0.0850\n",
      "Epoch 8/40\n",
      " - 2s - loss: 2.4073 - acc: 0.0922 - val_loss: 2.3985 - val_acc: 0.0846\n",
      "Epoch 9/40\n",
      " - 2s - loss: 2.4088 - acc: 0.0910 - val_loss: 2.3983 - val_acc: 0.0890\n",
      "Epoch 10/40\n",
      " - 2s - loss: 2.4062 - acc: 0.0919 - val_loss: 2.3984 - val_acc: 0.0902\n",
      "Epoch 11/40\n",
      " - 2s - loss: 2.4061 - acc: 0.0915 - val_loss: 2.3985 - val_acc: 0.0952\n",
      "Epoch 12/40\n",
      " - 2s - loss: 2.4050 - acc: 0.0903 - val_loss: 2.3984 - val_acc: 0.0846\n",
      "Epoch 13/40\n",
      " - 2s - loss: 2.4064 - acc: 0.0877 - val_loss: 2.3984 - val_acc: 0.0846\n",
      "Epoch 14/40\n",
      " - 2s - loss: 2.4055 - acc: 0.0899 - val_loss: 2.3979 - val_acc: 0.1003\n",
      "Epoch 15/40\n",
      " - 2s - loss: 2.4051 - acc: 0.0877 - val_loss: 2.3983 - val_acc: 0.0846\n",
      "Epoch 16/40\n",
      " - 2s - loss: 2.4032 - acc: 0.0930 - val_loss: 2.3965 - val_acc: 0.0944\n",
      "Epoch 17/40\n",
      " - 2s - loss: 2.4047 - acc: 0.0863 - val_loss: 2.3986 - val_acc: 0.0894\n",
      "Epoch 18/40\n",
      " - 2s - loss: 2.4041 - acc: 0.0878 - val_loss: 2.3982 - val_acc: 0.0846\n",
      "Epoch 19/40\n",
      " - 2s - loss: 2.4021 - acc: 0.0920 - val_loss: 2.3970 - val_acc: 0.0980\n",
      "Epoch 20/40\n",
      " - 2s - loss: 2.4013 - acc: 0.0938 - val_loss: 2.3985 - val_acc: 0.1092\n",
      "Epoch 21/40\n",
      " - 2s - loss: 2.4013 - acc: 0.0915 - val_loss: 2.3987 - val_acc: 0.0894\n",
      "Epoch 22/40\n",
      " - 2s - loss: 2.4023 - acc: 0.0910 - val_loss: 2.3979 - val_acc: 0.0894\n",
      "Epoch 23/40\n",
      " - 2s - loss: 2.4009 - acc: 0.0916 - val_loss: 2.3981 - val_acc: 0.1105\n",
      "Epoch 24/40\n",
      " - 2s - loss: 2.4005 - acc: 0.0928 - val_loss: 2.3980 - val_acc: 0.0877\n",
      "Epoch 25/40\n",
      " - 2s - loss: 2.4024 - acc: 0.0880 - val_loss: 2.3967 - val_acc: 0.1082\n",
      "Epoch 26/40\n",
      " - 2s - loss: 2.4001 - acc: 0.0953 - val_loss: 2.3960 - val_acc: 0.1207\n",
      "Epoch 27/40\n",
      " - 2s - loss: 2.3994 - acc: 0.0933 - val_loss: 2.3969 - val_acc: 0.1356\n",
      "Epoch 28/40\n",
      " - 2s - loss: 2.3996 - acc: 0.0914 - val_loss: 2.3899 - val_acc: 0.0892\n",
      "Epoch 29/40\n",
      " - 2s - loss: 2.4003 - acc: 0.0916 - val_loss: 2.3915 - val_acc: 0.0854\n",
      "Epoch 30/40\n",
      " - 2s - loss: 2.4005 - acc: 0.0901 - val_loss: 2.3906 - val_acc: 0.0719\n",
      "Epoch 31/40\n",
      " - 2s - loss: 2.3975 - acc: 0.0941 - val_loss: 2.3786 - val_acc: 0.1274\n",
      "Epoch 32/40\n",
      " - 2s - loss: 2.3947 - acc: 0.0961 - val_loss: 2.3720 - val_acc: 0.0959\n",
      "Epoch 33/40\n",
      " - 2s - loss: 2.3908 - acc: 0.1006 - val_loss: 2.3549 - val_acc: 0.1999\n",
      "Epoch 34/40\n",
      " - 2s - loss: 2.3914 - acc: 0.1049 - val_loss: 2.3292 - val_acc: 0.1322\n",
      "Epoch 35/40\n",
      " - 2s - loss: 2.3827 - acc: 0.1069 - val_loss: 2.3379 - val_acc: 0.1289\n",
      "Epoch 36/40\n",
      " - 2s - loss: 2.3795 - acc: 0.1109 - val_loss: 2.3066 - val_acc: 0.1253\n",
      "Epoch 37/40\n",
      " - 2s - loss: 2.3689 - acc: 0.1104 - val_loss: 2.2924 - val_acc: 0.1209\n",
      "Epoch 38/40\n",
      " - 2s - loss: 2.3651 - acc: 0.1183 - val_loss: 2.2804 - val_acc: 0.1328\n",
      "Epoch 39/40\n",
      " - 2s - loss: 2.3522 - acc: 0.1209 - val_loss: 2.2676 - val_acc: 0.1358\n",
      "Epoch 40/40\n",
      " - 2s - loss: 2.3429 - acc: 0.1246 - val_loss: 2.2405 - val_acc: 0.1416\n",
      "Test accuracy: 0.14159631622770796\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 2s - loss: 2.4626 - acc: 0.0947 - val_loss: 2.3935 - val_acc: 0.1065\n",
      "Epoch 2/40\n",
      " - 2s - loss: 2.3777 - acc: 0.1209 - val_loss: 2.2593 - val_acc: 0.2456\n",
      "Epoch 3/40\n",
      " - 2s - loss: 2.2416 - acc: 0.2057 - val_loss: 2.0386 - val_acc: 0.3056\n",
      "Epoch 4/40\n",
      " - 2s - loss: 2.0954 - acc: 0.2601 - val_loss: 1.8533 - val_acc: 0.3805\n",
      "Epoch 5/40\n",
      " - 2s - loss: 1.9459 - acc: 0.3132 - val_loss: 1.6320 - val_acc: 0.4453\n",
      "Epoch 6/40\n",
      " - 2s - loss: 1.8002 - acc: 0.3619 - val_loss: 1.4752 - val_acc: 0.5075\n",
      "Epoch 7/40\n",
      " - 2s - loss: 1.6790 - acc: 0.4055 - val_loss: 1.3740 - val_acc: 0.5138\n",
      "Epoch 8/40\n",
      " - 2s - loss: 1.5698 - acc: 0.4334 - val_loss: 1.2191 - val_acc: 0.5706\n",
      "Epoch 9/40\n",
      " - 2s - loss: 1.4546 - acc: 0.4833 - val_loss: 1.1272 - val_acc: 0.5961\n",
      "Epoch 10/40\n",
      " - 2s - loss: 1.3430 - acc: 0.5205 - val_loss: 0.9563 - val_acc: 0.6823\n",
      "Epoch 11/40\n",
      " - 2s - loss: 1.2506 - acc: 0.5590 - val_loss: 0.8754 - val_acc: 0.7289\n",
      "Epoch 12/40\n",
      " - 2s - loss: 1.1725 - acc: 0.5917 - val_loss: 0.7929 - val_acc: 0.7500\n",
      "Epoch 13/40\n",
      " - 2s - loss: 1.0847 - acc: 0.6229 - val_loss: 0.6750 - val_acc: 0.7968\n",
      "Epoch 14/40\n",
      " - 2s - loss: 1.0150 - acc: 0.6497 - val_loss: 0.6180 - val_acc: 0.8133\n",
      "Epoch 15/40\n",
      " - 2s - loss: 0.9582 - acc: 0.6707 - val_loss: 0.5701 - val_acc: 0.8304\n",
      "Epoch 16/40\n",
      " - 2s - loss: 0.9087 - acc: 0.6934 - val_loss: 0.5365 - val_acc: 0.8394\n",
      "Epoch 17/40\n",
      " - 2s - loss: 0.8685 - acc: 0.7050 - val_loss: 0.5065 - val_acc: 0.8454\n",
      "Epoch 18/40\n",
      " - 2s - loss: 0.8310 - acc: 0.7260 - val_loss: 0.4821 - val_acc: 0.8498\n",
      "Epoch 19/40\n",
      " - 2s - loss: 0.7948 - acc: 0.7380 - val_loss: 0.4447 - val_acc: 0.8605\n",
      "Epoch 20/40\n",
      " - 2s - loss: 0.7736 - acc: 0.7471 - val_loss: 0.4245 - val_acc: 0.8720\n",
      "Epoch 21/40\n",
      " - 2s - loss: 0.7373 - acc: 0.7628 - val_loss: 0.4217 - val_acc: 0.8722\n",
      "Epoch 22/40\n",
      " - 2s - loss: 0.7120 - acc: 0.7713 - val_loss: 0.3923 - val_acc: 0.8810\n",
      "Epoch 23/40\n",
      " - 2s - loss: 0.6970 - acc: 0.7782 - val_loss: 0.3730 - val_acc: 0.8864\n",
      "Epoch 24/40\n",
      " - 2s - loss: 0.6674 - acc: 0.7854 - val_loss: 0.3655 - val_acc: 0.8851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/40\n",
      " - 2s - loss: 0.6301 - acc: 0.8017 - val_loss: 0.3596 - val_acc: 0.8883\n",
      "Epoch 26/40\n",
      " - 2s - loss: 0.6299 - acc: 0.8023 - val_loss: 0.3338 - val_acc: 0.8956\n",
      "Epoch 27/40\n",
      " - 2s - loss: 0.5980 - acc: 0.8098 - val_loss: 0.3231 - val_acc: 0.9027\n",
      "Epoch 28/40\n",
      " - 2s - loss: 0.5912 - acc: 0.8146 - val_loss: 0.3095 - val_acc: 0.9058\n",
      "Epoch 29/40\n",
      " - 2s - loss: 0.5780 - acc: 0.8197 - val_loss: 0.3313 - val_acc: 0.8939\n",
      "Epoch 30/40\n",
      " - 2s - loss: 0.5616 - acc: 0.8259 - val_loss: 0.3161 - val_acc: 0.9002\n",
      "Epoch 31/40\n",
      " - 2s - loss: 0.5585 - acc: 0.8257 - val_loss: 0.2994 - val_acc: 0.9075\n",
      "Epoch 32/40\n",
      " - 2s - loss: 0.5395 - acc: 0.8325 - val_loss: 0.3032 - val_acc: 0.9046\n",
      "Epoch 33/40\n",
      " - 2s - loss: 0.5350 - acc: 0.8360 - val_loss: 0.2918 - val_acc: 0.9100\n",
      "Epoch 34/40\n",
      " - 2s - loss: 0.5159 - acc: 0.8408 - val_loss: 0.2847 - val_acc: 0.9152\n",
      "Epoch 35/40\n",
      " - 2s - loss: 0.5150 - acc: 0.8394 - val_loss: 0.2756 - val_acc: 0.9177\n",
      "Epoch 36/40\n",
      " - 2s - loss: 0.5012 - acc: 0.8446 - val_loss: 0.3044 - val_acc: 0.9071\n",
      "Epoch 37/40\n",
      " - 2s - loss: 0.5024 - acc: 0.8459 - val_loss: 0.2776 - val_acc: 0.9177\n",
      "Epoch 38/40\n",
      " - 2s - loss: 0.4870 - acc: 0.8486 - val_loss: 0.2794 - val_acc: 0.9114\n",
      "Epoch 39/40\n",
      " - 2s - loss: 0.4727 - acc: 0.8566 - val_loss: 0.2652 - val_acc: 0.9215\n",
      "Epoch 40/40\n",
      " - 2s - loss: 0.4628 - acc: 0.8585 - val_loss: 0.2551 - val_acc: 0.9169\n",
      "Test accuracy: 0.9169224865237109\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 3s - loss: 2.3718 - acc: 0.1634 - val_loss: 1.8126 - val_acc: 0.3784\n",
      "Epoch 2/40\n",
      " - 2s - loss: 1.8554 - acc: 0.3365 - val_loss: 1.3628 - val_acc: 0.5478\n",
      "Epoch 3/40\n",
      " - 2s - loss: 1.5076 - acc: 0.4654 - val_loss: 1.0040 - val_acc: 0.6771\n",
      "Epoch 4/40\n",
      " - 2s - loss: 1.2026 - acc: 0.5721 - val_loss: 0.7782 - val_acc: 0.7540\n",
      "Epoch 5/40\n",
      " - 2s - loss: 1.0222 - acc: 0.6441 - val_loss: 0.6348 - val_acc: 0.8081\n",
      "Epoch 6/40\n",
      " - 2s - loss: 0.8787 - acc: 0.6950 - val_loss: 0.5623 - val_acc: 0.8246\n",
      "Epoch 7/40\n",
      " - 2s - loss: 0.7715 - acc: 0.7385 - val_loss: 0.4748 - val_acc: 0.8534\n",
      "Epoch 8/40\n",
      " - 2s - loss: 0.6865 - acc: 0.7744 - val_loss: 0.4385 - val_acc: 0.8582\n",
      "Epoch 9/40\n",
      " - 2s - loss: 0.6431 - acc: 0.7874 - val_loss: 0.3865 - val_acc: 0.8789\n",
      "Epoch 10/40\n",
      " - 2s - loss: 0.5912 - acc: 0.8073 - val_loss: 0.3450 - val_acc: 0.8935\n",
      "Epoch 11/40\n",
      " - 2s - loss: 0.5549 - acc: 0.8193 - val_loss: 0.3558 - val_acc: 0.8895\n",
      "Epoch 12/40\n",
      " - 2s - loss: 0.4951 - acc: 0.8382 - val_loss: 0.3138 - val_acc: 0.8987\n",
      "Epoch 13/40\n",
      " - 2s - loss: 0.4849 - acc: 0.8453 - val_loss: 0.2952 - val_acc: 0.9073\n",
      "Epoch 14/40\n",
      " - 2s - loss: 0.4447 - acc: 0.8573 - val_loss: 0.3017 - val_acc: 0.9066\n",
      "Epoch 15/40\n",
      " - 2s - loss: 0.4259 - acc: 0.8638 - val_loss: 0.2676 - val_acc: 0.9160\n",
      "Epoch 16/40\n",
      " - 2s - loss: 0.4135 - acc: 0.8664 - val_loss: 0.2749 - val_acc: 0.9137\n",
      "Epoch 17/40\n",
      " - 2s - loss: 0.3953 - acc: 0.8739 - val_loss: 0.2582 - val_acc: 0.9152\n",
      "Epoch 18/40\n",
      " - 2s - loss: 0.3660 - acc: 0.8834 - val_loss: 0.2687 - val_acc: 0.9152\n",
      "Epoch 19/40\n",
      " - 2s - loss: 0.3569 - acc: 0.8831 - val_loss: 0.2652 - val_acc: 0.9196\n",
      "Epoch 20/40\n",
      " - 2s - loss: 0.3407 - acc: 0.8916 - val_loss: 0.2562 - val_acc: 0.9215\n",
      "Epoch 21/40\n",
      " - 2s - loss: 0.3342 - acc: 0.8949 - val_loss: 0.2408 - val_acc: 0.9252\n",
      "Epoch 22/40\n",
      " - 2s - loss: 0.3153 - acc: 0.9024 - val_loss: 0.2469 - val_acc: 0.9225\n",
      "Epoch 23/40\n",
      " - 2s - loss: 0.3046 - acc: 0.9019 - val_loss: 0.2309 - val_acc: 0.9313\n",
      "Epoch 24/40\n",
      " - 2s - loss: 0.2985 - acc: 0.9032 - val_loss: 0.2361 - val_acc: 0.9282\n",
      "Epoch 25/40\n",
      " - 2s - loss: 0.2833 - acc: 0.9107 - val_loss: 0.2295 - val_acc: 0.9307\n",
      "Epoch 26/40\n",
      " - 2s - loss: 0.2831 - acc: 0.9093 - val_loss: 0.2295 - val_acc: 0.9311\n",
      "Epoch 27/40\n",
      " - 2s - loss: 0.2728 - acc: 0.9125 - val_loss: 0.2316 - val_acc: 0.9309\n",
      "Epoch 28/40\n",
      " - 2s - loss: 0.2586 - acc: 0.9167 - val_loss: 0.2229 - val_acc: 0.9313\n",
      "Epoch 29/40\n",
      " - 2s - loss: 0.2560 - acc: 0.9158 - val_loss: 0.2195 - val_acc: 0.9355\n",
      "Epoch 30/40\n",
      " - 2s - loss: 0.2401 - acc: 0.9205 - val_loss: 0.2375 - val_acc: 0.9315\n",
      "Epoch 31/40\n",
      " - 2s - loss: 0.2364 - acc: 0.9251 - val_loss: 0.2223 - val_acc: 0.9328\n",
      "Epoch 32/40\n",
      " - 2s - loss: 0.2249 - acc: 0.9276 - val_loss: 0.2384 - val_acc: 0.9327\n",
      "Epoch 33/40\n",
      " - 2s - loss: 0.2219 - acc: 0.9280 - val_loss: 0.2480 - val_acc: 0.9338\n",
      "Epoch 34/40\n",
      " - 2s - loss: 0.2246 - acc: 0.9290 - val_loss: 0.2250 - val_acc: 0.9373\n",
      "Epoch 35/40\n",
      " - 2s - loss: 0.2155 - acc: 0.9315 - val_loss: 0.2190 - val_acc: 0.9367\n",
      "Epoch 36/40\n",
      " - 2s - loss: 0.2097 - acc: 0.9326 - val_loss: 0.2123 - val_acc: 0.9384\n",
      "Epoch 37/40\n",
      " - 2s - loss: 0.2031 - acc: 0.9335 - val_loss: 0.2227 - val_acc: 0.9388\n",
      "Epoch 38/40\n",
      " - 2s - loss: 0.1976 - acc: 0.9347 - val_loss: 0.2455 - val_acc: 0.9319\n",
      "Epoch 39/40\n",
      " - 2s - loss: 0.1993 - acc: 0.9362 - val_loss: 0.2129 - val_acc: 0.9399\n",
      "Epoch 40/40\n",
      " - 2s - loss: 0.1956 - acc: 0.9362 - val_loss: 0.2145 - val_acc: 0.9375\n",
      "Test accuracy: 0.9374520338597155\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 3s - loss: 2.5382 - acc: 0.0968 - val_loss: 2.3978 - val_acc: 0.0865\n",
      "Epoch 2/40\n",
      " - 2s - loss: 2.3977 - acc: 0.1017 - val_loss: 2.3968 - val_acc: 0.1069\n",
      "Epoch 3/40\n",
      " - 2s - loss: 2.3926 - acc: 0.1046 - val_loss: 2.3805 - val_acc: 0.1462\n",
      "Epoch 4/40\n",
      " - 2s - loss: 2.3314 - acc: 0.1468 - val_loss: 2.1685 - val_acc: 0.3079\n",
      "Epoch 5/40\n",
      " - 2s - loss: 2.1513 - acc: 0.2285 - val_loss: 1.8359 - val_acc: 0.4315\n",
      "Epoch 6/40\n",
      " - 2s - loss: 1.9310 - acc: 0.3177 - val_loss: 1.5869 - val_acc: 0.5134\n",
      "Epoch 7/40\n",
      " - 2s - loss: 1.7637 - acc: 0.3794 - val_loss: 1.3867 - val_acc: 0.5965\n",
      "Epoch 8/40\n",
      " - 2s - loss: 1.6234 - acc: 0.4373 - val_loss: 1.2005 - val_acc: 0.6462\n",
      "Epoch 9/40\n",
      " - 2s - loss: 1.4852 - acc: 0.4908 - val_loss: 1.0141 - val_acc: 0.6988\n",
      "Epoch 10/40\n",
      " - 2s - loss: 1.3472 - acc: 0.5392 - val_loss: 0.8800 - val_acc: 0.7433\n",
      "Epoch 11/40\n",
      " - 2s - loss: 1.2181 - acc: 0.5815 - val_loss: 0.7860 - val_acc: 0.7728\n",
      "Epoch 12/40\n",
      " - 2s - loss: 1.1222 - acc: 0.6181 - val_loss: 0.7064 - val_acc: 0.7866\n",
      "Epoch 13/40\n",
      " - 2s - loss: 1.0528 - acc: 0.6412 - val_loss: 0.6392 - val_acc: 0.8149\n",
      "Epoch 14/40\n",
      " - 2s - loss: 0.9665 - acc: 0.6737 - val_loss: 0.5824 - val_acc: 0.8310\n",
      "Epoch 15/40\n",
      " - 2s - loss: 0.9202 - acc: 0.6947 - val_loss: 0.5307 - val_acc: 0.8444\n",
      "Epoch 16/40\n",
      " - 2s - loss: 0.8488 - acc: 0.7159 - val_loss: 0.5057 - val_acc: 0.8440\n",
      "Epoch 17/40\n",
      " - 2s - loss: 0.8272 - acc: 0.7226 - val_loss: 0.4687 - val_acc: 0.8544\n",
      "Epoch 18/40\n",
      " - 2s - loss: 0.7943 - acc: 0.7362 - val_loss: 0.4675 - val_acc: 0.8590\n",
      "Epoch 19/40\n",
      " - 2s - loss: 0.7576 - acc: 0.7492 - val_loss: 0.4210 - val_acc: 0.8741\n",
      "Epoch 20/40\n",
      " - 2s - loss: 0.7177 - acc: 0.7600 - val_loss: 0.4138 - val_acc: 0.8753\n",
      "Epoch 21/40\n",
      " - 2s - loss: 0.6924 - acc: 0.7681 - val_loss: 0.3889 - val_acc: 0.8770\n",
      "Epoch 22/40\n",
      " - 2s - loss: 0.6578 - acc: 0.7826 - val_loss: 0.3697 - val_acc: 0.8856\n",
      "Epoch 23/40\n",
      " - 2s - loss: 0.6486 - acc: 0.7878 - val_loss: 0.3669 - val_acc: 0.8835\n",
      "Epoch 24/40\n",
      " - 2s - loss: 0.6159 - acc: 0.7960 - val_loss: 0.3704 - val_acc: 0.8904\n",
      "Epoch 25/40\n",
      " - 2s - loss: 0.5818 - acc: 0.8094 - val_loss: 0.3283 - val_acc: 0.8989\n",
      "Epoch 26/40\n",
      " - 2s - loss: 0.5705 - acc: 0.8095 - val_loss: 0.3204 - val_acc: 0.8991\n",
      "Epoch 27/40\n",
      " - 2s - loss: 0.5665 - acc: 0.8136 - val_loss: 0.3215 - val_acc: 0.8991\n",
      "Epoch 28/40\n",
      " - 2s - loss: 0.5419 - acc: 0.8218 - val_loss: 0.3000 - val_acc: 0.9073\n",
      "Epoch 29/40\n",
      " - 2s - loss: 0.5176 - acc: 0.8290 - val_loss: 0.3008 - val_acc: 0.9092\n",
      "Epoch 30/40\n",
      " - 2s - loss: 0.5198 - acc: 0.8316 - val_loss: 0.2831 - val_acc: 0.9100\n",
      "Epoch 31/40\n",
      " - 2s - loss: 0.4926 - acc: 0.8401 - val_loss: 0.2843 - val_acc: 0.9144\n",
      "Epoch 32/40\n",
      " - 2s - loss: 0.4799 - acc: 0.8421 - val_loss: 0.2772 - val_acc: 0.9171\n",
      "Epoch 33/40\n",
      " - 2s - loss: 0.4723 - acc: 0.8501 - val_loss: 0.2793 - val_acc: 0.9131\n",
      "Epoch 34/40\n",
      " - 2s - loss: 0.4633 - acc: 0.8483 - val_loss: 0.2721 - val_acc: 0.9144\n",
      "Epoch 35/40\n",
      " - 2s - loss: 0.4397 - acc: 0.8589 - val_loss: 0.2595 - val_acc: 0.9181\n",
      "Epoch 36/40\n",
      " - 2s - loss: 0.4362 - acc: 0.8584 - val_loss: 0.2691 - val_acc: 0.9162\n",
      "Epoch 37/40\n",
      " - 2s - loss: 0.4363 - acc: 0.8560 - val_loss: 0.2669 - val_acc: 0.9160\n",
      "Epoch 38/40\n",
      " - 2s - loss: 0.4180 - acc: 0.8644 - val_loss: 0.2538 - val_acc: 0.9217\n",
      "Epoch 39/40\n",
      " - 2s - loss: 0.4160 - acc: 0.8639 - val_loss: 0.2551 - val_acc: 0.9223\n",
      "Epoch 40/40\n",
      " - 2s - loss: 0.4058 - acc: 0.8679 - val_loss: 0.2412 - val_acc: 0.9265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9265157330155098\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 3s - loss: 2.4312 - acc: 0.1002 - val_loss: 2.3198 - val_acc: 0.1466\n",
      "Epoch 2/40\n",
      " - 3s - loss: 2.1933 - acc: 0.1897 - val_loss: 1.8880 - val_acc: 0.3078\n",
      "Epoch 3/40\n",
      " - 3s - loss: 1.9525 - acc: 0.2663 - val_loss: 1.6825 - val_acc: 0.4457\n",
      "Epoch 4/40\n",
      " - 3s - loss: 1.8041 - acc: 0.3322 - val_loss: 1.4916 - val_acc: 0.5351\n",
      "Epoch 5/40\n",
      " - 3s - loss: 1.6299 - acc: 0.4100 - val_loss: 1.2310 - val_acc: 0.6539\n",
      "Epoch 6/40\n",
      " - 3s - loss: 1.3673 - acc: 0.5112 - val_loss: 0.9290 - val_acc: 0.7323\n",
      "Epoch 7/40\n",
      " - 3s - loss: 1.1241 - acc: 0.6083 - val_loss: 0.6994 - val_acc: 0.8003\n",
      "Epoch 8/40\n",
      " - 3s - loss: 0.9110 - acc: 0.6886 - val_loss: 0.5652 - val_acc: 0.8252\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.7557 - acc: 0.7500 - val_loss: 0.4806 - val_acc: 0.8459\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.6539 - acc: 0.7812 - val_loss: 0.4251 - val_acc: 0.8640\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.5764 - acc: 0.8109 - val_loss: 0.3793 - val_acc: 0.8799\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.5126 - acc: 0.8317 - val_loss: 0.3488 - val_acc: 0.8916\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.4600 - acc: 0.8493 - val_loss: 0.3157 - val_acc: 0.9018\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.4505 - acc: 0.8560 - val_loss: 0.3074 - val_acc: 0.9016\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.3879 - acc: 0.8731 - val_loss: 0.2884 - val_acc: 0.9077\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.3808 - acc: 0.8764 - val_loss: 0.2748 - val_acc: 0.9127\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.3472 - acc: 0.8884 - val_loss: 0.2759 - val_acc: 0.9102\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.3283 - acc: 0.8945 - val_loss: 0.2660 - val_acc: 0.9169\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.3034 - acc: 0.9023 - val_loss: 0.2677 - val_acc: 0.9196\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.2903 - acc: 0.9037 - val_loss: 0.2470 - val_acc: 0.9223\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.2834 - acc: 0.9065 - val_loss: 0.2504 - val_acc: 0.9229\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.2522 - acc: 0.9167 - val_loss: 0.2461 - val_acc: 0.9240\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.2502 - acc: 0.9164 - val_loss: 0.2468 - val_acc: 0.9269\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.2408 - acc: 0.9211 - val_loss: 0.2491 - val_acc: 0.9210\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.2283 - acc: 0.9244 - val_loss: 0.2382 - val_acc: 0.9281\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.2209 - acc: 0.9274 - val_loss: 0.2421 - val_acc: 0.9267\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.2024 - acc: 0.9324 - val_loss: 0.2392 - val_acc: 0.9305\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.1992 - acc: 0.9350 - val_loss: 0.2411 - val_acc: 0.9296\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.1980 - acc: 0.9351 - val_loss: 0.2329 - val_acc: 0.9302\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.1810 - acc: 0.9396 - val_loss: 0.2411 - val_acc: 0.9311\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.1734 - acc: 0.9415 - val_loss: 0.2425 - val_acc: 0.9286\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.1660 - acc: 0.9452 - val_loss: 0.2414 - val_acc: 0.9313\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.1617 - acc: 0.9463 - val_loss: 0.2325 - val_acc: 0.9344\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.1567 - acc: 0.9478 - val_loss: 0.2382 - val_acc: 0.9323\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.1471 - acc: 0.9519 - val_loss: 0.2434 - val_acc: 0.9325\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.1513 - acc: 0.9506 - val_loss: 0.2476 - val_acc: 0.9336\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.1584 - acc: 0.9471 - val_loss: 0.2470 - val_acc: 0.9332\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.1300 - acc: 0.9568 - val_loss: 0.2800 - val_acc: 0.9277\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.1414 - acc: 0.9543 - val_loss: 0.2351 - val_acc: 0.9336\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.1257 - acc: 0.9570 - val_loss: 0.2517 - val_acc: 0.9367\n",
      "Test accuracy: 0.9366845741513502\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 2s - loss: 2.4885 - acc: 0.1611 - val_loss: 1.9600 - val_acc: 0.3302\n",
      "Epoch 2/40\n",
      " - 1s - loss: 1.8790 - acc: 0.3444 - val_loss: 1.5353 - val_acc: 0.4916\n",
      "Epoch 3/40\n",
      " - 1s - loss: 1.6175 - acc: 0.4476 - val_loss: 1.2624 - val_acc: 0.5992\n",
      "Epoch 4/40\n",
      " - 1s - loss: 1.4016 - acc: 0.5276 - val_loss: 1.0580 - val_acc: 0.6673\n",
      "Epoch 5/40\n",
      " - 1s - loss: 1.2553 - acc: 0.5784 - val_loss: 0.9471 - val_acc: 0.7072\n",
      "Epoch 6/40\n",
      " - 1s - loss: 1.1179 - acc: 0.6253 - val_loss: 0.8577 - val_acc: 0.7318\n",
      "Epoch 7/40\n",
      " - 1s - loss: 1.0213 - acc: 0.6611 - val_loss: 0.6967 - val_acc: 0.7859\n",
      "Epoch 8/40\n",
      " - 1s - loss: 0.9468 - acc: 0.6860 - val_loss: 0.6369 - val_acc: 0.7985\n",
      "Epoch 9/40\n",
      " - 1s - loss: 0.8673 - acc: 0.7139 - val_loss: 0.5928 - val_acc: 0.8141\n",
      "Epoch 10/40\n",
      " - 1s - loss: 0.8220 - acc: 0.7372 - val_loss: 0.5591 - val_acc: 0.8289\n",
      "Epoch 11/40\n",
      " - 1s - loss: 0.7690 - acc: 0.7461 - val_loss: 0.5169 - val_acc: 0.8427\n",
      "Epoch 12/40\n",
      " - 1s - loss: 0.7169 - acc: 0.7667 - val_loss: 0.4788 - val_acc: 0.8530\n",
      "Epoch 13/40\n",
      " - 1s - loss: 0.6800 - acc: 0.7786 - val_loss: 0.4453 - val_acc: 0.8649\n",
      "Epoch 14/40\n",
      " - 1s - loss: 0.6493 - acc: 0.7899 - val_loss: 0.4349 - val_acc: 0.8670\n",
      "Epoch 15/40\n",
      " - 1s - loss: 0.6158 - acc: 0.7974 - val_loss: 0.4095 - val_acc: 0.8741\n",
      "Epoch 16/40\n",
      " - 1s - loss: 0.5809 - acc: 0.8108 - val_loss: 0.3943 - val_acc: 0.8791\n",
      "Epoch 17/40\n",
      " - 1s - loss: 0.5643 - acc: 0.8199 - val_loss: 0.3886 - val_acc: 0.8803\n",
      "Epoch 18/40\n",
      " - 1s - loss: 0.5356 - acc: 0.8266 - val_loss: 0.3741 - val_acc: 0.8824\n",
      "Epoch 19/40\n",
      " - 1s - loss: 0.5194 - acc: 0.8300 - val_loss: 0.3586 - val_acc: 0.8868\n",
      "Epoch 20/40\n",
      " - 1s - loss: 0.5025 - acc: 0.8378 - val_loss: 0.3306 - val_acc: 0.8968\n",
      "Epoch 21/40\n",
      " - 1s - loss: 0.4920 - acc: 0.8441 - val_loss: 0.3311 - val_acc: 0.8939\n",
      "Epoch 22/40\n",
      " - 1s - loss: 0.4745 - acc: 0.8446 - val_loss: 0.3281 - val_acc: 0.8956\n",
      "Epoch 23/40\n",
      " - 1s - loss: 0.4562 - acc: 0.8504 - val_loss: 0.3111 - val_acc: 0.9021\n",
      "Epoch 24/40\n",
      " - 1s - loss: 0.4475 - acc: 0.8566 - val_loss: 0.3101 - val_acc: 0.9000\n",
      "Epoch 25/40\n",
      " - 1s - loss: 0.4232 - acc: 0.8636 - val_loss: 0.3168 - val_acc: 0.8977\n",
      "Epoch 26/40\n",
      " - 1s - loss: 0.4216 - acc: 0.8640 - val_loss: 0.2952 - val_acc: 0.9083\n",
      "Epoch 27/40\n",
      " - 1s - loss: 0.4120 - acc: 0.8638 - val_loss: 0.3065 - val_acc: 0.9027\n",
      "Epoch 28/40\n",
      " - 1s - loss: 0.4025 - acc: 0.8696 - val_loss: 0.3165 - val_acc: 0.8972\n",
      "Epoch 29/40\n",
      " - 1s - loss: 0.3997 - acc: 0.8703 - val_loss: 0.2781 - val_acc: 0.9085\n",
      "Epoch 30/40\n",
      " - 1s - loss: 0.3803 - acc: 0.8742 - val_loss: 0.2765 - val_acc: 0.9116\n",
      "Epoch 31/40\n",
      " - 1s - loss: 0.3768 - acc: 0.8766 - val_loss: 0.2719 - val_acc: 0.9121\n",
      "Epoch 32/40\n",
      " - 1s - loss: 0.3524 - acc: 0.8846 - val_loss: 0.2805 - val_acc: 0.9081\n",
      "Epoch 33/40\n",
      " - 1s - loss: 0.3537 - acc: 0.8860 - val_loss: 0.2595 - val_acc: 0.9185\n",
      "Epoch 34/40\n",
      " - 1s - loss: 0.3478 - acc: 0.8869 - val_loss: 0.2676 - val_acc: 0.9162\n",
      "Epoch 35/40\n",
      " - 1s - loss: 0.3463 - acc: 0.8866 - val_loss: 0.2753 - val_acc: 0.9148\n",
      "Epoch 36/40\n",
      " - 1s - loss: 0.3365 - acc: 0.8900 - val_loss: 0.2470 - val_acc: 0.9219\n",
      "Epoch 37/40\n",
      " - 1s - loss: 0.3198 - acc: 0.8940 - val_loss: 0.2575 - val_acc: 0.9175\n",
      "Epoch 38/40\n",
      " - 1s - loss: 0.3284 - acc: 0.8948 - val_loss: 0.2432 - val_acc: 0.9221\n",
      "Epoch 39/40\n",
      " - 1s - loss: 0.3241 - acc: 0.8924 - val_loss: 0.2486 - val_acc: 0.9206\n",
      "Epoch 40/40\n",
      " - 1s - loss: 0.3123 - acc: 0.8991 - val_loss: 0.2514 - val_acc: 0.9215\n",
      "Test accuracy: 0.9215272446824144\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 2s - loss: 2.5228 - acc: 0.1264 - val_loss: 2.1639 - val_acc: 0.2510\n",
      "Epoch 2/40\n",
      " - 2s - loss: 2.0529 - acc: 0.2654 - val_loss: 1.6506 - val_acc: 0.4714\n",
      "Epoch 3/40\n",
      " - 2s - loss: 1.7386 - acc: 0.3920 - val_loss: 1.3403 - val_acc: 0.5743\n",
      "Epoch 4/40\n",
      " - 2s - loss: 1.5055 - acc: 0.4863 - val_loss: 1.1329 - val_acc: 0.6520\n",
      "Epoch 5/40\n",
      " - 2s - loss: 1.2987 - acc: 0.5578 - val_loss: 0.9181 - val_acc: 0.7076\n",
      "Epoch 6/40\n",
      " - 2s - loss: 1.1468 - acc: 0.6116 - val_loss: 0.7876 - val_acc: 0.7483\n",
      "Epoch 7/40\n",
      " - 2s - loss: 1.0319 - acc: 0.6540 - val_loss: 0.7305 - val_acc: 0.7629\n",
      "Epoch 8/40\n",
      " - 2s - loss: 0.9458 - acc: 0.6848 - val_loss: 0.6780 - val_acc: 0.7795\n",
      "Epoch 9/40\n",
      " - 2s - loss: 0.8669 - acc: 0.7118 - val_loss: 0.5635 - val_acc: 0.8287\n",
      "Epoch 10/40\n",
      " - 2s - loss: 0.8065 - acc: 0.7340 - val_loss: 0.5609 - val_acc: 0.8221\n",
      "Epoch 11/40\n",
      " - 2s - loss: 0.7451 - acc: 0.7592 - val_loss: 0.5103 - val_acc: 0.8406\n",
      "Epoch 12/40\n",
      " - 2s - loss: 0.7061 - acc: 0.7701 - val_loss: 0.4648 - val_acc: 0.8563\n",
      "Epoch 13/40\n",
      " - 2s - loss: 0.6651 - acc: 0.7851 - val_loss: 0.4507 - val_acc: 0.8607\n",
      "Epoch 14/40\n",
      " - 2s - loss: 0.6361 - acc: 0.7955 - val_loss: 0.3927 - val_acc: 0.8793\n",
      "Epoch 15/40\n",
      " - 2s - loss: 0.5932 - acc: 0.8109 - val_loss: 0.4059 - val_acc: 0.8718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40\n",
      " - 2s - loss: 0.5734 - acc: 0.8168 - val_loss: 0.3617 - val_acc: 0.8889\n",
      "Epoch 17/40\n",
      " - 2s - loss: 0.5405 - acc: 0.8261 - val_loss: 0.3431 - val_acc: 0.8897\n",
      "Epoch 18/40\n",
      " - 2s - loss: 0.5204 - acc: 0.8319 - val_loss: 0.3390 - val_acc: 0.8929\n",
      "Epoch 19/40\n",
      " - 2s - loss: 0.4892 - acc: 0.8436 - val_loss: 0.3122 - val_acc: 0.8993\n",
      "Epoch 20/40\n",
      " - 2s - loss: 0.4712 - acc: 0.8478 - val_loss: 0.3004 - val_acc: 0.9071\n",
      "Epoch 21/40\n",
      " - 2s - loss: 0.4528 - acc: 0.8558 - val_loss: 0.2983 - val_acc: 0.9052\n",
      "Epoch 22/40\n",
      " - 2s - loss: 0.4398 - acc: 0.8615 - val_loss: 0.2967 - val_acc: 0.9016\n",
      "Epoch 23/40\n",
      " - 2s - loss: 0.4318 - acc: 0.8618 - val_loss: 0.2785 - val_acc: 0.9121\n",
      "Epoch 24/40\n",
      " - 2s - loss: 0.4084 - acc: 0.8688 - val_loss: 0.2713 - val_acc: 0.9144\n",
      "Epoch 25/40\n",
      " - 2s - loss: 0.4013 - acc: 0.8745 - val_loss: 0.2617 - val_acc: 0.9154\n",
      "Epoch 26/40\n",
      " - 2s - loss: 0.3842 - acc: 0.8781 - val_loss: 0.2619 - val_acc: 0.9150\n",
      "Epoch 27/40\n",
      " - 2s - loss: 0.3741 - acc: 0.8805 - val_loss: 0.2613 - val_acc: 0.9131\n",
      "Epoch 28/40\n",
      " - 2s - loss: 0.3637 - acc: 0.8839 - val_loss: 0.2638 - val_acc: 0.9167\n",
      "Epoch 29/40\n",
      " - 2s - loss: 0.3529 - acc: 0.8856 - val_loss: 0.2448 - val_acc: 0.9223\n",
      "Epoch 30/40\n",
      " - 2s - loss: 0.3479 - acc: 0.8877 - val_loss: 0.2395 - val_acc: 0.9225\n",
      "Epoch 31/40\n",
      " - 2s - loss: 0.3304 - acc: 0.8933 - val_loss: 0.2354 - val_acc: 0.9234\n",
      "Epoch 32/40\n",
      " - 2s - loss: 0.3167 - acc: 0.8948 - val_loss: 0.2321 - val_acc: 0.9261\n",
      "Epoch 33/40\n",
      " - 2s - loss: 0.3264 - acc: 0.8954 - val_loss: 0.2347 - val_acc: 0.9259\n",
      "Epoch 34/40\n",
      " - 2s - loss: 0.3075 - acc: 0.9013 - val_loss: 0.2378 - val_acc: 0.9225\n",
      "Epoch 35/40\n",
      " - 2s - loss: 0.2983 - acc: 0.9042 - val_loss: 0.2298 - val_acc: 0.9267\n",
      "Epoch 36/40\n",
      " - 2s - loss: 0.2998 - acc: 0.9015 - val_loss: 0.2238 - val_acc: 0.9296\n",
      "Epoch 37/40\n",
      " - 2s - loss: 0.2882 - acc: 0.9074 - val_loss: 0.2240 - val_acc: 0.9277\n",
      "Epoch 38/40\n",
      " - 2s - loss: 0.2788 - acc: 0.9098 - val_loss: 0.2179 - val_acc: 0.9327\n",
      "Epoch 39/40\n",
      " - 2s - loss: 0.2771 - acc: 0.9108 - val_loss: 0.2217 - val_acc: 0.9311\n",
      "Epoch 40/40\n",
      " - 2s - loss: 0.2712 - acc: 0.9115 - val_loss: 0.2211 - val_acc: 0.9296\n",
      "Test accuracy: 0.9295855716202502\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 3s - loss: 2.1595 - acc: 0.2036 - val_loss: 1.7801 - val_acc: 0.4186\n",
      "Epoch 2/40\n",
      " - 2s - loss: 1.5945 - acc: 0.4384 - val_loss: 1.1652 - val_acc: 0.6180\n",
      "Epoch 3/40\n",
      " - 2s - loss: 1.1714 - acc: 0.5980 - val_loss: 0.8388 - val_acc: 0.7251\n",
      "Epoch 4/40\n",
      " - 2s - loss: 0.9324 - acc: 0.6881 - val_loss: 0.6421 - val_acc: 0.7868\n",
      "Epoch 5/40\n",
      " - 2s - loss: 0.7855 - acc: 0.7380 - val_loss: 0.5449 - val_acc: 0.8233\n",
      "Epoch 6/40\n",
      " - 2s - loss: 0.6915 - acc: 0.7739 - val_loss: 0.4907 - val_acc: 0.8319\n",
      "Epoch 7/40\n",
      " - 2s - loss: 0.6127 - acc: 0.7981 - val_loss: 0.4139 - val_acc: 0.8611\n",
      "Epoch 8/40\n",
      " - 2s - loss: 0.5608 - acc: 0.8164 - val_loss: 0.3963 - val_acc: 0.8691\n",
      "Epoch 9/40\n",
      " - 2s - loss: 0.5151 - acc: 0.8325 - val_loss: 0.3543 - val_acc: 0.8830\n",
      "Epoch 10/40\n",
      " - 2s - loss: 0.4751 - acc: 0.8440 - val_loss: 0.3559 - val_acc: 0.8799\n",
      "Epoch 11/40\n",
      " - 2s - loss: 0.4444 - acc: 0.8546 - val_loss: 0.3276 - val_acc: 0.8956\n",
      "Epoch 12/40\n",
      " - 2s - loss: 0.4142 - acc: 0.8632 - val_loss: 0.3167 - val_acc: 0.8985\n",
      "Epoch 13/40\n",
      " - 2s - loss: 0.3995 - acc: 0.8701 - val_loss: 0.2890 - val_acc: 0.9060\n",
      "Epoch 14/40\n",
      " - 2s - loss: 0.3727 - acc: 0.8780 - val_loss: 0.2840 - val_acc: 0.9089\n",
      "Epoch 15/40\n",
      " - 2s - loss: 0.3538 - acc: 0.8838 - val_loss: 0.2705 - val_acc: 0.9146\n",
      "Epoch 16/40\n",
      " - 2s - loss: 0.3411 - acc: 0.8876 - val_loss: 0.2748 - val_acc: 0.9135\n",
      "Epoch 17/40\n",
      " - 2s - loss: 0.3283 - acc: 0.8926 - val_loss: 0.2535 - val_acc: 0.9173\n",
      "Epoch 18/40\n",
      " - 2s - loss: 0.3121 - acc: 0.8961 - val_loss: 0.2518 - val_acc: 0.9173\n",
      "Epoch 19/40\n",
      " - 2s - loss: 0.2970 - acc: 0.9029 - val_loss: 0.2519 - val_acc: 0.9146\n",
      "Epoch 20/40\n",
      " - 2s - loss: 0.2996 - acc: 0.9000 - val_loss: 0.2472 - val_acc: 0.9213\n",
      "Epoch 21/40\n",
      " - 2s - loss: 0.2946 - acc: 0.9033 - val_loss: 0.2561 - val_acc: 0.9181\n",
      "Epoch 22/40\n",
      " - 2s - loss: 0.2744 - acc: 0.9095 - val_loss: 0.2522 - val_acc: 0.9165\n",
      "Epoch 23/40\n",
      " - 2s - loss: 0.2674 - acc: 0.9109 - val_loss: 0.2354 - val_acc: 0.9221\n",
      "Epoch 24/40\n",
      " - 2s - loss: 0.2590 - acc: 0.9115 - val_loss: 0.2327 - val_acc: 0.9240\n",
      "Epoch 25/40\n",
      " - 2s - loss: 0.2554 - acc: 0.9161 - val_loss: 0.2429 - val_acc: 0.9221\n",
      "Epoch 26/40\n",
      " - 2s - loss: 0.2440 - acc: 0.9183 - val_loss: 0.2284 - val_acc: 0.9281\n",
      "Epoch 27/40\n",
      " - 2s - loss: 0.2361 - acc: 0.9203 - val_loss: 0.2490 - val_acc: 0.9233\n",
      "Epoch 28/40\n",
      " - 2s - loss: 0.2351 - acc: 0.9220 - val_loss: 0.2267 - val_acc: 0.9275\n",
      "Epoch 29/40\n",
      " - 2s - loss: 0.2359 - acc: 0.9232 - val_loss: 0.2281 - val_acc: 0.9286\n",
      "Epoch 30/40\n",
      " - 2s - loss: 0.2107 - acc: 0.9274 - val_loss: 0.2255 - val_acc: 0.9271\n",
      "Epoch 31/40\n",
      " - 2s - loss: 0.2093 - acc: 0.9305 - val_loss: 0.2413 - val_acc: 0.9282\n",
      "Epoch 32/40\n",
      " - 2s - loss: 0.2107 - acc: 0.9292 - val_loss: 0.2332 - val_acc: 0.9304\n",
      "Epoch 33/40\n",
      " - 2s - loss: 0.2094 - acc: 0.9295 - val_loss: 0.2242 - val_acc: 0.9305\n",
      "Epoch 34/40\n",
      " - 2s - loss: 0.2066 - acc: 0.9293 - val_loss: 0.2389 - val_acc: 0.9286\n",
      "Epoch 35/40\n",
      " - 2s - loss: 0.2035 - acc: 0.9302 - val_loss: 0.2321 - val_acc: 0.9290\n",
      "Epoch 36/40\n",
      " - 2s - loss: 0.1920 - acc: 0.9372 - val_loss: 0.2331 - val_acc: 0.9288\n",
      "Epoch 37/40\n",
      " - 2s - loss: 0.1926 - acc: 0.9357 - val_loss: 0.2345 - val_acc: 0.9284\n",
      "Epoch 38/40\n",
      " - 2s - loss: 0.1831 - acc: 0.9377 - val_loss: 0.2376 - val_acc: 0.9286\n",
      "Epoch 39/40\n",
      " - 2s - loss: 0.1819 - acc: 0.9400 - val_loss: 0.2381 - val_acc: 0.9273\n",
      "Epoch 40/40\n",
      " - 2s - loss: 0.1823 - acc: 0.9396 - val_loss: 0.2204 - val_acc: 0.9363\n",
      "Test accuracy: 0.9363008442971675\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 2s - loss: 2.4354 - acc: 0.1019 - val_loss: 2.3240 - val_acc: 0.1207\n",
      "Epoch 2/40\n",
      " - 1s - loss: 2.2834 - acc: 0.1616 - val_loss: 2.1443 - val_acc: 0.2801\n",
      "Epoch 3/40\n",
      " - 1s - loss: 2.1545 - acc: 0.2132 - val_loss: 1.9818 - val_acc: 0.3252\n",
      "Epoch 4/40\n",
      " - 1s - loss: 2.0326 - acc: 0.2507 - val_loss: 1.8290 - val_acc: 0.4186\n",
      "Epoch 5/40\n",
      " - 1s - loss: 1.8904 - acc: 0.3020 - val_loss: 1.5942 - val_acc: 0.5104\n",
      "Epoch 6/40\n",
      " - 1s - loss: 1.7077 - acc: 0.3752 - val_loss: 1.3371 - val_acc: 0.6005\n",
      "Epoch 7/40\n",
      " - 1s - loss: 1.4910 - acc: 0.4668 - val_loss: 1.0604 - val_acc: 0.6878\n",
      "Epoch 8/40\n",
      " - 1s - loss: 1.2771 - acc: 0.5531 - val_loss: 0.8628 - val_acc: 0.7504\n",
      "Epoch 9/40\n",
      " - 1s - loss: 1.1202 - acc: 0.6146 - val_loss: 0.7268 - val_acc: 0.7782\n",
      "Epoch 10/40\n",
      " - 1s - loss: 1.0158 - acc: 0.6504 - val_loss: 0.6452 - val_acc: 0.7943\n",
      "Epoch 11/40\n",
      " - 1s - loss: 0.9173 - acc: 0.6894 - val_loss: 0.6225 - val_acc: 0.8114\n",
      "Epoch 12/40\n",
      " - 1s - loss: 0.8561 - acc: 0.7090 - val_loss: 0.5303 - val_acc: 0.8381\n",
      "Epoch 13/40\n",
      " - 1s - loss: 0.7823 - acc: 0.7375 - val_loss: 0.4877 - val_acc: 0.8505\n",
      "Epoch 14/40\n",
      " - 1s - loss: 0.7409 - acc: 0.7521 - val_loss: 0.4495 - val_acc: 0.8596\n",
      "Epoch 15/40\n",
      " - 1s - loss: 0.6895 - acc: 0.7698 - val_loss: 0.4198 - val_acc: 0.8697\n",
      "Epoch 16/40\n",
      " - 1s - loss: 0.6587 - acc: 0.7825 - val_loss: 0.4044 - val_acc: 0.8720\n",
      "Epoch 17/40\n",
      " - 1s - loss: 0.6258 - acc: 0.7947 - val_loss: 0.4077 - val_acc: 0.8743\n",
      "Epoch 18/40\n",
      " - 2s - loss: 0.5929 - acc: 0.8066 - val_loss: 0.3806 - val_acc: 0.8858\n",
      "Epoch 19/40\n",
      " - 2s - loss: 0.5656 - acc: 0.8145 - val_loss: 0.3620 - val_acc: 0.8880\n",
      "Epoch 20/40\n",
      " - 1s - loss: 0.5384 - acc: 0.8238 - val_loss: 0.3422 - val_acc: 0.8931\n",
      "Epoch 21/40\n",
      " - 1s - loss: 0.5125 - acc: 0.8330 - val_loss: 0.3289 - val_acc: 0.8985\n",
      "Epoch 22/40\n",
      " - 1s - loss: 0.4989 - acc: 0.8393 - val_loss: 0.3100 - val_acc: 0.9031\n",
      "Epoch 23/40\n",
      " - 1s - loss: 0.4755 - acc: 0.8456 - val_loss: 0.3038 - val_acc: 0.9062\n",
      "Epoch 24/40\n",
      " - 1s - loss: 0.4586 - acc: 0.8483 - val_loss: 0.3064 - val_acc: 0.9014\n",
      "Epoch 25/40\n",
      " - 1s - loss: 0.4466 - acc: 0.8551 - val_loss: 0.2931 - val_acc: 0.9077\n",
      "Epoch 26/40\n",
      " - 1s - loss: 0.4190 - acc: 0.8625 - val_loss: 0.2955 - val_acc: 0.9092\n",
      "Epoch 27/40\n",
      " - 1s - loss: 0.4262 - acc: 0.8616 - val_loss: 0.2770 - val_acc: 0.9165\n",
      "Epoch 28/40\n",
      " - 1s - loss: 0.4024 - acc: 0.8693 - val_loss: 0.2830 - val_acc: 0.9146\n",
      "Epoch 29/40\n",
      " - 1s - loss: 0.3916 - acc: 0.8698 - val_loss: 0.2940 - val_acc: 0.9050\n",
      "Epoch 30/40\n",
      " - 1s - loss: 0.3780 - acc: 0.8771 - val_loss: 0.2711 - val_acc: 0.9163\n",
      "Epoch 31/40\n",
      " - 1s - loss: 0.3668 - acc: 0.8820 - val_loss: 0.2602 - val_acc: 0.9175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40\n",
      " - 1s - loss: 0.3627 - acc: 0.8812 - val_loss: 0.2750 - val_acc: 0.9135\n",
      "Epoch 33/40\n",
      " - 1s - loss: 0.3561 - acc: 0.8845 - val_loss: 0.2575 - val_acc: 0.9206\n",
      "Epoch 34/40\n",
      " - 1s - loss: 0.3508 - acc: 0.8870 - val_loss: 0.2666 - val_acc: 0.9185\n",
      "Epoch 35/40\n",
      " - 1s - loss: 0.3362 - acc: 0.8901 - val_loss: 0.2563 - val_acc: 0.9223\n",
      "Epoch 36/40\n",
      " - 1s - loss: 0.3315 - acc: 0.8919 - val_loss: 0.2529 - val_acc: 0.9217\n",
      "Epoch 37/40\n",
      " - 1s - loss: 0.3242 - acc: 0.8930 - val_loss: 0.2612 - val_acc: 0.9198\n",
      "Epoch 38/40\n",
      " - 1s - loss: 0.3089 - acc: 0.8978 - val_loss: 0.2482 - val_acc: 0.9233\n",
      "Epoch 39/40\n",
      " - 1s - loss: 0.3119 - acc: 0.8961 - val_loss: 0.2473 - val_acc: 0.9236\n",
      "Epoch 40/40\n",
      " - 1s - loss: 0.2994 - acc: 0.9022 - val_loss: 0.2437 - val_acc: 0.9269\n",
      "Test accuracy: 0.9268994626409717\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.7121 - acc: 0.0925 - val_loss: 2.3983 - val_acc: 0.0877\n",
      "Epoch 2/40\n",
      " - 3s - loss: 2.5438 - acc: 0.0909 - val_loss: 2.3988 - val_acc: 0.0886\n",
      "Epoch 3/40\n",
      " - 3s - loss: 2.5131 - acc: 0.0946 - val_loss: 2.3993 - val_acc: 0.0877\n",
      "Epoch 4/40\n",
      " - 3s - loss: 2.5020 - acc: 0.0909 - val_loss: 2.3985 - val_acc: 0.0986\n",
      "Epoch 5/40\n",
      " - 3s - loss: 2.4834 - acc: 0.0900 - val_loss: 2.3994 - val_acc: 0.0877\n",
      "Epoch 6/40\n",
      " - 3s - loss: 2.4709 - acc: 0.0899 - val_loss: 2.3990 - val_acc: 0.0986\n",
      "Epoch 7/40\n",
      " - 3s - loss: 2.4566 - acc: 0.0936 - val_loss: 2.3987 - val_acc: 0.0886\n",
      "Epoch 8/40\n",
      " - 3s - loss: 2.4555 - acc: 0.0866 - val_loss: 2.4000 - val_acc: 0.0894\n",
      "Epoch 9/40\n",
      " - 3s - loss: 2.4418 - acc: 0.0934 - val_loss: 2.3997 - val_acc: 0.0846\n",
      "Epoch 10/40\n",
      " - 3s - loss: 2.4360 - acc: 0.0873 - val_loss: 2.3988 - val_acc: 0.0894\n",
      "Epoch 11/40\n",
      " - 3s - loss: 2.4312 - acc: 0.0878 - val_loss: 2.3983 - val_acc: 0.0877\n",
      "Epoch 12/40\n",
      " - 3s - loss: 2.4225 - acc: 0.0925 - val_loss: 2.3986 - val_acc: 0.0846\n",
      "Epoch 13/40\n",
      " - 3s - loss: 2.4211 - acc: 0.0905 - val_loss: 2.3980 - val_acc: 0.0986\n",
      "Epoch 14/40\n",
      " - 3s - loss: 2.4152 - acc: 0.0905 - val_loss: 2.3991 - val_acc: 0.0877\n",
      "Epoch 15/40\n",
      " - 3s - loss: 2.4115 - acc: 0.0945 - val_loss: 2.3993 - val_acc: 0.0877\n",
      "Epoch 16/40\n",
      " - 3s - loss: 2.4103 - acc: 0.0933 - val_loss: 2.3984 - val_acc: 0.0877\n",
      "Epoch 17/40\n",
      " - 3s - loss: 2.4087 - acc: 0.0909 - val_loss: 2.3986 - val_acc: 0.0894\n",
      "Epoch 18/40\n",
      " - 3s - loss: 2.4073 - acc: 0.0924 - val_loss: 2.3997 - val_acc: 0.0846\n",
      "Epoch 19/40\n",
      " - 3s - loss: 2.4048 - acc: 0.0916 - val_loss: 2.3991 - val_acc: 0.0902\n",
      "Epoch 20/40\n",
      " - 3s - loss: 2.4048 - acc: 0.0896 - val_loss: 2.3989 - val_acc: 0.0902\n",
      "Epoch 21/40\n",
      " - 3s - loss: 2.4044 - acc: 0.0920 - val_loss: 2.3985 - val_acc: 0.0846\n",
      "Epoch 22/40\n",
      " - 3s - loss: 2.4015 - acc: 0.0943 - val_loss: 2.4000 - val_acc: 0.0902\n",
      "Epoch 23/40\n",
      " - 3s - loss: 2.4039 - acc: 0.0915 - val_loss: 2.3986 - val_acc: 0.0913\n",
      "Epoch 24/40\n",
      " - 3s - loss: 2.4029 - acc: 0.0878 - val_loss: 2.3990 - val_acc: 0.0886\n",
      "Epoch 25/40\n",
      " - 3s - loss: 2.4012 - acc: 0.0861 - val_loss: 2.3993 - val_acc: 0.0886\n",
      "Epoch 26/40\n",
      " - 3s - loss: 2.4014 - acc: 0.0910 - val_loss: 2.3988 - val_acc: 0.0911\n",
      "Epoch 27/40\n",
      " - 3s - loss: 2.4004 - acc: 0.0925 - val_loss: 2.3994 - val_acc: 0.0877\n",
      "Epoch 28/40\n",
      " - 3s - loss: 2.4005 - acc: 0.0897 - val_loss: 2.3994 - val_acc: 0.0911\n",
      "Epoch 29/40\n",
      " - 3s - loss: 2.4003 - acc: 0.0899 - val_loss: 2.3988 - val_acc: 0.0894\n",
      "Epoch 30/40\n",
      " - 3s - loss: 2.4008 - acc: 0.0866 - val_loss: 2.3988 - val_acc: 0.0846\n",
      "Epoch 31/40\n",
      " - 3s - loss: 2.4004 - acc: 0.0874 - val_loss: 2.3995 - val_acc: 0.0902\n",
      "Epoch 32/40\n",
      " - 3s - loss: 2.4001 - acc: 0.0896 - val_loss: 2.3992 - val_acc: 0.0877\n",
      "Epoch 33/40\n",
      " - 3s - loss: 2.3997 - acc: 0.0895 - val_loss: 2.3996 - val_acc: 0.0846\n",
      "Epoch 34/40\n",
      " - 4s - loss: 2.3994 - acc: 0.0921 - val_loss: 2.3991 - val_acc: 0.0911\n",
      "Epoch 35/40\n",
      " - 3s - loss: 2.3998 - acc: 0.0911 - val_loss: 2.3985 - val_acc: 0.0846\n",
      "Epoch 36/40\n",
      " - 3s - loss: 2.3999 - acc: 0.0908 - val_loss: 2.3996 - val_acc: 0.0913\n",
      "Epoch 37/40\n",
      " - 3s - loss: 2.3996 - acc: 0.0877 - val_loss: 2.3993 - val_acc: 0.0902\n",
      "Epoch 38/40\n",
      " - 3s - loss: 2.3991 - acc: 0.0908 - val_loss: 2.3991 - val_acc: 0.0911\n",
      "Epoch 39/40\n",
      " - 3s - loss: 2.3992 - acc: 0.0899 - val_loss: 2.3989 - val_acc: 0.0846\n",
      "Epoch 40/40\n",
      " - 3s - loss: 2.3991 - acc: 0.0905 - val_loss: 2.3988 - val_acc: 0.0886\n",
      "Test accuracy: 0.08864159632477044\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 3s - loss: 2.6639 - acc: 0.0925 - val_loss: 2.3968 - val_acc: 0.1065\n",
      "Epoch 2/40\n",
      " - 3s - loss: 2.4845 - acc: 0.1002 - val_loss: 2.3784 - val_acc: 0.1861\n",
      "Epoch 3/40\n",
      " - 3s - loss: 2.4007 - acc: 0.1280 - val_loss: 2.2013 - val_acc: 0.2989\n",
      "Epoch 4/40\n",
      " - 3s - loss: 2.2069 - acc: 0.2140 - val_loss: 1.9065 - val_acc: 0.4062\n",
      "Epoch 5/40\n",
      " - 3s - loss: 2.0399 - acc: 0.2864 - val_loss: 1.6567 - val_acc: 0.4941\n",
      "Epoch 6/40\n",
      " - 3s - loss: 1.8755 - acc: 0.3535 - val_loss: 1.4564 - val_acc: 0.5512\n",
      "Epoch 7/40\n",
      " - 3s - loss: 1.7216 - acc: 0.4094 - val_loss: 1.2498 - val_acc: 0.6239\n",
      "Epoch 8/40\n",
      " - 3s - loss: 1.5761 - acc: 0.4625 - val_loss: 1.0632 - val_acc: 0.6663\n",
      "Epoch 9/40\n",
      " - 3s - loss: 1.4181 - acc: 0.5176 - val_loss: 0.9243 - val_acc: 0.7151\n",
      "Epoch 10/40\n",
      " - 3s - loss: 1.2505 - acc: 0.5763 - val_loss: 0.7569 - val_acc: 0.7575\n",
      "Epoch 11/40\n",
      " - 3s - loss: 1.1560 - acc: 0.6094 - val_loss: 0.6772 - val_acc: 0.7830\n",
      "Epoch 12/40\n",
      " - 3s - loss: 1.0561 - acc: 0.6473 - val_loss: 0.6372 - val_acc: 0.7918\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.9684 - acc: 0.6763 - val_loss: 0.5822 - val_acc: 0.8183\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.9189 - acc: 0.6935 - val_loss: 0.5447 - val_acc: 0.8281\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.8421 - acc: 0.7201 - val_loss: 0.5100 - val_acc: 0.8381\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.8012 - acc: 0.7338 - val_loss: 0.5036 - val_acc: 0.8440\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.7603 - acc: 0.7494 - val_loss: 0.4523 - val_acc: 0.8584\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.7244 - acc: 0.7636 - val_loss: 0.4231 - val_acc: 0.8720\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.7037 - acc: 0.7727 - val_loss: 0.4086 - val_acc: 0.8691\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.6730 - acc: 0.7850 - val_loss: 0.3962 - val_acc: 0.8774\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.6379 - acc: 0.7960 - val_loss: 0.3797 - val_acc: 0.8860\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.6071 - acc: 0.8061 - val_loss: 0.3578 - val_acc: 0.8910\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.5911 - acc: 0.8127 - val_loss: 0.3493 - val_acc: 0.8912\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.5678 - acc: 0.8213 - val_loss: 0.3309 - val_acc: 0.8960\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.5500 - acc: 0.8291 - val_loss: 0.3020 - val_acc: 0.9083\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.5302 - acc: 0.8357 - val_loss: 0.2974 - val_acc: 0.9033\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.5187 - acc: 0.8416 - val_loss: 0.2984 - val_acc: 0.9066\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.5008 - acc: 0.8438 - val_loss: 0.3107 - val_acc: 0.9041\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.4857 - acc: 0.8496 - val_loss: 0.2846 - val_acc: 0.9158\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.4616 - acc: 0.8572 - val_loss: 0.2633 - val_acc: 0.9185\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.4647 - acc: 0.8591 - val_loss: 0.2610 - val_acc: 0.9202\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.4353 - acc: 0.8630 - val_loss: 0.2576 - val_acc: 0.9225\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.4413 - acc: 0.8635 - val_loss: 0.2518 - val_acc: 0.9227\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.4297 - acc: 0.8684 - val_loss: 0.2627 - val_acc: 0.9211\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.4084 - acc: 0.8747 - val_loss: 0.2643 - val_acc: 0.9202\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.4208 - acc: 0.8716 - val_loss: 0.2477 - val_acc: 0.9259\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.3900 - acc: 0.8799 - val_loss: 0.2419 - val_acc: 0.9250\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.3941 - acc: 0.8789 - val_loss: 0.2330 - val_acc: 0.9273\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.3810 - acc: 0.8834 - val_loss: 0.2466 - val_acc: 0.9231\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.3788 - acc: 0.8841 - val_loss: 0.2556 - val_acc: 0.9229\n",
      "Test accuracy: 0.9228702993092862\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 3s - loss: 2.4365 - acc: 0.0918 - val_loss: 2.3977 - val_acc: 0.1094\n",
      "Epoch 2/40\n",
      " - 3s - loss: 2.3979 - acc: 0.0944 - val_loss: 2.3977 - val_acc: 0.1065\n",
      "Epoch 3/40\n",
      " - 3s - loss: 2.3977 - acc: 0.0970 - val_loss: 2.3975 - val_acc: 0.1261\n",
      "Epoch 4/40\n",
      " - 3s - loss: 2.3973 - acc: 0.0998 - val_loss: 2.3954 - val_acc: 0.1238\n",
      "Epoch 5/40\n",
      " - 3s - loss: 2.3807 - acc: 0.1089 - val_loss: 2.3229 - val_acc: 0.1523\n",
      "Epoch 6/40\n",
      " - 3s - loss: 2.2968 - acc: 0.1448 - val_loss: 2.1392 - val_acc: 0.2640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40\n",
      " - 3s - loss: 2.1831 - acc: 0.1854 - val_loss: 1.9881 - val_acc: 0.3066\n",
      "Epoch 8/40\n",
      " - 3s - loss: 2.0575 - acc: 0.2348 - val_loss: 1.8149 - val_acc: 0.4269\n",
      "Epoch 9/40\n",
      " - 3s - loss: 1.9656 - acc: 0.2674 - val_loss: 1.7066 - val_acc: 0.5094\n",
      "Epoch 10/40\n",
      " - 3s - loss: 1.8633 - acc: 0.3019 - val_loss: 1.5451 - val_acc: 0.5234\n",
      "Epoch 11/40\n",
      " - 3s - loss: 1.7436 - acc: 0.3441 - val_loss: 1.3695 - val_acc: 0.5909\n",
      "Epoch 12/40\n",
      " - 3s - loss: 1.6387 - acc: 0.3807 - val_loss: 1.2122 - val_acc: 0.6305\n",
      "Epoch 13/40\n",
      " - 3s - loss: 1.5182 - acc: 0.4240 - val_loss: 1.0460 - val_acc: 0.6840\n",
      "Epoch 14/40\n",
      " - 3s - loss: 1.4048 - acc: 0.4664 - val_loss: 0.9445 - val_acc: 0.7001\n",
      "Epoch 15/40\n",
      " - 3s - loss: 1.3228 - acc: 0.4986 - val_loss: 0.7846 - val_acc: 0.7414\n",
      "Epoch 16/40\n",
      " - 3s - loss: 1.2375 - acc: 0.5336 - val_loss: 0.6948 - val_acc: 0.7630\n",
      "Epoch 17/40\n",
      " - 3s - loss: 1.1529 - acc: 0.5683 - val_loss: 0.6560 - val_acc: 0.7746\n",
      "Epoch 18/40\n",
      " - 3s - loss: 1.0840 - acc: 0.5948 - val_loss: 0.6010 - val_acc: 0.8298\n",
      "Epoch 19/40\n",
      " - 3s - loss: 1.0230 - acc: 0.6253 - val_loss: 0.5166 - val_acc: 0.8455\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.9725 - acc: 0.6500 - val_loss: 0.4925 - val_acc: 0.8415\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.9057 - acc: 0.6733 - val_loss: 0.4560 - val_acc: 0.8626\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.8729 - acc: 0.6864 - val_loss: 0.4053 - val_acc: 0.8776\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.8336 - acc: 0.7034 - val_loss: 0.3821 - val_acc: 0.8860\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.8109 - acc: 0.7105 - val_loss: 0.3834 - val_acc: 0.8889\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.7789 - acc: 0.7243 - val_loss: 0.3598 - val_acc: 0.8920\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.7559 - acc: 0.7287 - val_loss: 0.3464 - val_acc: 0.8954\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.7398 - acc: 0.7348 - val_loss: 0.3377 - val_acc: 0.8929\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.7045 - acc: 0.7488 - val_loss: 0.3299 - val_acc: 0.8998\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.6960 - acc: 0.7502 - val_loss: 0.3070 - val_acc: 0.9079\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.6771 - acc: 0.7594 - val_loss: 0.3209 - val_acc: 0.9046\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.6585 - acc: 0.7606 - val_loss: 0.2948 - val_acc: 0.9085\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.6452 - acc: 0.7681 - val_loss: 0.2948 - val_acc: 0.9052\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.6228 - acc: 0.7807 - val_loss: 0.2704 - val_acc: 0.9139\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.6183 - acc: 0.7786 - val_loss: 0.2676 - val_acc: 0.9148\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.6150 - acc: 0.7784 - val_loss: 0.2811 - val_acc: 0.9137\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.5759 - acc: 0.7905 - val_loss: 0.2646 - val_acc: 0.9154\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.5754 - acc: 0.7888 - val_loss: 0.2719 - val_acc: 0.9173\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.5746 - acc: 0.7914 - val_loss: 0.2499 - val_acc: 0.9215\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.5644 - acc: 0.7961 - val_loss: 0.2666 - val_acc: 0.9202\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.5638 - acc: 0.7945 - val_loss: 0.2408 - val_acc: 0.9252\n",
      "Test accuracy: 0.9251726782971497\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 2s - loss: 2.4820 - acc: 0.0896 - val_loss: 2.4051 - val_acc: 0.0894\n",
      "Epoch 2/40\n",
      " - 1s - loss: 2.4045 - acc: 0.0937 - val_loss: 2.3989 - val_acc: 0.0846\n",
      "Epoch 3/40\n",
      " - 1s - loss: 2.4008 - acc: 0.0919 - val_loss: 2.3987 - val_acc: 0.0846\n",
      "Epoch 4/40\n",
      " - 1s - loss: 2.4008 - acc: 0.0911 - val_loss: 2.3979 - val_acc: 0.0913\n",
      "Epoch 5/40\n",
      " - 1s - loss: 2.4011 - acc: 0.0908 - val_loss: 2.3984 - val_acc: 0.0894\n",
      "Epoch 6/40\n",
      " - 1s - loss: 2.4007 - acc: 0.0914 - val_loss: 2.3987 - val_acc: 0.0846\n",
      "Epoch 7/40\n",
      " - 1s - loss: 2.4009 - acc: 0.0912 - val_loss: 2.3981 - val_acc: 0.0892\n",
      "Epoch 8/40\n",
      " - 1s - loss: 2.4016 - acc: 0.0894 - val_loss: 2.3981 - val_acc: 0.0877\n",
      "Epoch 9/40\n",
      " - 1s - loss: 2.4009 - acc: 0.0928 - val_loss: 2.3986 - val_acc: 0.0846\n",
      "Epoch 10/40\n",
      " - 1s - loss: 2.4000 - acc: 0.0970 - val_loss: 2.3986 - val_acc: 0.0846\n",
      "Epoch 11/40\n",
      " - 1s - loss: 2.4006 - acc: 0.0933 - val_loss: 2.3981 - val_acc: 0.0871\n",
      "Epoch 12/40\n",
      " - 1s - loss: 2.4009 - acc: 0.0934 - val_loss: 2.3983 - val_acc: 0.0846\n",
      "Epoch 13/40\n",
      " - 1s - loss: 2.4015 - acc: 0.0895 - val_loss: 2.3985 - val_acc: 0.0877\n",
      "Epoch 14/40\n",
      " - 1s - loss: 2.4002 - acc: 0.0924 - val_loss: 2.3992 - val_acc: 0.0846\n",
      "Epoch 15/40\n",
      " - 1s - loss: 2.4014 - acc: 0.0898 - val_loss: 2.3982 - val_acc: 0.0846\n",
      "Epoch 16/40\n",
      " - 1s - loss: 2.4004 - acc: 0.0905 - val_loss: 2.3953 - val_acc: 0.1433\n",
      "Epoch 17/40\n",
      " - 1s - loss: 2.3977 - acc: 0.0931 - val_loss: 2.3750 - val_acc: 0.1111\n",
      "Epoch 18/40\n",
      " - 1s - loss: 2.3794 - acc: 0.1025 - val_loss: 2.3125 - val_acc: 0.2214\n",
      "Epoch 19/40\n",
      " - 1s - loss: 2.3298 - acc: 0.1244 - val_loss: 2.1889 - val_acc: 0.2341\n",
      "Epoch 20/40\n",
      " - 1s - loss: 2.2411 - acc: 0.1506 - val_loss: 2.0540 - val_acc: 0.2721\n",
      "Epoch 21/40\n",
      " - 1s - loss: 2.1472 - acc: 0.1803 - val_loss: 1.9719 - val_acc: 0.2861\n",
      "Epoch 22/40\n",
      " - 1s - loss: 2.0739 - acc: 0.2028 - val_loss: 1.8854 - val_acc: 0.3404\n",
      "Epoch 23/40\n",
      " - 1s - loss: 2.0009 - acc: 0.2240 - val_loss: 1.7871 - val_acc: 0.3663\n",
      "Epoch 24/40\n",
      " - 1s - loss: 1.9377 - acc: 0.2433 - val_loss: 1.7075 - val_acc: 0.4415\n",
      "Epoch 25/40\n",
      " - 1s - loss: 1.8772 - acc: 0.2678 - val_loss: 1.6099 - val_acc: 0.4710\n",
      "Epoch 26/40\n",
      " - 1s - loss: 1.8243 - acc: 0.2807 - val_loss: 1.5679 - val_acc: 0.4752\n",
      "Epoch 27/40\n",
      " - 1s - loss: 1.7648 - acc: 0.2975 - val_loss: 1.4680 - val_acc: 0.5044\n",
      "Epoch 28/40\n",
      " - 1s - loss: 1.7208 - acc: 0.3091 - val_loss: 1.4185 - val_acc: 0.5134\n",
      "Epoch 29/40\n",
      " - 1s - loss: 1.6841 - acc: 0.3215 - val_loss: 1.3788 - val_acc: 0.5372\n",
      "Epoch 30/40\n",
      " - 1s - loss: 1.6400 - acc: 0.3309 - val_loss: 1.3006 - val_acc: 0.5652\n",
      "Epoch 31/40\n",
      " - 1s - loss: 1.6098 - acc: 0.3454 - val_loss: 1.2841 - val_acc: 0.5835\n",
      "Epoch 32/40\n",
      " - 1s - loss: 1.5920 - acc: 0.3499 - val_loss: 1.2335 - val_acc: 0.5911\n",
      "Epoch 33/40\n",
      " - 1s - loss: 1.5613 - acc: 0.3590 - val_loss: 1.1968 - val_acc: 0.5815\n",
      "Epoch 34/40\n",
      " - 1s - loss: 1.5470 - acc: 0.3656 - val_loss: 1.1819 - val_acc: 0.6122\n",
      "Epoch 35/40\n",
      " - 1s - loss: 1.5235 - acc: 0.3754 - val_loss: 1.1388 - val_acc: 0.6314\n",
      "Epoch 36/40\n",
      " - 1s - loss: 1.5053 - acc: 0.3817 - val_loss: 1.1665 - val_acc: 0.6255\n",
      "Epoch 37/40\n",
      " - 1s - loss: 1.4807 - acc: 0.3846 - val_loss: 1.0902 - val_acc: 0.6253\n",
      "Epoch 38/40\n",
      " - 1s - loss: 1.4580 - acc: 0.3929 - val_loss: 1.0918 - val_acc: 0.6568\n",
      "Epoch 39/40\n",
      " - 2s - loss: 1.4435 - acc: 0.4044 - val_loss: 1.0607 - val_acc: 0.6790\n",
      "Epoch 40/40\n",
      " - 1s - loss: 1.4314 - acc: 0.4110 - val_loss: 1.0360 - val_acc: 0.6930\n",
      "Test accuracy: 0.6930161165166432\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 3s - loss: 2.6593 - acc: 0.0906 - val_loss: 2.4012 - val_acc: 0.0877\n",
      "Epoch 2/40\n",
      " - 2s - loss: 2.4320 - acc: 0.0899 - val_loss: 2.3982 - val_acc: 0.0877\n",
      "Epoch 3/40\n",
      " - 2s - loss: 2.4303 - acc: 0.0891 - val_loss: 2.3980 - val_acc: 0.0917\n",
      "Epoch 4/40\n",
      " - 2s - loss: 2.4300 - acc: 0.0896 - val_loss: 2.3978 - val_acc: 0.0904\n",
      "Epoch 5/40\n",
      " - 2s - loss: 2.4332 - acc: 0.0893 - val_loss: 2.3976 - val_acc: 0.0846\n",
      "Epoch 6/40\n",
      " - 2s - loss: 2.4258 - acc: 0.0932 - val_loss: 2.3975 - val_acc: 0.0917\n",
      "Epoch 7/40\n",
      " - 2s - loss: 2.4305 - acc: 0.0893 - val_loss: 2.3978 - val_acc: 0.0931\n",
      "Epoch 8/40\n",
      " - 2s - loss: 2.4272 - acc: 0.0889 - val_loss: 2.3930 - val_acc: 0.1245\n",
      "Epoch 9/40\n",
      " - 2s - loss: 2.4203 - acc: 0.0981 - val_loss: 2.3644 - val_acc: 0.1101\n",
      "Epoch 10/40\n",
      " - 2s - loss: 2.4046 - acc: 0.1025 - val_loss: 2.3215 - val_acc: 0.1928\n",
      "Epoch 11/40\n",
      " - 2s - loss: 2.3747 - acc: 0.1160 - val_loss: 2.2768 - val_acc: 0.2047\n",
      "Epoch 12/40\n",
      " - 2s - loss: 2.3524 - acc: 0.1254 - val_loss: 2.2346 - val_acc: 0.2274\n",
      "Epoch 13/40\n",
      " - 2s - loss: 2.3126 - acc: 0.1394 - val_loss: 2.1470 - val_acc: 0.2502\n",
      "Epoch 14/40\n",
      " - 2s - loss: 2.2523 - acc: 0.1676 - val_loss: 2.0406 - val_acc: 0.3089\n",
      "Epoch 15/40\n",
      " - 2s - loss: 2.2102 - acc: 0.1770 - val_loss: 1.9912 - val_acc: 0.3129\n",
      "Epoch 16/40\n",
      " - 2s - loss: 2.1502 - acc: 0.1977 - val_loss: 1.9098 - val_acc: 0.3974\n",
      "Epoch 17/40\n",
      " - 2s - loss: 2.1053 - acc: 0.2128 - val_loss: 1.8781 - val_acc: 0.4290\n",
      "Epoch 18/40\n",
      " - 2s - loss: 2.0472 - acc: 0.2365 - val_loss: 1.7934 - val_acc: 0.4570\n",
      "Epoch 19/40\n",
      " - 2s - loss: 2.0200 - acc: 0.2459 - val_loss: 1.6942 - val_acc: 0.4624\n",
      "Epoch 20/40\n",
      " - 2s - loss: 1.9793 - acc: 0.2546 - val_loss: 1.6632 - val_acc: 0.5140\n",
      "Epoch 21/40\n",
      " - 2s - loss: 1.9459 - acc: 0.2661 - val_loss: 1.6250 - val_acc: 0.5015\n",
      "Epoch 22/40\n",
      " - 2s - loss: 1.9102 - acc: 0.2825 - val_loss: 1.5895 - val_acc: 0.5447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40\n",
      " - 2s - loss: 1.8706 - acc: 0.2981 - val_loss: 1.5521 - val_acc: 0.5503\n",
      "Epoch 24/40\n",
      " - 2s - loss: 1.8540 - acc: 0.2973 - val_loss: 1.5065 - val_acc: 0.5541\n",
      "Epoch 25/40\n",
      " - 2s - loss: 1.8400 - acc: 0.3094 - val_loss: 1.4816 - val_acc: 0.5670\n",
      "Epoch 26/40\n",
      " - 2s - loss: 1.8109 - acc: 0.3173 - val_loss: 1.4570 - val_acc: 0.5735\n",
      "Epoch 27/40\n",
      " - 2s - loss: 1.7880 - acc: 0.3308 - val_loss: 1.4328 - val_acc: 0.5658\n",
      "Epoch 28/40\n",
      " - 2s - loss: 1.7567 - acc: 0.3462 - val_loss: 1.4430 - val_acc: 0.5737\n",
      "Epoch 29/40\n",
      " - 2s - loss: 1.7517 - acc: 0.3496 - val_loss: 1.4025 - val_acc: 0.5817\n",
      "Epoch 30/40\n",
      " - 2s - loss: 1.7440 - acc: 0.3503 - val_loss: 1.4122 - val_acc: 0.5794\n",
      "Epoch 31/40\n",
      " - 2s - loss: 1.7221 - acc: 0.3614 - val_loss: 1.3729 - val_acc: 0.5808\n",
      "Epoch 32/40\n",
      " - 2s - loss: 1.6956 - acc: 0.3634 - val_loss: 1.3322 - val_acc: 0.5927\n",
      "Epoch 33/40\n",
      " - 2s - loss: 1.6756 - acc: 0.3728 - val_loss: 1.3235 - val_acc: 0.5888\n",
      "Epoch 34/40\n",
      " - 2s - loss: 1.6735 - acc: 0.3772 - val_loss: 1.3294 - val_acc: 0.6101\n",
      "Epoch 35/40\n",
      " - 2s - loss: 1.6494 - acc: 0.3852 - val_loss: 1.2893 - val_acc: 0.5867\n",
      "Epoch 36/40\n",
      " - 2s - loss: 1.6337 - acc: 0.3910 - val_loss: 1.2434 - val_acc: 0.6117\n",
      "Epoch 37/40\n",
      " - 2s - loss: 1.6107 - acc: 0.4056 - val_loss: 1.2843 - val_acc: 0.6167\n",
      "Epoch 38/40\n",
      " - 2s - loss: 1.6034 - acc: 0.4039 - val_loss: 1.2255 - val_acc: 0.6452\n",
      "Epoch 39/40\n",
      " - 2s - loss: 1.5951 - acc: 0.4111 - val_loss: 1.2214 - val_acc: 0.6218\n",
      "Epoch 40/40\n",
      " - 2s - loss: 1.5815 - acc: 0.4161 - val_loss: 1.2092 - val_acc: 0.6130\n",
      "Test accuracy: 0.6130084420567921\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 3s - loss: 2.4632 - acc: 0.0960 - val_loss: 2.3900 - val_acc: 0.1107\n",
      "Epoch 2/40\n",
      " - 2s - loss: 2.3642 - acc: 0.1131 - val_loss: 2.2641 - val_acc: 0.1790\n",
      "Epoch 3/40\n",
      " - 2s - loss: 2.2719 - acc: 0.1434 - val_loss: 2.1104 - val_acc: 0.2465\n",
      "Epoch 4/40\n",
      " - 2s - loss: 2.1598 - acc: 0.2018 - val_loss: 1.9428 - val_acc: 0.3267\n",
      "Epoch 5/40\n",
      " - 2s - loss: 2.0218 - acc: 0.2610 - val_loss: 1.7416 - val_acc: 0.3927\n",
      "Epoch 6/40\n",
      " - 2s - loss: 1.8900 - acc: 0.3170 - val_loss: 1.5956 - val_acc: 0.4726\n",
      "Epoch 7/40\n",
      " - 2s - loss: 1.7755 - acc: 0.3540 - val_loss: 1.4548 - val_acc: 0.5276\n",
      "Epoch 8/40\n",
      " - 2s - loss: 1.6879 - acc: 0.3908 - val_loss: 1.3760 - val_acc: 0.5391\n",
      "Epoch 9/40\n",
      " - 2s - loss: 1.5908 - acc: 0.4220 - val_loss: 1.1984 - val_acc: 0.6048\n",
      "Epoch 10/40\n",
      " - 2s - loss: 1.4964 - acc: 0.4615 - val_loss: 1.1071 - val_acc: 0.6545\n",
      "Epoch 11/40\n",
      " - 2s - loss: 1.4013 - acc: 0.4928 - val_loss: 1.0293 - val_acc: 0.6700\n",
      "Epoch 12/40\n",
      " - 2s - loss: 1.3294 - acc: 0.5155 - val_loss: 0.9424 - val_acc: 0.7191\n",
      "Epoch 13/40\n",
      " - 2s - loss: 1.2573 - acc: 0.5363 - val_loss: 0.8393 - val_acc: 0.7352\n",
      "Epoch 14/40\n",
      " - 2s - loss: 1.1766 - acc: 0.5661 - val_loss: 0.8069 - val_acc: 0.7421\n",
      "Epoch 15/40\n",
      " - 2s - loss: 1.1264 - acc: 0.5902 - val_loss: 0.7362 - val_acc: 0.7692\n",
      "Epoch 16/40\n",
      " - 2s - loss: 1.0659 - acc: 0.6158 - val_loss: 0.6969 - val_acc: 0.7776\n",
      "Epoch 17/40\n",
      " - 2s - loss: 1.0013 - acc: 0.6358 - val_loss: 0.6542 - val_acc: 0.7878\n",
      "Epoch 18/40\n",
      " - 2s - loss: 0.9647 - acc: 0.6567 - val_loss: 0.6191 - val_acc: 0.7972\n",
      "Epoch 19/40\n",
      " - 2s - loss: 0.9271 - acc: 0.6638 - val_loss: 0.6053 - val_acc: 0.8120\n",
      "Epoch 20/40\n",
      " - 2s - loss: 0.8845 - acc: 0.6835 - val_loss: 0.5648 - val_acc: 0.8221\n",
      "Epoch 21/40\n",
      " - 2s - loss: 0.8598 - acc: 0.6974 - val_loss: 0.5489 - val_acc: 0.8266\n",
      "Epoch 22/40\n",
      " - 2s - loss: 0.8412 - acc: 0.7017 - val_loss: 0.5249 - val_acc: 0.8361\n",
      "Epoch 23/40\n",
      " - 2s - loss: 0.8094 - acc: 0.7160 - val_loss: 0.4994 - val_acc: 0.8436\n",
      "Epoch 24/40\n",
      " - 2s - loss: 0.7794 - acc: 0.7295 - val_loss: 0.4859 - val_acc: 0.8494\n",
      "Epoch 25/40\n",
      " - 2s - loss: 0.7526 - acc: 0.7365 - val_loss: 0.4835 - val_acc: 0.8538\n",
      "Epoch 26/40\n",
      " - 2s - loss: 0.7490 - acc: 0.7388 - val_loss: 0.4679 - val_acc: 0.8542\n",
      "Epoch 27/40\n",
      " - 2s - loss: 0.7195 - acc: 0.7488 - val_loss: 0.4389 - val_acc: 0.8668\n",
      "Epoch 28/40\n",
      " - 2s - loss: 0.7124 - acc: 0.7506 - val_loss: 0.4224 - val_acc: 0.8680\n",
      "Epoch 29/40\n",
      " - 2s - loss: 0.6742 - acc: 0.7655 - val_loss: 0.4298 - val_acc: 0.8716\n",
      "Epoch 30/40\n",
      " - 2s - loss: 0.6610 - acc: 0.7697 - val_loss: 0.3997 - val_acc: 0.8791\n",
      "Epoch 31/40\n",
      " - 2s - loss: 0.6465 - acc: 0.7751 - val_loss: 0.3959 - val_acc: 0.8782\n",
      "Epoch 32/40\n",
      " - 2s - loss: 0.6303 - acc: 0.7782 - val_loss: 0.3854 - val_acc: 0.8807\n",
      "Epoch 33/40\n",
      " - 2s - loss: 0.6227 - acc: 0.7814 - val_loss: 0.3989 - val_acc: 0.8851\n",
      "Epoch 34/40\n",
      " - 2s - loss: 0.6137 - acc: 0.7868 - val_loss: 0.3900 - val_acc: 0.8833\n",
      "Epoch 35/40\n",
      " - 2s - loss: 0.5934 - acc: 0.7897 - val_loss: 0.3757 - val_acc: 0.8870\n",
      "Epoch 36/40\n",
      " - 2s - loss: 0.5827 - acc: 0.7987 - val_loss: 0.3587 - val_acc: 0.8943\n",
      "Epoch 37/40\n",
      " - 2s - loss: 0.5679 - acc: 0.8030 - val_loss: 0.3470 - val_acc: 0.8922\n",
      "Epoch 38/40\n",
      " - 2s - loss: 0.5723 - acc: 0.8044 - val_loss: 0.3495 - val_acc: 0.8954\n",
      "Epoch 39/40\n",
      " - 2s - loss: 0.5544 - acc: 0.8078 - val_loss: 0.3460 - val_acc: 0.8964\n",
      "Epoch 40/40\n",
      " - 2s - loss: 0.5404 - acc: 0.8136 - val_loss: 0.3196 - val_acc: 0.9014\n",
      "Test accuracy: 0.9013814274293134\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 3s - loss: 2.5963 - acc: 0.0924 - val_loss: 2.3881 - val_acc: 0.1021\n",
      "Epoch 2/40\n",
      " - 2s - loss: 2.4234 - acc: 0.1052 - val_loss: 2.3639 - val_acc: 0.2157\n",
      "Epoch 3/40\n",
      " - 2s - loss: 2.3324 - acc: 0.1473 - val_loss: 2.1160 - val_acc: 0.3149\n",
      "Epoch 4/40\n",
      " - 2s - loss: 2.1839 - acc: 0.2240 - val_loss: 1.8617 - val_acc: 0.3883\n",
      "Epoch 5/40\n",
      " - 2s - loss: 2.0376 - acc: 0.2802 - val_loss: 1.6301 - val_acc: 0.4720\n",
      "Epoch 6/40\n",
      " - 2s - loss: 1.9010 - acc: 0.3262 - val_loss: 1.4625 - val_acc: 0.5067\n",
      "Epoch 7/40\n",
      " - 2s - loss: 1.7567 - acc: 0.3711 - val_loss: 1.3039 - val_acc: 0.5727\n",
      "Epoch 8/40\n",
      " - 2s - loss: 1.6306 - acc: 0.4114 - val_loss: 1.1464 - val_acc: 0.6203\n",
      "Epoch 9/40\n",
      " - 2s - loss: 1.5116 - acc: 0.4524 - val_loss: 1.0353 - val_acc: 0.6475\n",
      "Epoch 10/40\n",
      " - 2s - loss: 1.4067 - acc: 0.4926 - val_loss: 0.9454 - val_acc: 0.6681\n",
      "Epoch 11/40\n",
      " - 2s - loss: 1.3399 - acc: 0.5192 - val_loss: 0.8793 - val_acc: 0.6903\n",
      "Epoch 12/40\n",
      " - 2s - loss: 1.2649 - acc: 0.5495 - val_loss: 0.8343 - val_acc: 0.7087\n",
      "Epoch 13/40\n",
      " - 2s - loss: 1.1907 - acc: 0.5774 - val_loss: 0.7856 - val_acc: 0.7308\n",
      "Epoch 14/40\n",
      " - 2s - loss: 1.1464 - acc: 0.5885 - val_loss: 0.7218 - val_acc: 0.7552\n",
      "Epoch 15/40\n",
      " - 2s - loss: 1.0886 - acc: 0.6145 - val_loss: 0.6644 - val_acc: 0.7765\n",
      "Epoch 16/40\n",
      " - 2s - loss: 1.0594 - acc: 0.6263 - val_loss: 0.6670 - val_acc: 0.7736\n",
      "Epoch 17/40\n",
      " - 2s - loss: 1.0273 - acc: 0.6388 - val_loss: 0.6256 - val_acc: 0.7861\n",
      "Epoch 18/40\n",
      " - 2s - loss: 0.9792 - acc: 0.6540 - val_loss: 0.6065 - val_acc: 0.7983\n",
      "Epoch 19/40\n",
      " - 2s - loss: 0.9547 - acc: 0.6591 - val_loss: 0.5713 - val_acc: 0.7980\n",
      "Epoch 20/40\n",
      " - 2s - loss: 0.9331 - acc: 0.6716 - val_loss: 0.5539 - val_acc: 0.8139\n",
      "Epoch 21/40\n",
      " - 2s - loss: 0.9231 - acc: 0.6734 - val_loss: 0.5290 - val_acc: 0.8162\n",
      "Epoch 22/40\n",
      " - 2s - loss: 0.8853 - acc: 0.6880 - val_loss: 0.5394 - val_acc: 0.7976\n",
      "Epoch 23/40\n",
      " - 2s - loss: 0.8597 - acc: 0.6952 - val_loss: 0.5001 - val_acc: 0.8147\n",
      "Epoch 24/40\n",
      " - 2s - loss: 0.8370 - acc: 0.7064 - val_loss: 0.5154 - val_acc: 0.8225\n",
      "Epoch 25/40\n",
      " - 2s - loss: 0.8284 - acc: 0.7112 - val_loss: 0.4874 - val_acc: 0.8290\n",
      "Epoch 26/40\n",
      " - 2s - loss: 0.8030 - acc: 0.7134 - val_loss: 0.4895 - val_acc: 0.8208\n",
      "Epoch 27/40\n",
      " - 2s - loss: 0.8009 - acc: 0.7174 - val_loss: 0.4568 - val_acc: 0.8457\n",
      "Epoch 28/40\n",
      " - 2s - loss: 0.7820 - acc: 0.7231 - val_loss: 0.4840 - val_acc: 0.8377\n",
      "Epoch 29/40\n",
      " - 2s - loss: 0.7511 - acc: 0.7368 - val_loss: 0.4458 - val_acc: 0.8406\n",
      "Epoch 30/40\n",
      " - 2s - loss: 0.7430 - acc: 0.7405 - val_loss: 0.4162 - val_acc: 0.8617\n",
      "Epoch 31/40\n",
      " - 2s - loss: 0.7368 - acc: 0.7441 - val_loss: 0.4200 - val_acc: 0.8682\n",
      "Epoch 32/40\n",
      " - 2s - loss: 0.7228 - acc: 0.7530 - val_loss: 0.4202 - val_acc: 0.8659\n",
      "Epoch 33/40\n",
      " - 2s - loss: 0.7054 - acc: 0.7553 - val_loss: 0.3865 - val_acc: 0.8753\n",
      "Epoch 34/40\n",
      " - 2s - loss: 0.7010 - acc: 0.7654 - val_loss: 0.3852 - val_acc: 0.8739\n",
      "Epoch 35/40\n",
      " - 2s - loss: 0.6699 - acc: 0.7711 - val_loss: 0.3925 - val_acc: 0.8776\n",
      "Epoch 36/40\n",
      " - 2s - loss: 0.6670 - acc: 0.7757 - val_loss: 0.3795 - val_acc: 0.8816\n",
      "Epoch 37/40\n",
      " - 2s - loss: 0.6589 - acc: 0.7813 - val_loss: 0.3525 - val_acc: 0.8950\n",
      "Epoch 38/40\n",
      " - 2s - loss: 0.6444 - acc: 0.7837 - val_loss: 0.3576 - val_acc: 0.8950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/40\n",
      " - 2s - loss: 0.6454 - acc: 0.7843 - val_loss: 0.3415 - val_acc: 0.8998\n",
      "Epoch 40/40\n",
      " - 2s - loss: 0.6204 - acc: 0.7940 - val_loss: 0.3310 - val_acc: 0.9004\n",
      "Test accuracy: 0.9004221027938567\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 3s - loss: 2.5088 - acc: 0.1064 - val_loss: 2.3313 - val_acc: 0.1527\n",
      "Epoch 2/40\n",
      " - 2s - loss: 2.2135 - acc: 0.1993 - val_loss: 1.8760 - val_acc: 0.3701\n",
      "Epoch 3/40\n",
      " - 2s - loss: 1.8473 - acc: 0.3593 - val_loss: 1.4727 - val_acc: 0.5259\n",
      "Epoch 4/40\n",
      " - 2s - loss: 1.5365 - acc: 0.4782 - val_loss: 1.1675 - val_acc: 0.6251\n",
      "Epoch 5/40\n",
      " - 2s - loss: 1.2716 - acc: 0.5734 - val_loss: 0.9306 - val_acc: 0.7009\n",
      "Epoch 6/40\n",
      " - 2s - loss: 1.0745 - acc: 0.6395 - val_loss: 0.7881 - val_acc: 0.7421\n",
      "Epoch 7/40\n",
      " - 2s - loss: 0.9506 - acc: 0.6844 - val_loss: 0.6755 - val_acc: 0.7792\n",
      "Epoch 8/40\n",
      " - 2s - loss: 0.8342 - acc: 0.7276 - val_loss: 0.5952 - val_acc: 0.8060\n",
      "Epoch 9/40\n",
      " - 2s - loss: 0.7386 - acc: 0.7584 - val_loss: 0.5438 - val_acc: 0.8271\n",
      "Epoch 10/40\n",
      " - 2s - loss: 0.6829 - acc: 0.7730 - val_loss: 0.4890 - val_acc: 0.8431\n",
      "Epoch 11/40\n",
      " - 2s - loss: 0.6217 - acc: 0.7926 - val_loss: 0.4625 - val_acc: 0.8523\n",
      "Epoch 12/40\n",
      " - 2s - loss: 0.5843 - acc: 0.8110 - val_loss: 0.4406 - val_acc: 0.8626\n",
      "Epoch 13/40\n",
      " - 2s - loss: 0.5363 - acc: 0.8236 - val_loss: 0.4067 - val_acc: 0.8738\n",
      "Epoch 14/40\n",
      " - 2s - loss: 0.5107 - acc: 0.8337 - val_loss: 0.3920 - val_acc: 0.8768\n",
      "Epoch 15/40\n",
      " - 2s - loss: 0.4684 - acc: 0.8456 - val_loss: 0.3831 - val_acc: 0.8807\n",
      "Epoch 16/40\n",
      " - 2s - loss: 0.4441 - acc: 0.8518 - val_loss: 0.3516 - val_acc: 0.8908\n",
      "Epoch 17/40\n",
      " - 2s - loss: 0.4277 - acc: 0.8580 - val_loss: 0.3492 - val_acc: 0.8901\n",
      "Epoch 18/40\n",
      " - 2s - loss: 0.4038 - acc: 0.8667 - val_loss: 0.3398 - val_acc: 0.8952\n",
      "Epoch 19/40\n",
      " - 2s - loss: 0.3889 - acc: 0.8745 - val_loss: 0.3220 - val_acc: 0.9021\n",
      "Epoch 20/40\n",
      " - 2s - loss: 0.3711 - acc: 0.8781 - val_loss: 0.3340 - val_acc: 0.8956\n",
      "Epoch 21/40\n",
      " - 2s - loss: 0.3519 - acc: 0.8804 - val_loss: 0.3045 - val_acc: 0.9060\n",
      "Epoch 22/40\n",
      " - 2s - loss: 0.3456 - acc: 0.8853 - val_loss: 0.3035 - val_acc: 0.9092\n",
      "Epoch 23/40\n",
      " - 2s - loss: 0.3283 - acc: 0.8933 - val_loss: 0.2975 - val_acc: 0.9114\n",
      "Epoch 24/40\n",
      " - 2s - loss: 0.3105 - acc: 0.8979 - val_loss: 0.3104 - val_acc: 0.9052\n",
      "Epoch 25/40\n",
      " - 2s - loss: 0.3067 - acc: 0.8971 - val_loss: 0.2972 - val_acc: 0.9129\n",
      "Epoch 26/40\n",
      " - 2s - loss: 0.2918 - acc: 0.9012 - val_loss: 0.2984 - val_acc: 0.9123\n",
      "Epoch 27/40\n",
      " - 2s - loss: 0.2875 - acc: 0.9024 - val_loss: 0.2786 - val_acc: 0.9173\n",
      "Epoch 28/40\n",
      " - 2s - loss: 0.2788 - acc: 0.9060 - val_loss: 0.2880 - val_acc: 0.9144\n",
      "Epoch 29/40\n",
      " - 2s - loss: 0.2542 - acc: 0.9142 - val_loss: 0.2756 - val_acc: 0.9190\n",
      "Epoch 30/40\n",
      " - 2s - loss: 0.2611 - acc: 0.9114 - val_loss: 0.2811 - val_acc: 0.9183\n",
      "Epoch 31/40\n",
      " - 2s - loss: 0.2472 - acc: 0.9171 - val_loss: 0.2730 - val_acc: 0.9181\n",
      "Epoch 32/40\n",
      " - 2s - loss: 0.2419 - acc: 0.9191 - val_loss: 0.2883 - val_acc: 0.9171\n",
      "Epoch 33/40\n",
      " - 2s - loss: 0.2296 - acc: 0.9223 - val_loss: 0.2808 - val_acc: 0.9152\n",
      "Epoch 34/40\n",
      " - 2s - loss: 0.2237 - acc: 0.9245 - val_loss: 0.2738 - val_acc: 0.9211\n",
      "Epoch 35/40\n",
      " - 2s - loss: 0.2211 - acc: 0.9253 - val_loss: 0.2683 - val_acc: 0.9217\n",
      "Epoch 36/40\n",
      " - 2s - loss: 0.2212 - acc: 0.9248 - val_loss: 0.2836 - val_acc: 0.9208\n",
      "Epoch 37/40\n",
      " - 2s - loss: 0.2022 - acc: 0.9305 - val_loss: 0.2703 - val_acc: 0.9186\n",
      "Epoch 38/40\n",
      " - 2s - loss: 0.2091 - acc: 0.9291 - val_loss: 0.2616 - val_acc: 0.9273\n",
      "Epoch 39/40\n",
      " - 2s - loss: 0.1944 - acc: 0.9333 - val_loss: 0.2676 - val_acc: 0.9215\n",
      "Epoch 40/40\n",
      " - 2s - loss: 0.1915 - acc: 0.9361 - val_loss: 0.2754 - val_acc: 0.9200\n",
      "Test accuracy: 0.9199923254029163\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.4107 - acc: 0.1307 - val_loss: 2.0515 - val_acc: 0.3398\n",
      "Epoch 2/40\n",
      " - 2s - loss: 1.9896 - acc: 0.2961 - val_loss: 1.5587 - val_acc: 0.5048\n",
      "Epoch 3/40\n",
      " - 3s - loss: 1.6688 - acc: 0.4194 - val_loss: 1.2152 - val_acc: 0.6199\n",
      "Epoch 4/40\n",
      " - 3s - loss: 1.3870 - acc: 0.5268 - val_loss: 0.9292 - val_acc: 0.7201\n",
      "Epoch 5/40\n",
      " - 3s - loss: 1.1969 - acc: 0.5935 - val_loss: 0.7601 - val_acc: 0.7740\n",
      "Epoch 6/40\n",
      " - 3s - loss: 1.0373 - acc: 0.6481 - val_loss: 0.6303 - val_acc: 0.8060\n",
      "Epoch 7/40\n",
      " - 3s - loss: 0.9001 - acc: 0.6964 - val_loss: 0.5453 - val_acc: 0.8350\n",
      "Epoch 8/40\n",
      " - 3s - loss: 0.8309 - acc: 0.7257 - val_loss: 0.5274 - val_acc: 0.8408\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.7557 - acc: 0.7497 - val_loss: 0.4452 - val_acc: 0.8596\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.7062 - acc: 0.7684 - val_loss: 0.4297 - val_acc: 0.8713\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.6400 - acc: 0.7946 - val_loss: 0.3884 - val_acc: 0.8789\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.5954 - acc: 0.8084 - val_loss: 0.3600 - val_acc: 0.8853\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.5591 - acc: 0.8181 - val_loss: 0.3457 - val_acc: 0.8891\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.5288 - acc: 0.8297 - val_loss: 0.3519 - val_acc: 0.8908\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.4955 - acc: 0.8393 - val_loss: 0.3472 - val_acc: 0.8943\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.4713 - acc: 0.8494 - val_loss: 0.3128 - val_acc: 0.9050\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.4470 - acc: 0.8576 - val_loss: 0.3064 - val_acc: 0.9052\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.4327 - acc: 0.8607 - val_loss: 0.2903 - val_acc: 0.9104\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.4054 - acc: 0.8686 - val_loss: 0.2852 - val_acc: 0.9094\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.4011 - acc: 0.8727 - val_loss: 0.2751 - val_acc: 0.9139\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.3835 - acc: 0.8764 - val_loss: 0.2664 - val_acc: 0.9160\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.3768 - acc: 0.8781 - val_loss: 0.2575 - val_acc: 0.9198\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.3554 - acc: 0.8865 - val_loss: 0.2569 - val_acc: 0.9213\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.3420 - acc: 0.8897 - val_loss: 0.2657 - val_acc: 0.9198\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.3326 - acc: 0.8944 - val_loss: 0.2673 - val_acc: 0.9221\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.3122 - acc: 0.9021 - val_loss: 0.2705 - val_acc: 0.9196\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.3132 - acc: 0.9009 - val_loss: 0.2847 - val_acc: 0.9185\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.3083 - acc: 0.9021 - val_loss: 0.2557 - val_acc: 0.9211\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.2971 - acc: 0.9054 - val_loss: 0.2784 - val_acc: 0.9231\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.2922 - acc: 0.9080 - val_loss: 0.2704 - val_acc: 0.9259\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.2756 - acc: 0.9126 - val_loss: 0.2579 - val_acc: 0.9261\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.2667 - acc: 0.9140 - val_loss: 0.2657 - val_acc: 0.9281\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.2651 - acc: 0.9145 - val_loss: 0.2416 - val_acc: 0.9328\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.2536 - acc: 0.9203 - val_loss: 0.2600 - val_acc: 0.9323\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.2497 - acc: 0.9201 - val_loss: 0.2526 - val_acc: 0.9304\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.2378 - acc: 0.9260 - val_loss: 0.2446 - val_acc: 0.9305\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.2465 - acc: 0.9227 - val_loss: 0.2641 - val_acc: 0.9300\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.2375 - acc: 0.9263 - val_loss: 0.2550 - val_acc: 0.9296\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.2248 - acc: 0.9298 - val_loss: 0.2684 - val_acc: 0.9269\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.2280 - acc: 0.9290 - val_loss: 0.2586 - val_acc: 0.9313\n",
      "Test accuracy: 0.9313123561013047\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.2837 - acc: 0.1543 - val_loss: 2.0190 - val_acc: 0.2277\n",
      "Epoch 2/40\n",
      " - 3s - loss: 2.0076 - acc: 0.2385 - val_loss: 1.6732 - val_acc: 0.3465\n",
      "Epoch 3/40\n",
      " - 3s - loss: 1.7127 - acc: 0.3229 - val_loss: 1.3386 - val_acc: 0.5017\n",
      "Epoch 4/40\n",
      " - 3s - loss: 1.4357 - acc: 0.4548 - val_loss: 0.9716 - val_acc: 0.6898\n",
      "Epoch 5/40\n",
      " - 3s - loss: 1.1223 - acc: 0.6014 - val_loss: 0.6422 - val_acc: 0.7983\n",
      "Epoch 6/40\n",
      " - 3s - loss: 0.8777 - acc: 0.6996 - val_loss: 0.5113 - val_acc: 0.8348\n",
      "Epoch 7/40\n",
      " - 3s - loss: 0.7149 - acc: 0.7623 - val_loss: 0.3915 - val_acc: 0.8757\n",
      "Epoch 8/40\n",
      " - 3s - loss: 0.6028 - acc: 0.8021 - val_loss: 0.3621 - val_acc: 0.8801\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.5149 - acc: 0.8315 - val_loss: 0.3007 - val_acc: 0.9035\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.4640 - acc: 0.8481 - val_loss: 0.2896 - val_acc: 0.9077\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.4134 - acc: 0.8707 - val_loss: 0.3002 - val_acc: 0.9041\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.3735 - acc: 0.8831 - val_loss: 0.2664 - val_acc: 0.9169\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.3331 - acc: 0.8931 - val_loss: 0.2666 - val_acc: 0.9160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40\n",
      " - 3s - loss: 0.3081 - acc: 0.9006 - val_loss: 0.2629 - val_acc: 0.9188\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.2874 - acc: 0.9087 - val_loss: 0.3227 - val_acc: 0.9056\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.2690 - acc: 0.9161 - val_loss: 0.2458 - val_acc: 0.9200\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.2362 - acc: 0.9238 - val_loss: 0.2438 - val_acc: 0.9250\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.2324 - acc: 0.9230 - val_loss: 0.2333 - val_acc: 0.9298\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.2109 - acc: 0.9314 - val_loss: 0.2526 - val_acc: 0.9227\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.2037 - acc: 0.9345 - val_loss: 0.2543 - val_acc: 0.9286\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.1999 - acc: 0.9367 - val_loss: 0.2401 - val_acc: 0.9282\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.1872 - acc: 0.9396 - val_loss: 0.2316 - val_acc: 0.9365\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.1782 - acc: 0.9414 - val_loss: 0.2604 - val_acc: 0.9325\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.1595 - acc: 0.9476 - val_loss: 0.2548 - val_acc: 0.9330\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.1657 - acc: 0.9474 - val_loss: 0.2382 - val_acc: 0.9336\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.1454 - acc: 0.9518 - val_loss: 0.2700 - val_acc: 0.9325\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.1425 - acc: 0.9557 - val_loss: 0.2603 - val_acc: 0.9359\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.1354 - acc: 0.9560 - val_loss: 0.2752 - val_acc: 0.9325\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.1300 - acc: 0.9595 - val_loss: 0.2870 - val_acc: 0.9348\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.1337 - acc: 0.9577 - val_loss: 0.2701 - val_acc: 0.9346\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.1153 - acc: 0.9630 - val_loss: 0.2718 - val_acc: 0.9346\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.1173 - acc: 0.9638 - val_loss: 0.2664 - val_acc: 0.9386\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.1055 - acc: 0.9666 - val_loss: 0.2944 - val_acc: 0.9375\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.1044 - acc: 0.9681 - val_loss: 0.2747 - val_acc: 0.9378\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.1027 - acc: 0.9681 - val_loss: 0.3567 - val_acc: 0.9263\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.0936 - acc: 0.9704 - val_loss: 0.2930 - val_acc: 0.9392\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.1008 - acc: 0.9697 - val_loss: 0.2755 - val_acc: 0.9384\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.0902 - acc: 0.9709 - val_loss: 0.2694 - val_acc: 0.9388\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.0868 - acc: 0.9728 - val_loss: 0.3003 - val_acc: 0.9327\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.0922 - acc: 0.9715 - val_loss: 0.3206 - val_acc: 0.9348\n",
      "Test accuracy: 0.9347659247889486\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.2386 - acc: 0.1981 - val_loss: 1.8270 - val_acc: 0.4340\n",
      "Epoch 2/40\n",
      " - 3s - loss: 1.6960 - acc: 0.4078 - val_loss: 1.1295 - val_acc: 0.6562\n",
      "Epoch 3/40\n",
      " - 3s - loss: 1.2553 - acc: 0.5653 - val_loss: 0.7692 - val_acc: 0.7726\n",
      "Epoch 4/40\n",
      " - 3s - loss: 0.9568 - acc: 0.6709 - val_loss: 0.5916 - val_acc: 0.8093\n",
      "Epoch 5/40\n",
      " - 3s - loss: 0.7812 - acc: 0.7313 - val_loss: 0.4965 - val_acc: 0.8490\n",
      "Epoch 6/40\n",
      " - 3s - loss: 0.6543 - acc: 0.7777 - val_loss: 0.4274 - val_acc: 0.8619\n",
      "Epoch 7/40\n",
      " - 3s - loss: 0.5713 - acc: 0.8120 - val_loss: 0.3635 - val_acc: 0.8816\n",
      "Epoch 8/40\n",
      " - 3s - loss: 0.5058 - acc: 0.8356 - val_loss: 0.3424 - val_acc: 0.8885\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.4371 - acc: 0.8553 - val_loss: 0.2894 - val_acc: 0.9066\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.3914 - acc: 0.8706 - val_loss: 0.3069 - val_acc: 0.9021\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.3646 - acc: 0.8810 - val_loss: 0.2740 - val_acc: 0.9123\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.3316 - acc: 0.8930 - val_loss: 0.2631 - val_acc: 0.9171\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.2990 - acc: 0.9009 - val_loss: 0.2509 - val_acc: 0.9194\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.2812 - acc: 0.9070 - val_loss: 0.2653 - val_acc: 0.9200\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.2772 - acc: 0.9093 - val_loss: 0.2677 - val_acc: 0.9217\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.2591 - acc: 0.9174 - val_loss: 0.2749 - val_acc: 0.9198\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.2343 - acc: 0.9244 - val_loss: 0.2405 - val_acc: 0.9284\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.2214 - acc: 0.9272 - val_loss: 0.2546 - val_acc: 0.9271\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.2036 - acc: 0.9334 - val_loss: 0.2557 - val_acc: 0.9302\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.2030 - acc: 0.9316 - val_loss: 0.2587 - val_acc: 0.9290\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.1928 - acc: 0.9359 - val_loss: 0.2955 - val_acc: 0.9213\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.1876 - acc: 0.9393 - val_loss: 0.2571 - val_acc: 0.9313\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.1725 - acc: 0.9442 - val_loss: 0.2588 - val_acc: 0.9298\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.1661 - acc: 0.9456 - val_loss: 0.2465 - val_acc: 0.9328\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.1582 - acc: 0.9474 - val_loss: 0.2509 - val_acc: 0.9363\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.1506 - acc: 0.9507 - val_loss: 0.2453 - val_acc: 0.9371\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.1473 - acc: 0.9516 - val_loss: 0.2459 - val_acc: 0.9382\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.1461 - acc: 0.9522 - val_loss: 0.2333 - val_acc: 0.9384\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.1365 - acc: 0.9573 - val_loss: 0.2634 - val_acc: 0.9365\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.1258 - acc: 0.9588 - val_loss: 0.2701 - val_acc: 0.9357\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.1181 - acc: 0.9614 - val_loss: 0.2475 - val_acc: 0.9396\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.1212 - acc: 0.9598 - val_loss: 0.2702 - val_acc: 0.9323\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.1125 - acc: 0.9621 - val_loss: 0.2604 - val_acc: 0.9363\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.1088 - acc: 0.9636 - val_loss: 0.2634 - val_acc: 0.9378\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.1107 - acc: 0.9650 - val_loss: 0.2707 - val_acc: 0.9373\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.1017 - acc: 0.9679 - val_loss: 0.2598 - val_acc: 0.9396\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.1030 - acc: 0.9673 - val_loss: 0.2595 - val_acc: 0.9405\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.1018 - acc: 0.9686 - val_loss: 0.2750 - val_acc: 0.9348\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.0892 - acc: 0.9725 - val_loss: 0.3159 - val_acc: 0.9317\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.0882 - acc: 0.9718 - val_loss: 0.2742 - val_acc: 0.9340\n",
      "Test accuracy: 0.9339984651720716\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.1678 - acc: 0.1865 - val_loss: 1.8544 - val_acc: 0.3296\n",
      "Epoch 2/40\n",
      " - 3s - loss: 1.6292 - acc: 0.4244 - val_loss: 1.0522 - val_acc: 0.6757\n",
      "Epoch 3/40\n",
      " - 3s - loss: 1.0230 - acc: 0.6572 - val_loss: 0.6488 - val_acc: 0.7945\n",
      "Epoch 4/40\n",
      " - 3s - loss: 0.7451 - acc: 0.7584 - val_loss: 0.4823 - val_acc: 0.8486\n",
      "Epoch 5/40\n",
      " - 3s - loss: 0.5748 - acc: 0.8106 - val_loss: 0.3864 - val_acc: 0.8726\n",
      "Epoch 6/40\n",
      " - 3s - loss: 0.4751 - acc: 0.8458 - val_loss: 0.3378 - val_acc: 0.8880\n",
      "Epoch 7/40\n",
      " - 3s - loss: 0.4244 - acc: 0.8617 - val_loss: 0.3221 - val_acc: 0.8935\n",
      "Epoch 8/40\n",
      " - 3s - loss: 0.3598 - acc: 0.8830 - val_loss: 0.3039 - val_acc: 0.9071\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.3256 - acc: 0.8936 - val_loss: 0.2826 - val_acc: 0.9083\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.3010 - acc: 0.9020 - val_loss: 0.2627 - val_acc: 0.9133\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.2739 - acc: 0.9090 - val_loss: 0.2369 - val_acc: 0.9221\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.2501 - acc: 0.9184 - val_loss: 0.2479 - val_acc: 0.9225\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.2330 - acc: 0.9226 - val_loss: 0.2448 - val_acc: 0.9242\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.2226 - acc: 0.9252 - val_loss: 0.2475 - val_acc: 0.9269\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.2060 - acc: 0.9313 - val_loss: 0.2258 - val_acc: 0.9304\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.1957 - acc: 0.9339 - val_loss: 0.2400 - val_acc: 0.9267\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.1887 - acc: 0.9383 - val_loss: 0.2197 - val_acc: 0.9317\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.1765 - acc: 0.9415 - val_loss: 0.2260 - val_acc: 0.9353\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.1594 - acc: 0.9479 - val_loss: 0.2200 - val_acc: 0.9321\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.1551 - acc: 0.9472 - val_loss: 0.2417 - val_acc: 0.9309\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.1495 - acc: 0.9477 - val_loss: 0.2221 - val_acc: 0.9340\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.1421 - acc: 0.9515 - val_loss: 0.2378 - val_acc: 0.9359\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.1309 - acc: 0.9565 - val_loss: 0.2200 - val_acc: 0.9365\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.1308 - acc: 0.9561 - val_loss: 0.2210 - val_acc: 0.9353\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.1283 - acc: 0.9593 - val_loss: 0.2263 - val_acc: 0.9344\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.1161 - acc: 0.9614 - val_loss: 0.2266 - val_acc: 0.9365\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.1158 - acc: 0.9600 - val_loss: 0.2393 - val_acc: 0.9365\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.1026 - acc: 0.9656 - val_loss: 0.2347 - val_acc: 0.9365\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.1078 - acc: 0.9634 - val_loss: 0.2229 - val_acc: 0.9399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/40\n",
      " - 3s - loss: 0.0999 - acc: 0.9656 - val_loss: 0.2477 - val_acc: 0.9340\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.0984 - acc: 0.9667 - val_loss: 0.2269 - val_acc: 0.9386\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.0928 - acc: 0.9691 - val_loss: 0.2205 - val_acc: 0.9398\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.0853 - acc: 0.9724 - val_loss: 0.2338 - val_acc: 0.9396\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.0863 - acc: 0.9709 - val_loss: 0.2383 - val_acc: 0.9388\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.0870 - acc: 0.9711 - val_loss: 0.2164 - val_acc: 0.9399\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.0854 - acc: 0.9706 - val_loss: 0.2478 - val_acc: 0.9422\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.0726 - acc: 0.9759 - val_loss: 0.2509 - val_acc: 0.9380\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.0782 - acc: 0.9736 - val_loss: 0.2381 - val_acc: 0.9376\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.0793 - acc: 0.9738 - val_loss: 0.2451 - val_acc: 0.9403\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.0733 - acc: 0.9761 - val_loss: 0.2610 - val_acc: 0.9386\n",
      "Test accuracy: 0.938603223285031\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.2432 - acc: 0.1705 - val_loss: 1.8592 - val_acc: 0.3498\n",
      "Epoch 2/40\n",
      " - 3s - loss: 1.6857 - acc: 0.3853 - val_loss: 1.1123 - val_acc: 0.6057\n",
      "Epoch 3/40\n",
      " - 3s - loss: 1.2069 - acc: 0.5839 - val_loss: 0.7357 - val_acc: 0.7713\n",
      "Epoch 4/40\n",
      " - 3s - loss: 0.8702 - acc: 0.7130 - val_loss: 0.5224 - val_acc: 0.8281\n",
      "Epoch 5/40\n",
      " - 3s - loss: 0.6939 - acc: 0.7731 - val_loss: 0.4359 - val_acc: 0.8663\n",
      "Epoch 6/40\n",
      " - 3s - loss: 0.5605 - acc: 0.8182 - val_loss: 0.3778 - val_acc: 0.8832\n",
      "Epoch 7/40\n",
      " - 3s - loss: 0.4813 - acc: 0.8459 - val_loss: 0.3314 - val_acc: 0.8977\n",
      "Epoch 8/40\n",
      " - 3s - loss: 0.4328 - acc: 0.8616 - val_loss: 0.3238 - val_acc: 0.8964\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.3814 - acc: 0.8804 - val_loss: 0.2902 - val_acc: 0.9116\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.3470 - acc: 0.8903 - val_loss: 0.2752 - val_acc: 0.9135\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.3169 - acc: 0.8985 - val_loss: 0.2782 - val_acc: 0.9135\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.2924 - acc: 0.9062 - val_loss: 0.2858 - val_acc: 0.9127\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.2763 - acc: 0.9120 - val_loss: 0.2479 - val_acc: 0.9202\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.2466 - acc: 0.9235 - val_loss: 0.2776 - val_acc: 0.9163\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.2324 - acc: 0.9252 - val_loss: 0.2464 - val_acc: 0.9234\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.2228 - acc: 0.9283 - val_loss: 0.2535 - val_acc: 0.9246\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.2134 - acc: 0.9326 - val_loss: 0.2477 - val_acc: 0.9284\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.1944 - acc: 0.9386 - val_loss: 0.2343 - val_acc: 0.9330\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.1834 - acc: 0.9403 - val_loss: 0.2443 - val_acc: 0.9294\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.1727 - acc: 0.9460 - val_loss: 0.2799 - val_acc: 0.9265\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.1730 - acc: 0.9459 - val_loss: 0.2494 - val_acc: 0.9307\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.1546 - acc: 0.9518 - val_loss: 0.2479 - val_acc: 0.9309\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.1577 - acc: 0.9491 - val_loss: 0.2588 - val_acc: 0.9313\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.1464 - acc: 0.9544 - val_loss: 0.2419 - val_acc: 0.9323\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.1406 - acc: 0.9543 - val_loss: 0.2557 - val_acc: 0.9275\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.1310 - acc: 0.9598 - val_loss: 0.2501 - val_acc: 0.9296\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.1320 - acc: 0.9574 - val_loss: 0.2537 - val_acc: 0.9317\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.1202 - acc: 0.9605 - val_loss: 0.2632 - val_acc: 0.9317\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.1168 - acc: 0.9624 - val_loss: 0.2724 - val_acc: 0.9319\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.1180 - acc: 0.9619 - val_loss: 0.2695 - val_acc: 0.9334\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.1146 - acc: 0.9630 - val_loss: 0.2500 - val_acc: 0.9338\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.1074 - acc: 0.9653 - val_loss: 0.2687 - val_acc: 0.9336\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.1071 - acc: 0.9672 - val_loss: 0.2967 - val_acc: 0.9292\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.0934 - acc: 0.9704 - val_loss: 0.2632 - val_acc: 0.9340\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.0974 - acc: 0.9683 - val_loss: 0.2715 - val_acc: 0.9348\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.1035 - acc: 0.9680 - val_loss: 0.2767 - val_acc: 0.9286\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.0779 - acc: 0.9764 - val_loss: 0.2776 - val_acc: 0.9330\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.0849 - acc: 0.9740 - val_loss: 0.2745 - val_acc: 0.9365\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.0803 - acc: 0.9747 - val_loss: 0.3068 - val_acc: 0.9271\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.0836 - acc: 0.9747 - val_loss: 0.2949 - val_acc: 0.9315\n",
      "Test accuracy: 0.9315042209826518\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.2877 - acc: 0.1497 - val_loss: 2.0078 - val_acc: 0.3078\n",
      "Epoch 2/40\n",
      " - 3s - loss: 1.9410 - acc: 0.2940 - val_loss: 1.6218 - val_acc: 0.4743\n",
      "Epoch 3/40\n",
      " - 3s - loss: 1.5371 - acc: 0.4676 - val_loss: 1.0196 - val_acc: 0.6888\n",
      "Epoch 4/40\n",
      " - 3s - loss: 1.1221 - acc: 0.6216 - val_loss: 0.6553 - val_acc: 0.8133\n",
      "Epoch 5/40\n",
      " - 3s - loss: 0.8444 - acc: 0.7275 - val_loss: 0.4968 - val_acc: 0.8496\n",
      "Epoch 6/40\n",
      " - 3s - loss: 0.6862 - acc: 0.7833 - val_loss: 0.4108 - val_acc: 0.8680\n",
      "Epoch 7/40\n",
      " - 3s - loss: 0.5707 - acc: 0.8205 - val_loss: 0.3470 - val_acc: 0.8918\n",
      "Epoch 8/40\n",
      " - 3s - loss: 0.5014 - acc: 0.8434 - val_loss: 0.3156 - val_acc: 0.8985\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.4424 - acc: 0.8643 - val_loss: 0.2936 - val_acc: 0.9056\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.3905 - acc: 0.8769 - val_loss: 0.2912 - val_acc: 0.9060\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.3543 - acc: 0.8893 - val_loss: 0.2718 - val_acc: 0.9129\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.3225 - acc: 0.8996 - val_loss: 0.2714 - val_acc: 0.9171\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.2958 - acc: 0.9074 - val_loss: 0.2521 - val_acc: 0.9227\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.2811 - acc: 0.9133 - val_loss: 0.2865 - val_acc: 0.9177\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.2597 - acc: 0.9177 - val_loss: 0.2485 - val_acc: 0.9259\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.2453 - acc: 0.9219 - val_loss: 0.2469 - val_acc: 0.9269\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.2313 - acc: 0.9270 - val_loss: 0.2499 - val_acc: 0.9302\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.2181 - acc: 0.9308 - val_loss: 0.2361 - val_acc: 0.9307\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.2032 - acc: 0.9358 - val_loss: 0.2427 - val_acc: 0.9309\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.1968 - acc: 0.9381 - val_loss: 0.2292 - val_acc: 0.9350\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.1895 - acc: 0.9407 - val_loss: 0.2476 - val_acc: 0.9292\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.1753 - acc: 0.9444 - val_loss: 0.2430 - val_acc: 0.9338\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.1648 - acc: 0.9475 - val_loss: 0.2633 - val_acc: 0.9292\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.1617 - acc: 0.9497 - val_loss: 0.2320 - val_acc: 0.9346\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.1482 - acc: 0.9530 - val_loss: 0.2362 - val_acc: 0.9380\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.1406 - acc: 0.9554 - val_loss: 0.2578 - val_acc: 0.9355\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.1345 - acc: 0.9571 - val_loss: 0.2264 - val_acc: 0.9403\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.1297 - acc: 0.9594 - val_loss: 0.2387 - val_acc: 0.9382\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.1281 - acc: 0.9584 - val_loss: 0.2647 - val_acc: 0.9330\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.1220 - acc: 0.9610 - val_loss: 0.2482 - val_acc: 0.9394\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.1174 - acc: 0.9622 - val_loss: 0.3015 - val_acc: 0.9315\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.1150 - acc: 0.9638 - val_loss: 0.2450 - val_acc: 0.9398\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.1103 - acc: 0.9645 - val_loss: 0.2652 - val_acc: 0.9394\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.1088 - acc: 0.9670 - val_loss: 0.2472 - val_acc: 0.9394\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.0982 - acc: 0.9690 - val_loss: 0.2890 - val_acc: 0.9363\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.0973 - acc: 0.9691 - val_loss: 0.2730 - val_acc: 0.9371\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.0977 - acc: 0.9684 - val_loss: 0.2915 - val_acc: 0.9336\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.0908 - acc: 0.9710 - val_loss: 0.2563 - val_acc: 0.9403\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.0880 - acc: 0.9710 - val_loss: 0.2646 - val_acc: 0.9392\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.0851 - acc: 0.9739 - val_loss: 0.2593 - val_acc: 0.9421\n",
      "Test accuracy: 0.9420567921099073\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.3721 - acc: 0.1250 - val_loss: 2.1242 - val_acc: 0.2283\n",
      "Epoch 2/40\n",
      " - 3s - loss: 2.0737 - acc: 0.2505 - val_loss: 1.7667 - val_acc: 0.4031\n",
      "Epoch 3/40\n",
      " - 3s - loss: 1.7576 - acc: 0.3902 - val_loss: 1.2611 - val_acc: 0.6529\n",
      "Epoch 4/40\n",
      " - 3s - loss: 1.3936 - acc: 0.5332 - val_loss: 0.8355 - val_acc: 0.7479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40\n",
      " - 3s - loss: 1.0997 - acc: 0.6313 - val_loss: 0.6394 - val_acc: 0.8068\n",
      "Epoch 6/40\n",
      " - 3s - loss: 0.8720 - acc: 0.7046 - val_loss: 0.5326 - val_acc: 0.8358\n",
      "Epoch 7/40\n",
      " - 3s - loss: 0.7318 - acc: 0.7636 - val_loss: 0.4306 - val_acc: 0.8699\n",
      "Epoch 8/40\n",
      " - 3s - loss: 0.6225 - acc: 0.7998 - val_loss: 0.3655 - val_acc: 0.8862\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.5524 - acc: 0.8216 - val_loss: 0.3357 - val_acc: 0.8950\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.4848 - acc: 0.8446 - val_loss: 0.3232 - val_acc: 0.8987\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.4402 - acc: 0.8583 - val_loss: 0.3159 - val_acc: 0.8998\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.4065 - acc: 0.8701 - val_loss: 0.2849 - val_acc: 0.9123\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.3666 - acc: 0.8818 - val_loss: 0.2732 - val_acc: 0.9154\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.3434 - acc: 0.8920 - val_loss: 0.2994 - val_acc: 0.9104\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.3170 - acc: 0.8999 - val_loss: 0.2636 - val_acc: 0.9225\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.3014 - acc: 0.9055 - val_loss: 0.2489 - val_acc: 0.9259\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.2763 - acc: 0.9134 - val_loss: 0.2586 - val_acc: 0.9261\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.2624 - acc: 0.9183 - val_loss: 0.2442 - val_acc: 0.9288\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.2472 - acc: 0.9213 - val_loss: 0.2533 - val_acc: 0.9267\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.2448 - acc: 0.9239 - val_loss: 0.2746 - val_acc: 0.9257\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.2202 - acc: 0.9293 - val_loss: 0.2429 - val_acc: 0.9321\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.2047 - acc: 0.9334 - val_loss: 0.2607 - val_acc: 0.9286\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.2022 - acc: 0.9340 - val_loss: 0.2486 - val_acc: 0.9317\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.1998 - acc: 0.9370 - val_loss: 0.2507 - val_acc: 0.9305\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.1903 - acc: 0.9392 - val_loss: 0.2300 - val_acc: 0.9359\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.1754 - acc: 0.9422 - val_loss: 0.2842 - val_acc: 0.9282\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.1761 - acc: 0.9429 - val_loss: 0.2625 - val_acc: 0.9355\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.1604 - acc: 0.9492 - val_loss: 0.2566 - val_acc: 0.9361\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.1573 - acc: 0.9502 - val_loss: 0.2643 - val_acc: 0.9317\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.1606 - acc: 0.9488 - val_loss: 0.2759 - val_acc: 0.9317\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.1466 - acc: 0.9528 - val_loss: 0.2623 - val_acc: 0.9375\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.1402 - acc: 0.9548 - val_loss: 0.2515 - val_acc: 0.9376\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.1295 - acc: 0.9574 - val_loss: 0.2822 - val_acc: 0.9330\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.1323 - acc: 0.9576 - val_loss: 0.2799 - val_acc: 0.9317\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.1256 - acc: 0.9606 - val_loss: 0.2694 - val_acc: 0.9342\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.1245 - acc: 0.9620 - val_loss: 0.2655 - val_acc: 0.9361\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.1178 - acc: 0.9621 - val_loss: 0.2729 - val_acc: 0.9344\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.1217 - acc: 0.9631 - val_loss: 0.2654 - val_acc: 0.9353\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.1109 - acc: 0.9641 - val_loss: 0.2649 - val_acc: 0.9346\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.1125 - acc: 0.9643 - val_loss: 0.2686 - val_acc: 0.9376\n",
      "Test accuracy: 0.9376438986953185\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 5s - loss: 2.2544 - acc: 0.1586 - val_loss: 1.8263 - val_acc: 0.3492\n",
      "Epoch 2/40\n",
      " - 3s - loss: 1.5543 - acc: 0.4748 - val_loss: 0.9461 - val_acc: 0.7134\n",
      "Epoch 3/40\n",
      " - 3s - loss: 0.9951 - acc: 0.6685 - val_loss: 0.6305 - val_acc: 0.7987\n",
      "Epoch 4/40\n",
      " - 3s - loss: 0.7257 - acc: 0.7601 - val_loss: 0.5413 - val_acc: 0.8181\n",
      "Epoch 5/40\n",
      " - 3s - loss: 0.5965 - acc: 0.8077 - val_loss: 0.4127 - val_acc: 0.8716\n",
      "Epoch 6/40\n",
      " - 3s - loss: 0.5068 - acc: 0.8415 - val_loss: 0.3630 - val_acc: 0.8851\n",
      "Epoch 7/40\n",
      " - 3s - loss: 0.4438 - acc: 0.8590 - val_loss: 0.3447 - val_acc: 0.8862\n",
      "Epoch 8/40\n",
      " - 3s - loss: 0.4049 - acc: 0.8710 - val_loss: 0.2953 - val_acc: 0.9025\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.3607 - acc: 0.8855 - val_loss: 0.2793 - val_acc: 0.9135\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.3405 - acc: 0.8926 - val_loss: 0.2627 - val_acc: 0.9185\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.3017 - acc: 0.9033 - val_loss: 0.2899 - val_acc: 0.9091\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.2837 - acc: 0.9107 - val_loss: 0.2636 - val_acc: 0.9131\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.2625 - acc: 0.9176 - val_loss: 0.2322 - val_acc: 0.9281\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.2382 - acc: 0.9228 - val_loss: 0.2455 - val_acc: 0.9225\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.2257 - acc: 0.9285 - val_loss: 0.2287 - val_acc: 0.9290\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.2032 - acc: 0.9338 - val_loss: 0.2553 - val_acc: 0.9208\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.1994 - acc: 0.9356 - val_loss: 0.2430 - val_acc: 0.9236\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.1751 - acc: 0.9431 - val_loss: 0.2276 - val_acc: 0.9311\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.1761 - acc: 0.9429 - val_loss: 0.2548 - val_acc: 0.9227\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.1621 - acc: 0.9470 - val_loss: 0.2482 - val_acc: 0.9256\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.1660 - acc: 0.9447 - val_loss: 0.2454 - val_acc: 0.9294\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.1377 - acc: 0.9542 - val_loss: 0.2223 - val_acc: 0.9355\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.1392 - acc: 0.9557 - val_loss: 0.2407 - val_acc: 0.9302\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.1334 - acc: 0.9566 - val_loss: 0.2450 - val_acc: 0.9300\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.1257 - acc: 0.9589 - val_loss: 0.2456 - val_acc: 0.9290\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.1218 - acc: 0.9594 - val_loss: 0.2384 - val_acc: 0.9350\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.1094 - acc: 0.9653 - val_loss: 0.2405 - val_acc: 0.9390\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.1114 - acc: 0.9639 - val_loss: 0.2540 - val_acc: 0.9328\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.0975 - acc: 0.9678 - val_loss: 0.2509 - val_acc: 0.9327\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.1016 - acc: 0.9675 - val_loss: 0.2571 - val_acc: 0.9290\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.0939 - acc: 0.9701 - val_loss: 0.2439 - val_acc: 0.9338\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.0963 - acc: 0.9697 - val_loss: 0.2598 - val_acc: 0.9317\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.0858 - acc: 0.9714 - val_loss: 0.2459 - val_acc: 0.9386\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.0807 - acc: 0.9741 - val_loss: 0.2490 - val_acc: 0.9373\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.0886 - acc: 0.9734 - val_loss: 0.2659 - val_acc: 0.9302\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.0847 - acc: 0.9738 - val_loss: 0.2592 - val_acc: 0.9309\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.0728 - acc: 0.9770 - val_loss: 0.2382 - val_acc: 0.9388\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.0730 - acc: 0.9773 - val_loss: 0.2737 - val_acc: 0.9382\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.0721 - acc: 0.9781 - val_loss: 0.2560 - val_acc: 0.9369\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.0721 - acc: 0.9781 - val_loss: 0.2656 - val_acc: 0.9342\n",
      "Test accuracy: 0.9341903298704421\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.4099 - acc: 0.1314 - val_loss: 2.2035 - val_acc: 0.2953\n",
      "Epoch 2/40\n",
      " - 3s - loss: 2.1464 - acc: 0.2346 - val_loss: 1.8225 - val_acc: 0.4378\n",
      "Epoch 3/40\n",
      " - 3s - loss: 1.8848 - acc: 0.3374 - val_loss: 1.3967 - val_acc: 0.5854\n",
      "Epoch 4/40\n",
      " - 3s - loss: 1.5803 - acc: 0.4604 - val_loss: 1.0660 - val_acc: 0.6679\n",
      "Epoch 5/40\n",
      " - 3s - loss: 1.3463 - acc: 0.5406 - val_loss: 0.8541 - val_acc: 0.7276\n",
      "Epoch 6/40\n",
      " - 3s - loss: 1.1372 - acc: 0.6166 - val_loss: 0.6935 - val_acc: 0.7776\n",
      "Epoch 7/40\n",
      " - 3s - loss: 0.9672 - acc: 0.6793 - val_loss: 0.5677 - val_acc: 0.8237\n",
      "Epoch 8/40\n",
      " - 3s - loss: 0.8660 - acc: 0.7161 - val_loss: 0.4927 - val_acc: 0.8477\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.7591 - acc: 0.7550 - val_loss: 0.4428 - val_acc: 0.8642\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.6943 - acc: 0.7755 - val_loss: 0.4150 - val_acc: 0.8653\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.6506 - acc: 0.7904 - val_loss: 0.3659 - val_acc: 0.8881\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.5912 - acc: 0.8067 - val_loss: 0.3420 - val_acc: 0.8954\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.5586 - acc: 0.8239 - val_loss: 0.3296 - val_acc: 0.8993\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.5283 - acc: 0.8315 - val_loss: 0.3266 - val_acc: 0.9025\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.4924 - acc: 0.8436 - val_loss: 0.3046 - val_acc: 0.9046\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.4614 - acc: 0.8504 - val_loss: 0.2960 - val_acc: 0.9110\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.4439 - acc: 0.8582 - val_loss: 0.2699 - val_acc: 0.9162\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.4226 - acc: 0.8652 - val_loss: 0.2795 - val_acc: 0.9154\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.4008 - acc: 0.8695 - val_loss: 0.2618 - val_acc: 0.9210\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.3913 - acc: 0.8744 - val_loss: 0.2712 - val_acc: 0.9169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40\n",
      " - 3s - loss: 0.3786 - acc: 0.8762 - val_loss: 0.2774 - val_acc: 0.9204\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.3569 - acc: 0.8843 - val_loss: 0.2419 - val_acc: 0.9259\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.3593 - acc: 0.8845 - val_loss: 0.2763 - val_acc: 0.9215\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.3413 - acc: 0.8887 - val_loss: 0.2512 - val_acc: 0.9273\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.3283 - acc: 0.8956 - val_loss: 0.2444 - val_acc: 0.9265\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.3274 - acc: 0.8964 - val_loss: 0.2411 - val_acc: 0.9279\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.3120 - acc: 0.8980 - val_loss: 0.2485 - val_acc: 0.9234\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.3019 - acc: 0.9018 - val_loss: 0.2297 - val_acc: 0.9286\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.2914 - acc: 0.9063 - val_loss: 0.2566 - val_acc: 0.9269\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.2868 - acc: 0.9072 - val_loss: 0.2267 - val_acc: 0.9338\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.2744 - acc: 0.9097 - val_loss: 0.2478 - val_acc: 0.9311\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.2652 - acc: 0.9148 - val_loss: 0.2451 - val_acc: 0.9259\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.2624 - acc: 0.9135 - val_loss: 0.2383 - val_acc: 0.9313\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.2610 - acc: 0.9130 - val_loss: 0.2300 - val_acc: 0.9332\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.2586 - acc: 0.9186 - val_loss: 0.2395 - val_acc: 0.9361\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.2422 - acc: 0.9181 - val_loss: 0.2303 - val_acc: 0.9369\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.2459 - acc: 0.9214 - val_loss: 0.2345 - val_acc: 0.9355\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.2299 - acc: 0.9268 - val_loss: 0.2423 - val_acc: 0.9304\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.2270 - acc: 0.9246 - val_loss: 0.2534 - val_acc: 0.9317\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.2291 - acc: 0.9238 - val_loss: 0.2454 - val_acc: 0.9340\n",
      "Test accuracy: 0.9339984650805833\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 5s - loss: 2.2787 - acc: 0.1463 - val_loss: 1.9764 - val_acc: 0.3139\n",
      "Epoch 2/40\n",
      " - 3s - loss: 1.7968 - acc: 0.3715 - val_loss: 1.2771 - val_acc: 0.5980\n",
      "Epoch 3/40\n",
      " - 3s - loss: 1.2012 - acc: 0.6003 - val_loss: 0.7812 - val_acc: 0.7464\n",
      "Epoch 4/40\n",
      " - 3s - loss: 0.8345 - acc: 0.7295 - val_loss: 0.5650 - val_acc: 0.8175\n",
      "Epoch 5/40\n",
      " - 3s - loss: 0.6440 - acc: 0.7884 - val_loss: 0.4646 - val_acc: 0.8494\n",
      "Epoch 6/40\n",
      " - 3s - loss: 0.5280 - acc: 0.8286 - val_loss: 0.4089 - val_acc: 0.8713\n",
      "Epoch 7/40\n",
      " - 3s - loss: 0.4555 - acc: 0.8522 - val_loss: 0.3717 - val_acc: 0.8843\n",
      "Epoch 8/40\n",
      " - 3s - loss: 0.3948 - acc: 0.8698 - val_loss: 0.3419 - val_acc: 0.8893\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.3548 - acc: 0.8818 - val_loss: 0.3194 - val_acc: 0.8964\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.3204 - acc: 0.8965 - val_loss: 0.3074 - val_acc: 0.9008\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.2933 - acc: 0.9046 - val_loss: 0.2619 - val_acc: 0.9179\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.2677 - acc: 0.9124 - val_loss: 0.2697 - val_acc: 0.9160\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.2474 - acc: 0.9166 - val_loss: 0.2518 - val_acc: 0.9242\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.2376 - acc: 0.9210 - val_loss: 0.2476 - val_acc: 0.9240\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.2064 - acc: 0.9320 - val_loss: 0.2473 - val_acc: 0.9246\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.2042 - acc: 0.9323 - val_loss: 0.2413 - val_acc: 0.9273\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.1918 - acc: 0.9362 - val_loss: 0.2548 - val_acc: 0.9284\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.1747 - acc: 0.9412 - val_loss: 0.2707 - val_acc: 0.9227\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.1715 - acc: 0.9427 - val_loss: 0.2595 - val_acc: 0.9211\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.1567 - acc: 0.9464 - val_loss: 0.2403 - val_acc: 0.9309\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.1548 - acc: 0.9491 - val_loss: 0.2491 - val_acc: 0.9305\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.1412 - acc: 0.9530 - val_loss: 0.2638 - val_acc: 0.9242\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.1402 - acc: 0.9536 - val_loss: 0.2586 - val_acc: 0.9298\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.1321 - acc: 0.9574 - val_loss: 0.2714 - val_acc: 0.9257\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.1184 - acc: 0.9598 - val_loss: 0.2458 - val_acc: 0.9351\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.1200 - acc: 0.9592 - val_loss: 0.2458 - val_acc: 0.9321\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.1098 - acc: 0.9628 - val_loss: 0.2489 - val_acc: 0.9351\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.1072 - acc: 0.9644 - val_loss: 0.2500 - val_acc: 0.9292\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.1033 - acc: 0.9645 - val_loss: 0.2489 - val_acc: 0.9375\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.1008 - acc: 0.9657 - val_loss: 0.2605 - val_acc: 0.9342\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.0901 - acc: 0.9693 - val_loss: 0.2759 - val_acc: 0.9313\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.0945 - acc: 0.9668 - val_loss: 0.2492 - val_acc: 0.9346\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.0927 - acc: 0.9697 - val_loss: 0.2527 - val_acc: 0.9363\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.0894 - acc: 0.9703 - val_loss: 0.2557 - val_acc: 0.9351\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.0762 - acc: 0.9750 - val_loss: 0.2587 - val_acc: 0.9363\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.0714 - acc: 0.9772 - val_loss: 0.2742 - val_acc: 0.9380\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.0747 - acc: 0.9759 - val_loss: 0.2757 - val_acc: 0.9361\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.0680 - acc: 0.9777 - val_loss: 0.2788 - val_acc: 0.9394\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.0668 - acc: 0.9768 - val_loss: 0.2786 - val_acc: 0.9327\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.0674 - acc: 0.9763 - val_loss: 0.2751 - val_acc: 0.9351\n",
      "Test accuracy: 0.9351496547346195\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.3097 - acc: 0.1539 - val_loss: 1.9920 - val_acc: 0.3007\n",
      "Epoch 2/40\n",
      " - 3s - loss: 1.9664 - acc: 0.2818 - val_loss: 1.6609 - val_acc: 0.4628\n",
      "Epoch 3/40\n",
      " - 3s - loss: 1.6968 - acc: 0.3872 - val_loss: 1.2848 - val_acc: 0.5959\n",
      "Epoch 4/40\n",
      " - 3s - loss: 1.3833 - acc: 0.5068 - val_loss: 0.9125 - val_acc: 0.6967\n",
      "Epoch 5/40\n",
      " - 3s - loss: 1.1127 - acc: 0.6086 - val_loss: 0.6684 - val_acc: 0.7782\n",
      "Epoch 6/40\n",
      " - 3s - loss: 0.9239 - acc: 0.6812 - val_loss: 0.5441 - val_acc: 0.8275\n",
      "Epoch 7/40\n",
      " - 3s - loss: 0.7873 - acc: 0.7347 - val_loss: 0.4558 - val_acc: 0.8565\n",
      "Epoch 8/40\n",
      " - 3s - loss: 0.6741 - acc: 0.7772 - val_loss: 0.4008 - val_acc: 0.8726\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.6032 - acc: 0.8056 - val_loss: 0.3627 - val_acc: 0.8824\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.5472 - acc: 0.8258 - val_loss: 0.3295 - val_acc: 0.8922\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.5007 - acc: 0.8393 - val_loss: 0.3508 - val_acc: 0.8893\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.4561 - acc: 0.8544 - val_loss: 0.3110 - val_acc: 0.9002\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.4174 - acc: 0.8697 - val_loss: 0.2761 - val_acc: 0.9112\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.3860 - acc: 0.8784 - val_loss: 0.2852 - val_acc: 0.9133\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.3660 - acc: 0.8876 - val_loss: 0.2563 - val_acc: 0.9179\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.3447 - acc: 0.8936 - val_loss: 0.2410 - val_acc: 0.9246\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.3271 - acc: 0.8998 - val_loss: 0.2594 - val_acc: 0.9210\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.2966 - acc: 0.9086 - val_loss: 0.2302 - val_acc: 0.9304\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.2957 - acc: 0.9084 - val_loss: 0.2463 - val_acc: 0.9246\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.2756 - acc: 0.9155 - val_loss: 0.2269 - val_acc: 0.9317\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.2564 - acc: 0.9208 - val_loss: 0.2270 - val_acc: 0.9319\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.2590 - acc: 0.9179 - val_loss: 0.2348 - val_acc: 0.9323\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.2416 - acc: 0.9244 - val_loss: 0.2548 - val_acc: 0.9313\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.2389 - acc: 0.9259 - val_loss: 0.2553 - val_acc: 0.9263\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.2265 - acc: 0.9284 - val_loss: 0.2196 - val_acc: 0.9355\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.2043 - acc: 0.9358 - val_loss: 0.2255 - val_acc: 0.9376\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.2057 - acc: 0.9344 - val_loss: 0.2256 - val_acc: 0.9351\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.1972 - acc: 0.9375 - val_loss: 0.2452 - val_acc: 0.9328\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.1953 - acc: 0.9374 - val_loss: 0.2406 - val_acc: 0.9350\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.1888 - acc: 0.9396 - val_loss: 0.2407 - val_acc: 0.9332\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.1774 - acc: 0.9457 - val_loss: 0.2347 - val_acc: 0.9375\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.1762 - acc: 0.9452 - val_loss: 0.2403 - val_acc: 0.9371\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.1658 - acc: 0.9479 - val_loss: 0.2281 - val_acc: 0.9373\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.1666 - acc: 0.9478 - val_loss: 0.2336 - val_acc: 0.9367\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.1579 - acc: 0.9510 - val_loss: 0.2588 - val_acc: 0.9290\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.1552 - acc: 0.9500 - val_loss: 0.2387 - val_acc: 0.9371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/40\n",
      " - 3s - loss: 0.1493 - acc: 0.9540 - val_loss: 0.2376 - val_acc: 0.9371\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.1424 - acc: 0.9543 - val_loss: 0.2551 - val_acc: 0.9351\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.1346 - acc: 0.9570 - val_loss: 0.2561 - val_acc: 0.9367\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.1464 - acc: 0.9556 - val_loss: 0.2587 - val_acc: 0.9355\n",
      "Test accuracy: 0.9355333845888022\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 5s - loss: 2.3825 - acc: 0.1243 - val_loss: 2.1058 - val_acc: 0.2661\n",
      "Epoch 2/40\n",
      " - 3s - loss: 2.0203 - acc: 0.2675 - val_loss: 1.6360 - val_acc: 0.4624\n",
      "Epoch 3/40\n",
      " - 3s - loss: 1.6641 - acc: 0.4285 - val_loss: 1.1483 - val_acc: 0.6303\n",
      "Epoch 4/40\n",
      " - 3s - loss: 1.3041 - acc: 0.5686 - val_loss: 0.7999 - val_acc: 0.7602\n",
      "Epoch 5/40\n",
      " - 3s - loss: 1.0105 - acc: 0.6750 - val_loss: 0.6301 - val_acc: 0.8064\n",
      "Epoch 6/40\n",
      " - 3s - loss: 0.8312 - acc: 0.7380 - val_loss: 0.4906 - val_acc: 0.8390\n",
      "Epoch 7/40\n",
      " - 3s - loss: 0.7223 - acc: 0.7715 - val_loss: 0.4437 - val_acc: 0.8573\n",
      "Epoch 8/40\n",
      " - 3s - loss: 0.6209 - acc: 0.8073 - val_loss: 0.3923 - val_acc: 0.8732\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.5531 - acc: 0.8241 - val_loss: 0.3512 - val_acc: 0.8904\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.4963 - acc: 0.8450 - val_loss: 0.3789 - val_acc: 0.8820\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.4557 - acc: 0.8568 - val_loss: 0.3179 - val_acc: 0.8968\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.4168 - acc: 0.8703 - val_loss: 0.2752 - val_acc: 0.9087\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.3905 - acc: 0.8780 - val_loss: 0.3193 - val_acc: 0.9037\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.3592 - acc: 0.8860 - val_loss: 0.2553 - val_acc: 0.9131\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.3408 - acc: 0.8930 - val_loss: 0.2432 - val_acc: 0.9204\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.3226 - acc: 0.8968 - val_loss: 0.2356 - val_acc: 0.9250\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.3000 - acc: 0.9026 - val_loss: 0.2408 - val_acc: 0.9213\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.2863 - acc: 0.9064 - val_loss: 0.2240 - val_acc: 0.9269\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.2773 - acc: 0.9119 - val_loss: 0.2322 - val_acc: 0.9284\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.2542 - acc: 0.9177 - val_loss: 0.2255 - val_acc: 0.9284\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.2570 - acc: 0.9167 - val_loss: 0.2203 - val_acc: 0.9313\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.2370 - acc: 0.9231 - val_loss: 0.2204 - val_acc: 0.9307\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.2259 - acc: 0.9263 - val_loss: 0.2144 - val_acc: 0.9327\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.2222 - acc: 0.9282 - val_loss: 0.2196 - val_acc: 0.9384\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.2080 - acc: 0.9303 - val_loss: 0.2328 - val_acc: 0.9317\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.1961 - acc: 0.9351 - val_loss: 0.2055 - val_acc: 0.9399\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.1902 - acc: 0.9378 - val_loss: 0.2193 - val_acc: 0.9384\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.1887 - acc: 0.9368 - val_loss: 0.2262 - val_acc: 0.9355\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.1755 - acc: 0.9438 - val_loss: 0.2088 - val_acc: 0.9386\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.1705 - acc: 0.9437 - val_loss: 0.2136 - val_acc: 0.9388\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.1782 - acc: 0.9418 - val_loss: 0.2316 - val_acc: 0.9371\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.1606 - acc: 0.9467 - val_loss: 0.2188 - val_acc: 0.9365\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.1596 - acc: 0.9482 - val_loss: 0.2172 - val_acc: 0.9428\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.1537 - acc: 0.9496 - val_loss: 0.2147 - val_acc: 0.9390\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.1501 - acc: 0.9513 - val_loss: 0.2165 - val_acc: 0.9455\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.1538 - acc: 0.9504 - val_loss: 0.2362 - val_acc: 0.9407\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.1358 - acc: 0.9548 - val_loss: 0.2188 - val_acc: 0.9451\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.1333 - acc: 0.9568 - val_loss: 0.2204 - val_acc: 0.9426\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.1269 - acc: 0.9585 - val_loss: 0.2518 - val_acc: 0.9407\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.1246 - acc: 0.9590 - val_loss: 0.2332 - val_acc: 0.9426\n",
      "Test accuracy: 0.942632386799693\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.3698 - acc: 0.1382 - val_loss: 2.1125 - val_acc: 0.3371\n",
      "Epoch 2/40\n",
      " - 2s - loss: 2.0014 - acc: 0.2964 - val_loss: 1.5661 - val_acc: 0.4973\n",
      "Epoch 3/40\n",
      " - 2s - loss: 1.6044 - acc: 0.4481 - val_loss: 1.0432 - val_acc: 0.6976\n",
      "Epoch 4/40\n",
      " - 2s - loss: 1.2099 - acc: 0.6050 - val_loss: 0.7493 - val_acc: 0.7807\n",
      "Epoch 5/40\n",
      " - 2s - loss: 0.9398 - acc: 0.7009 - val_loss: 0.5642 - val_acc: 0.8277\n",
      "Epoch 6/40\n",
      " - 2s - loss: 0.7769 - acc: 0.7520 - val_loss: 0.4655 - val_acc: 0.8532\n",
      "Epoch 7/40\n",
      " - 2s - loss: 0.6570 - acc: 0.7954 - val_loss: 0.4315 - val_acc: 0.8567\n",
      "Epoch 8/40\n",
      " - 2s - loss: 0.5823 - acc: 0.8172 - val_loss: 0.3642 - val_acc: 0.8830\n",
      "Epoch 9/40\n",
      " - 2s - loss: 0.5178 - acc: 0.8391 - val_loss: 0.3213 - val_acc: 0.8947\n",
      "Epoch 10/40\n",
      " - 2s - loss: 0.4753 - acc: 0.8491 - val_loss: 0.3168 - val_acc: 0.8970\n",
      "Epoch 11/40\n",
      " - 2s - loss: 0.4313 - acc: 0.8650 - val_loss: 0.2871 - val_acc: 0.9104\n",
      "Epoch 12/40\n",
      " - 2s - loss: 0.3984 - acc: 0.8740 - val_loss: 0.2775 - val_acc: 0.9100\n",
      "Epoch 13/40\n",
      " - 2s - loss: 0.3726 - acc: 0.8818 - val_loss: 0.2604 - val_acc: 0.9152\n",
      "Epoch 14/40\n",
      " - 2s - loss: 0.3475 - acc: 0.8894 - val_loss: 0.2693 - val_acc: 0.9162\n",
      "Epoch 15/40\n",
      " - 2s - loss: 0.3251 - acc: 0.8974 - val_loss: 0.2564 - val_acc: 0.9160\n",
      "Epoch 16/40\n",
      " - 2s - loss: 0.3083 - acc: 0.9015 - val_loss: 0.2727 - val_acc: 0.9154\n",
      "Epoch 17/40\n",
      " - 2s - loss: 0.2949 - acc: 0.9077 - val_loss: 0.2457 - val_acc: 0.9236\n",
      "Epoch 18/40\n",
      " - 2s - loss: 0.2841 - acc: 0.9086 - val_loss: 0.2440 - val_acc: 0.9231\n",
      "Epoch 19/40\n",
      " - 2s - loss: 0.2714 - acc: 0.9127 - val_loss: 0.2328 - val_acc: 0.9256\n",
      "Epoch 20/40\n",
      " - 2s - loss: 0.2555 - acc: 0.9166 - val_loss: 0.2726 - val_acc: 0.9215\n",
      "Epoch 21/40\n",
      " - 2s - loss: 0.2532 - acc: 0.9204 - val_loss: 0.2294 - val_acc: 0.9265\n",
      "Epoch 22/40\n",
      " - 2s - loss: 0.2276 - acc: 0.9244 - val_loss: 0.2388 - val_acc: 0.9294\n",
      "Epoch 23/40\n",
      " - 2s - loss: 0.2327 - acc: 0.9251 - val_loss: 0.2260 - val_acc: 0.9309\n",
      "Epoch 24/40\n",
      " - 2s - loss: 0.2183 - acc: 0.9286 - val_loss: 0.2344 - val_acc: 0.9269\n",
      "Epoch 25/40\n",
      " - 2s - loss: 0.2100 - acc: 0.9312 - val_loss: 0.2240 - val_acc: 0.9340\n",
      "Epoch 26/40\n",
      " - 2s - loss: 0.2008 - acc: 0.9353 - val_loss: 0.2343 - val_acc: 0.9340\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.1950 - acc: 0.9364 - val_loss: 0.2337 - val_acc: 0.9342\n",
      "Epoch 28/40\n",
      " - 2s - loss: 0.1890 - acc: 0.9369 - val_loss: 0.2336 - val_acc: 0.9304\n",
      "Epoch 29/40\n",
      " - 2s - loss: 0.1780 - acc: 0.9397 - val_loss: 0.2307 - val_acc: 0.9346\n",
      "Epoch 30/40\n",
      " - 2s - loss: 0.1736 - acc: 0.9424 - val_loss: 0.2522 - val_acc: 0.9325\n",
      "Epoch 31/40\n",
      " - 2s - loss: 0.1628 - acc: 0.9449 - val_loss: 0.2293 - val_acc: 0.9353\n",
      "Epoch 32/40\n",
      " - 2s - loss: 0.1723 - acc: 0.9438 - val_loss: 0.2176 - val_acc: 0.9386\n",
      "Epoch 33/40\n",
      " - 2s - loss: 0.1633 - acc: 0.9451 - val_loss: 0.2363 - val_acc: 0.9348\n",
      "Epoch 34/40\n",
      " - 2s - loss: 0.1651 - acc: 0.9446 - val_loss: 0.2142 - val_acc: 0.9371\n",
      "Epoch 35/40\n",
      " - 2s - loss: 0.1450 - acc: 0.9511 - val_loss: 0.2253 - val_acc: 0.9386\n",
      "Epoch 36/40\n",
      " - 2s - loss: 0.1412 - acc: 0.9536 - val_loss: 0.2233 - val_acc: 0.9399\n",
      "Epoch 37/40\n",
      " - 2s - loss: 0.1385 - acc: 0.9542 - val_loss: 0.2339 - val_acc: 0.9373\n",
      "Epoch 38/40\n",
      " - 2s - loss: 0.1396 - acc: 0.9537 - val_loss: 0.2475 - val_acc: 0.9357\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.1339 - acc: 0.9561 - val_loss: 0.2411 - val_acc: 0.9359\n",
      "Epoch 40/40\n",
      " - 2s - loss: 0.1311 - acc: 0.9553 - val_loss: 0.2216 - val_acc: 0.9411\n",
      "Test accuracy: 0.9410974674744507\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 6s - loss: 2.5249 - acc: 0.0939 - val_loss: 2.3970 - val_acc: 0.0908\n",
      "Epoch 2/40\n",
      " - 4s - loss: 2.3972 - acc: 0.0932 - val_loss: 2.3945 - val_acc: 0.0911\n",
      "Epoch 3/40\n",
      " - 4s - loss: 2.3668 - acc: 0.1143 - val_loss: 2.2375 - val_acc: 0.2343\n",
      "Epoch 4/40\n",
      " - 4s - loss: 2.2176 - acc: 0.1868 - val_loss: 1.9737 - val_acc: 0.3924\n",
      "Epoch 5/40\n",
      " - 4s - loss: 2.0449 - acc: 0.2684 - val_loss: 1.6888 - val_acc: 0.5190\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.8717 - acc: 0.3445 - val_loss: 1.4331 - val_acc: 0.6199\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.6975 - acc: 0.4174 - val_loss: 1.1730 - val_acc: 0.6633\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.5232 - acc: 0.4787 - val_loss: 0.9601 - val_acc: 0.7414\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.3630 - acc: 0.5365 - val_loss: 0.8251 - val_acc: 0.7621\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.2345 - acc: 0.5830 - val_loss: 0.6989 - val_acc: 0.7916\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1228 - acc: 0.6271 - val_loss: 0.5965 - val_acc: 0.8250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40\n",
      " - 4s - loss: 1.0178 - acc: 0.6679 - val_loss: 0.5279 - val_acc: 0.8367\n",
      "Epoch 13/40\n",
      " - 4s - loss: 0.9289 - acc: 0.6908 - val_loss: 0.4993 - val_acc: 0.8469\n",
      "Epoch 14/40\n",
      " - 4s - loss: 0.8630 - acc: 0.7162 - val_loss: 0.4431 - val_acc: 0.8642\n",
      "Epoch 15/40\n",
      " - 4s - loss: 0.8185 - acc: 0.7299 - val_loss: 0.4032 - val_acc: 0.8799\n",
      "Epoch 16/40\n",
      " - 4s - loss: 0.7676 - acc: 0.7470 - val_loss: 0.3958 - val_acc: 0.8803\n",
      "Epoch 17/40\n",
      " - 4s - loss: 0.7031 - acc: 0.7727 - val_loss: 0.3513 - val_acc: 0.8876\n",
      "Epoch 18/40\n",
      " - 4s - loss: 0.6719 - acc: 0.7767 - val_loss: 0.3314 - val_acc: 0.8962\n",
      "Epoch 19/40\n",
      " - 4s - loss: 0.6507 - acc: 0.7885 - val_loss: 0.3235 - val_acc: 0.9012\n",
      "Epoch 20/40\n",
      " - 4s - loss: 0.6187 - acc: 0.7992 - val_loss: 0.3175 - val_acc: 0.9045\n",
      "Epoch 21/40\n",
      " - 4s - loss: 0.5816 - acc: 0.8106 - val_loss: 0.2982 - val_acc: 0.9098\n",
      "Epoch 22/40\n",
      " - 4s - loss: 0.5628 - acc: 0.8150 - val_loss: 0.2794 - val_acc: 0.9133\n",
      "Epoch 23/40\n",
      " - 4s - loss: 0.5347 - acc: 0.8225 - val_loss: 0.2621 - val_acc: 0.9165\n",
      "Epoch 24/40\n",
      " - 4s - loss: 0.5190 - acc: 0.8294 - val_loss: 0.2569 - val_acc: 0.9211\n",
      "Epoch 25/40\n",
      " - 4s - loss: 0.4981 - acc: 0.8362 - val_loss: 0.2564 - val_acc: 0.9202\n",
      "Epoch 26/40\n",
      " - 4s - loss: 0.4777 - acc: 0.8425 - val_loss: 0.2531 - val_acc: 0.9213\n",
      "Epoch 27/40\n",
      " - 4s - loss: 0.4777 - acc: 0.8440 - val_loss: 0.2439 - val_acc: 0.9248\n",
      "Epoch 28/40\n",
      " - 4s - loss: 0.4443 - acc: 0.8551 - val_loss: 0.2392 - val_acc: 0.9290\n",
      "Epoch 29/40\n",
      " - 4s - loss: 0.4368 - acc: 0.8554 - val_loss: 0.2339 - val_acc: 0.9269\n",
      "Epoch 30/40\n",
      " - 4s - loss: 0.4236 - acc: 0.8590 - val_loss: 0.2324 - val_acc: 0.9294\n",
      "Epoch 31/40\n",
      " - 4s - loss: 0.4075 - acc: 0.8647 - val_loss: 0.2353 - val_acc: 0.9271\n",
      "Epoch 32/40\n",
      " - 4s - loss: 0.3910 - acc: 0.8701 - val_loss: 0.2243 - val_acc: 0.9319\n",
      "Epoch 33/40\n",
      " - 4s - loss: 0.3855 - acc: 0.8735 - val_loss: 0.2292 - val_acc: 0.9277\n",
      "Epoch 34/40\n",
      " - 4s - loss: 0.3862 - acc: 0.8693 - val_loss: 0.2201 - val_acc: 0.9328\n",
      "Epoch 35/40\n",
      " - 4s - loss: 0.3734 - acc: 0.8768 - val_loss: 0.2303 - val_acc: 0.9315\n",
      "Epoch 36/40\n",
      " - 4s - loss: 0.3809 - acc: 0.8729 - val_loss: 0.2162 - val_acc: 0.9346\n",
      "Epoch 37/40\n",
      " - 4s - loss: 0.3585 - acc: 0.8792 - val_loss: 0.2171 - val_acc: 0.9346\n",
      "Epoch 38/40\n",
      " - 4s - loss: 0.3540 - acc: 0.8805 - val_loss: 0.2116 - val_acc: 0.9363\n",
      "Epoch 39/40\n",
      " - 4s - loss: 0.3454 - acc: 0.8839 - val_loss: 0.2155 - val_acc: 0.9373\n",
      "Epoch 40/40\n",
      " - 4s - loss: 0.3423 - acc: 0.8858 - val_loss: 0.2238 - val_acc: 0.9346\n",
      "Test accuracy: 0.9345740597246248\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.4508 - acc: 0.0984 - val_loss: 2.3916 - val_acc: 0.1627\n",
      "Epoch 2/40\n",
      " - 3s - loss: 2.3370 - acc: 0.1393 - val_loss: 2.1266 - val_acc: 0.3461\n",
      "Epoch 3/40\n",
      " - 3s - loss: 2.1257 - acc: 0.2350 - val_loss: 1.8010 - val_acc: 0.4845\n",
      "Epoch 4/40\n",
      " - 3s - loss: 1.9077 - acc: 0.3184 - val_loss: 1.5168 - val_acc: 0.5829\n",
      "Epoch 5/40\n",
      " - 3s - loss: 1.7014 - acc: 0.4052 - val_loss: 1.2162 - val_acc: 0.6880\n",
      "Epoch 6/40\n",
      " - 3s - loss: 1.4748 - acc: 0.4912 - val_loss: 0.9074 - val_acc: 0.7533\n",
      "Epoch 7/40\n",
      " - 3s - loss: 1.2839 - acc: 0.5677 - val_loss: 0.7442 - val_acc: 0.7978\n",
      "Epoch 8/40\n",
      " - 3s - loss: 1.1231 - acc: 0.6222 - val_loss: 0.6193 - val_acc: 0.8223\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.9933 - acc: 0.6692 - val_loss: 0.5311 - val_acc: 0.8398\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.8968 - acc: 0.7028 - val_loss: 0.4745 - val_acc: 0.8584\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.8203 - acc: 0.7313 - val_loss: 0.4181 - val_acc: 0.8705\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.7510 - acc: 0.7569 - val_loss: 0.3736 - val_acc: 0.8860\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.6941 - acc: 0.7772 - val_loss: 0.3464 - val_acc: 0.8893\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.6387 - acc: 0.7908 - val_loss: 0.3181 - val_acc: 0.9000\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.6074 - acc: 0.8062 - val_loss: 0.3162 - val_acc: 0.8962\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.5642 - acc: 0.8185 - val_loss: 0.2931 - val_acc: 0.9048\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.5231 - acc: 0.8293 - val_loss: 0.2996 - val_acc: 0.9085\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.5052 - acc: 0.8379 - val_loss: 0.2707 - val_acc: 0.9135\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.4741 - acc: 0.8454 - val_loss: 0.2570 - val_acc: 0.9156\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.4571 - acc: 0.8534 - val_loss: 0.2516 - val_acc: 0.9202\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.4460 - acc: 0.8562 - val_loss: 0.2483 - val_acc: 0.9242\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.4226 - acc: 0.8653 - val_loss: 0.2409 - val_acc: 0.9248\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.4066 - acc: 0.8705 - val_loss: 0.2367 - val_acc: 0.9282\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.3873 - acc: 0.8760 - val_loss: 0.2351 - val_acc: 0.9250\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.3785 - acc: 0.8764 - val_loss: 0.2189 - val_acc: 0.9321\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.3714 - acc: 0.8808 - val_loss: 0.2354 - val_acc: 0.9267\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.3603 - acc: 0.8812 - val_loss: 0.2166 - val_acc: 0.9351\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.3424 - acc: 0.8881 - val_loss: 0.2210 - val_acc: 0.9319\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.3410 - acc: 0.8914 - val_loss: 0.2268 - val_acc: 0.9309\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.3215 - acc: 0.8960 - val_loss: 0.2135 - val_acc: 0.9346\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.3193 - acc: 0.8949 - val_loss: 0.2172 - val_acc: 0.9325\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.3069 - acc: 0.8980 - val_loss: 0.2052 - val_acc: 0.9336\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.3098 - acc: 0.9007 - val_loss: 0.2157 - val_acc: 0.9363\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.2993 - acc: 0.9023 - val_loss: 0.2085 - val_acc: 0.9369\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.2892 - acc: 0.9046 - val_loss: 0.2191 - val_acc: 0.9353\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.2871 - acc: 0.9057 - val_loss: 0.2094 - val_acc: 0.9359\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.2786 - acc: 0.9090 - val_loss: 0.2022 - val_acc: 0.9394\n",
      "Epoch 38/40\n",
      " - 3s - loss: nan - acc: 0.1407 - val_loss: nan - val_acc: 0.0931\n",
      "Epoch 39/40\n",
      " - 3s - loss: nan - acc: 0.0898 - val_loss: nan - val_acc: 0.0931\n",
      "Epoch 40/40\n",
      " - 3s - loss: nan - acc: 0.0898 - val_loss: nan - val_acc: 0.0931\n",
      "Test accuracy: 0.093054489656448\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.4664 - acc: 0.0897 - val_loss: 2.3922 - val_acc: 0.0963\n",
      "Epoch 2/40\n",
      " - 3s - loss: 2.2853 - acc: 0.1652 - val_loss: 1.9941 - val_acc: 0.3479\n",
      "Epoch 3/40\n",
      " - 3s - loss: 1.9334 - acc: 0.3204 - val_loss: 1.5392 - val_acc: 0.5217\n",
      "Epoch 4/40\n",
      " - 2s - loss: 1.6222 - acc: 0.4547 - val_loss: 1.1340 - val_acc: 0.6600\n",
      "Epoch 5/40\n",
      " - 2s - loss: 1.3108 - acc: 0.5735 - val_loss: 0.8080 - val_acc: 0.7546\n",
      "Epoch 6/40\n",
      " - 2s - loss: 1.0644 - acc: 0.6576 - val_loss: 0.6341 - val_acc: 0.7949\n",
      "Epoch 7/40\n",
      " - 2s - loss: 0.9103 - acc: 0.7087 - val_loss: 0.5249 - val_acc: 0.8269\n",
      "Epoch 8/40\n",
      " - 2s - loss: 0.7951 - acc: 0.7498 - val_loss: 0.4892 - val_acc: 0.8413\n",
      "Epoch 9/40\n",
      " - 2s - loss: 0.7090 - acc: 0.7779 - val_loss: 0.4348 - val_acc: 0.8580\n",
      "Epoch 10/40\n",
      " - 2s - loss: 0.6441 - acc: 0.7961 - val_loss: 0.3870 - val_acc: 0.8743\n",
      "Epoch 11/40\n",
      " - 2s - loss: 0.6101 - acc: 0.8072 - val_loss: 0.3372 - val_acc: 0.8912\n",
      "Epoch 12/40\n",
      " - 2s - loss: 0.5410 - acc: 0.8295 - val_loss: 0.3426 - val_acc: 0.8849\n",
      "Epoch 13/40\n",
      " - 2s - loss: 0.5188 - acc: 0.8377 - val_loss: 0.3177 - val_acc: 0.8962\n",
      "Epoch 14/40\n",
      " - 2s - loss: 0.4808 - acc: 0.8477 - val_loss: 0.3025 - val_acc: 0.9006\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.4613 - acc: 0.8537 - val_loss: 0.2890 - val_acc: 0.9075\n",
      "Epoch 16/40\n",
      " - 2s - loss: 0.4419 - acc: 0.8622 - val_loss: 0.2786 - val_acc: 0.9073\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.4227 - acc: 0.8674 - val_loss: 0.2790 - val_acc: 0.9079\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.3901 - acc: 0.8750 - val_loss: 0.2692 - val_acc: 0.9139\n",
      "Epoch 19/40\n",
      " - 2s - loss: 0.3827 - acc: 0.8780 - val_loss: 0.2562 - val_acc: 0.9154\n",
      "Epoch 20/40\n",
      " - 2s - loss: 0.3660 - acc: 0.8865 - val_loss: 0.2687 - val_acc: 0.9150\n",
      "Epoch 21/40\n",
      " - 2s - loss: 0.3573 - acc: 0.8856 - val_loss: 0.2583 - val_acc: 0.9160\n",
      "Epoch 22/40\n",
      " - 2s - loss: 0.3420 - acc: 0.8906 - val_loss: 0.2402 - val_acc: 0.9231\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.3322 - acc: 0.8930 - val_loss: 0.2496 - val_acc: 0.9198\n",
      "Epoch 24/40\n",
      " - 2s - loss: 0.3225 - acc: 0.8961 - val_loss: 0.2466 - val_acc: 0.9236\n",
      "Epoch 25/40\n",
      " - 2s - loss: 0.3060 - acc: 0.9019 - val_loss: 0.2405 - val_acc: 0.9234\n",
      "Epoch 26/40\n",
      " - 2s - loss: 0.2952 - acc: 0.9044 - val_loss: 0.2395 - val_acc: 0.9259\n",
      "Epoch 27/40\n",
      " - 2s - loss: 0.2977 - acc: 0.9058 - val_loss: 0.2363 - val_acc: 0.9246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/40\n",
      " - 3s - loss: 0.2829 - acc: 0.9085 - val_loss: 0.2311 - val_acc: 0.9248\n",
      "Epoch 29/40\n",
      " - 2s - loss: 0.2852 - acc: 0.9056 - val_loss: 0.2342 - val_acc: 0.9263\n",
      "Epoch 30/40\n",
      " - 2s - loss: 0.2735 - acc: 0.9129 - val_loss: 0.2405 - val_acc: 0.9248\n",
      "Epoch 31/40\n",
      " - 2s - loss: 0.2720 - acc: 0.9121 - val_loss: 0.2294 - val_acc: 0.9284\n",
      "Epoch 32/40\n",
      " - 2s - loss: 0.2645 - acc: 0.9147 - val_loss: 0.2126 - val_acc: 0.9365\n",
      "Epoch 33/40\n",
      " - 2s - loss: 0.2588 - acc: 0.9162 - val_loss: 0.2406 - val_acc: 0.9259\n",
      "Epoch 34/40\n",
      " - 2s - loss: 0.2429 - acc: 0.9175 - val_loss: 0.2343 - val_acc: 0.9309\n",
      "Epoch 35/40\n",
      " - 2s - loss: 0.2474 - acc: 0.9209 - val_loss: 0.2187 - val_acc: 0.9319\n",
      "Epoch 36/40\n",
      " - 2s - loss: 0.2295 - acc: 0.9254 - val_loss: 0.2220 - val_acc: 0.9340\n",
      "Epoch 37/40\n",
      " - 2s - loss: 0.2264 - acc: 0.9269 - val_loss: 0.2280 - val_acc: 0.9334\n",
      "Epoch 38/40\n",
      " - 2s - loss: 0.2270 - acc: 0.9260 - val_loss: 0.2253 - val_acc: 0.9319\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.2187 - acc: 0.9280 - val_loss: 0.2302 - val_acc: 0.9328\n",
      "Epoch 40/40\n",
      " - 2s - loss: 0.2154 - acc: 0.9291 - val_loss: 0.2209 - val_acc: 0.9355\n",
      "Test accuracy: 0.9355333845888022\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.4166 - acc: 0.0928 - val_loss: 2.3979 - val_acc: 0.0931\n",
      "Epoch 2/40\n",
      " - 2s - loss: 2.3998 - acc: 0.0908 - val_loss: 2.3979 - val_acc: 0.0931\n",
      "Epoch 3/40\n",
      " - 2s - loss: 2.3998 - acc: 0.0924 - val_loss: 2.3979 - val_acc: 0.0931\n",
      "Epoch 4/40\n",
      " - 2s - loss: 2.4000 - acc: 0.0906 - val_loss: 2.3979 - val_acc: 0.0931\n",
      "Epoch 5/40\n",
      " - 2s - loss: 2.3991 - acc: 0.0920 - val_loss: 2.3979 - val_acc: 0.1061\n",
      "Epoch 6/40\n",
      " - 2s - loss: 2.3987 - acc: 0.0891 - val_loss: 2.3979 - val_acc: 0.0931\n",
      "Epoch 7/40\n",
      " - 2s - loss: 2.3986 - acc: 0.0901 - val_loss: 2.3979 - val_acc: 0.0931\n",
      "Epoch 8/40\n",
      " - 2s - loss: 2.3987 - acc: 0.0916 - val_loss: 2.3979 - val_acc: 0.0898\n",
      "Epoch 9/40\n",
      " - 2s - loss: 2.3989 - acc: 0.0930 - val_loss: 2.3979 - val_acc: 0.0948\n",
      "Epoch 10/40\n",
      " - 2s - loss: 2.3985 - acc: 0.0945 - val_loss: 2.3979 - val_acc: 0.0942\n",
      "Epoch 11/40\n",
      " - 2s - loss: 2.3983 - acc: 0.0956 - val_loss: 2.3979 - val_acc: 0.1126\n",
      "Epoch 12/40\n",
      " - 2s - loss: 2.3979 - acc: 0.0972 - val_loss: 2.3971 - val_acc: 0.0716\n",
      "Epoch 13/40\n",
      " - 2s - loss: 2.2175 - acc: 0.1667 - val_loss: 1.7926 - val_acc: 0.4428\n",
      "Epoch 14/40\n",
      " - 2s - loss: 1.6959 - acc: 0.4268 - val_loss: 1.2054 - val_acc: 0.6356\n",
      "Epoch 15/40\n",
      " - 2s - loss: 1.3083 - acc: 0.5726 - val_loss: 0.8383 - val_acc: 0.7368\n",
      "Epoch 16/40\n",
      " - 2s - loss: 1.0605 - acc: 0.6546 - val_loss: 0.6744 - val_acc: 0.7880\n",
      "Epoch 17/40\n",
      " - 2s - loss: 0.8989 - acc: 0.7124 - val_loss: 0.5542 - val_acc: 0.8281\n",
      "Epoch 18/40\n",
      " - 2s - loss: 0.7840 - acc: 0.7506 - val_loss: 0.4639 - val_acc: 0.8525\n",
      "Epoch 19/40\n",
      " - 2s - loss: 0.7131 - acc: 0.7742 - val_loss: 0.4267 - val_acc: 0.8651\n",
      "Epoch 20/40\n",
      " - 2s - loss: 0.6498 - acc: 0.7937 - val_loss: 0.4084 - val_acc: 0.8667\n",
      "Epoch 21/40\n",
      " - 2s - loss: 0.6003 - acc: 0.8067 - val_loss: 0.3651 - val_acc: 0.8843\n",
      "Epoch 22/40\n",
      " - 2s - loss: 0.5440 - acc: 0.8279 - val_loss: 0.3312 - val_acc: 0.8926\n",
      "Epoch 23/40\n",
      " - 2s - loss: 0.5268 - acc: 0.8334 - val_loss: 0.3302 - val_acc: 0.8939\n",
      "Epoch 24/40\n",
      " - 2s - loss: 0.4846 - acc: 0.8432 - val_loss: 0.2956 - val_acc: 0.9045\n",
      "Epoch 25/40\n",
      " - 2s - loss: 0.4689 - acc: 0.8485 - val_loss: 0.2962 - val_acc: 0.9079\n",
      "Epoch 26/40\n",
      " - 2s - loss: 0.4376 - acc: 0.8619 - val_loss: 0.2787 - val_acc: 0.9096\n",
      "Epoch 27/40\n",
      " - 2s - loss: 0.4208 - acc: 0.8648 - val_loss: 0.2624 - val_acc: 0.9183\n",
      "Epoch 28/40\n",
      " - 2s - loss: 0.4104 - acc: 0.8664 - val_loss: 0.2650 - val_acc: 0.9152\n",
      "Epoch 29/40\n",
      " - 2s - loss: 0.3842 - acc: 0.8773 - val_loss: 0.2590 - val_acc: 0.9158\n",
      "Epoch 30/40\n",
      " - 2s - loss: 0.3806 - acc: 0.8774 - val_loss: 0.2496 - val_acc: 0.9196\n",
      "Epoch 31/40\n",
      " - 2s - loss: 0.3584 - acc: 0.8831 - val_loss: 0.2492 - val_acc: 0.9177\n",
      "Epoch 32/40\n",
      " - 2s - loss: 0.3515 - acc: 0.8858 - val_loss: 0.2325 - val_acc: 0.9254\n",
      "Epoch 33/40\n",
      " - 2s - loss: 0.3382 - acc: 0.8906 - val_loss: 0.2601 - val_acc: 0.9154\n",
      "Epoch 34/40\n",
      " - 2s - loss: 0.3305 - acc: 0.8922 - val_loss: 0.2343 - val_acc: 0.9244\n",
      "Epoch 35/40\n",
      " - 2s - loss: 0.3233 - acc: 0.8944 - val_loss: 0.2335 - val_acc: 0.9244\n",
      "Epoch 36/40\n",
      " - 2s - loss: 0.3120 - acc: 0.8978 - val_loss: 0.2390 - val_acc: 0.9227\n",
      "Epoch 37/40\n",
      " - 2s - loss: 0.2978 - acc: 0.9043 - val_loss: 0.2327 - val_acc: 0.9246\n",
      "Epoch 38/40\n",
      " - 2s - loss: 0.2854 - acc: 0.9064 - val_loss: 0.2192 - val_acc: 0.9294\n",
      "Epoch 39/40\n",
      " - 2s - loss: 0.2960 - acc: 0.9047 - val_loss: 0.2240 - val_acc: 0.9271\n",
      "Epoch 40/40\n",
      " - 2s - loss: 0.2784 - acc: 0.9079 - val_loss: 0.2227 - val_acc: 0.9269\n",
      "Test accuracy: 0.9268994628696925\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 5s - loss: 2.4439 - acc: 0.0941 - val_loss: 2.3734 - val_acc: 0.0894\n",
      "Epoch 2/40\n",
      " - 3s - loss: 2.2712 - acc: 0.1668 - val_loss: 2.0221 - val_acc: 0.3513\n",
      "Epoch 3/40\n",
      " - 3s - loss: 2.0307 - acc: 0.2852 - val_loss: 1.6695 - val_acc: 0.5031\n",
      "Epoch 4/40\n",
      " - 3s - loss: 1.8175 - acc: 0.3785 - val_loss: 1.4276 - val_acc: 0.5861\n",
      "Epoch 5/40\n",
      " - 3s - loss: 1.6196 - acc: 0.4522 - val_loss: 1.2035 - val_acc: 0.6669\n",
      "Epoch 6/40\n",
      " - 3s - loss: 1.3853 - acc: 0.5372 - val_loss: 0.8307 - val_acc: 0.7630\n",
      "Epoch 7/40\n",
      " - 3s - loss: 1.1698 - acc: 0.6143 - val_loss: 0.6664 - val_acc: 0.7914\n",
      "Epoch 8/40\n",
      " - 3s - loss: 1.0060 - acc: 0.6699 - val_loss: 0.5492 - val_acc: 0.8337\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.8889 - acc: 0.7121 - val_loss: 0.4923 - val_acc: 0.8419\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.7962 - acc: 0.7406 - val_loss: 0.4281 - val_acc: 0.8659\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.7161 - acc: 0.7729 - val_loss: 0.3946 - val_acc: 0.8766\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.6627 - acc: 0.7867 - val_loss: 0.3469 - val_acc: 0.8903\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.6108 - acc: 0.8052 - val_loss: 0.3367 - val_acc: 0.8933\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.5607 - acc: 0.8248 - val_loss: 0.3101 - val_acc: 0.8975\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.5103 - acc: 0.8376 - val_loss: 0.2981 - val_acc: 0.9023\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.4926 - acc: 0.8436 - val_loss: 0.2921 - val_acc: 0.9066\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.4645 - acc: 0.8511 - val_loss: 0.2754 - val_acc: 0.9085\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.4386 - acc: 0.8615 - val_loss: 0.2548 - val_acc: 0.9160\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.4160 - acc: 0.8676 - val_loss: 0.2520 - val_acc: 0.9213\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.4029 - acc: 0.8725 - val_loss: 0.2428 - val_acc: 0.9219\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.3774 - acc: 0.8798 - val_loss: 0.2312 - val_acc: 0.9246\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.3596 - acc: 0.8863 - val_loss: 0.2318 - val_acc: 0.9250\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.3429 - acc: 0.8920 - val_loss: 0.2326 - val_acc: 0.9282\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.3358 - acc: 0.8924 - val_loss: 0.2282 - val_acc: 0.9304\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.3275 - acc: 0.8965 - val_loss: 0.2276 - val_acc: 0.9277\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.3031 - acc: 0.9024 - val_loss: 0.2399 - val_acc: 0.9252\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.3080 - acc: 0.9010 - val_loss: 0.2141 - val_acc: 0.9302\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.2857 - acc: 0.9075 - val_loss: 0.2084 - val_acc: 0.9351\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.2872 - acc: 0.9074 - val_loss: 0.2165 - val_acc: 0.9369\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.2704 - acc: 0.9130 - val_loss: 0.2166 - val_acc: 0.9338\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.2723 - acc: 0.9134 - val_loss: 0.2134 - val_acc: 0.9353\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.2572 - acc: 0.9167 - val_loss: 0.2135 - val_acc: 0.9359\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.2484 - acc: 0.9191 - val_loss: 0.2220 - val_acc: 0.9346\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.2389 - acc: 0.9235 - val_loss: 0.2029 - val_acc: 0.9390\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.2548 - acc: 0.9187 - val_loss: 0.1965 - val_acc: 0.9405\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.2321 - acc: 0.9255 - val_loss: 0.2124 - val_acc: 0.9353\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.2163 - acc: 0.9307 - val_loss: 0.2170 - val_acc: 0.9380\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.2112 - acc: 0.9305 - val_loss: 0.2102 - val_acc: 0.9390\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.2170 - acc: 0.9293 - val_loss: 0.2045 - val_acc: 0.9422\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.2117 - acc: 0.9291 - val_loss: 0.2010 - val_acc: 0.9413\n",
      "Test accuracy: 0.9412893322643096\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 5s - loss: 2.4307 - acc: 0.0967 - val_loss: 2.3919 - val_acc: 0.1817\n",
      "Epoch 2/40\n",
      " - 3s - loss: 2.1476 - acc: 0.2155 - val_loss: 1.7547 - val_acc: 0.3488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40\n",
      " - 3s - loss: 1.7057 - acc: 0.3938 - val_loss: 1.2482 - val_acc: 0.6393\n",
      "Epoch 4/40\n",
      " - 3s - loss: 1.2827 - acc: 0.5710 - val_loss: 0.7551 - val_acc: 0.7688\n",
      "Epoch 5/40\n",
      " - 3s - loss: 0.9770 - acc: 0.6846 - val_loss: 0.5521 - val_acc: 0.8342\n",
      "Epoch 6/40\n",
      " - 3s - loss: 0.7853 - acc: 0.7514 - val_loss: 0.4765 - val_acc: 0.8471\n",
      "Epoch 7/40\n",
      " - 3s - loss: 0.6561 - acc: 0.7948 - val_loss: 0.3761 - val_acc: 0.8797\n",
      "Epoch 8/40\n",
      " - 3s - loss: 0.5835 - acc: 0.8177 - val_loss: 0.3483 - val_acc: 0.8883\n",
      "Epoch 9/40\n",
      " - 3s - loss: 0.5085 - acc: 0.8423 - val_loss: 0.3238 - val_acc: 0.8985\n",
      "Epoch 10/40\n",
      " - 3s - loss: 0.4661 - acc: 0.8568 - val_loss: 0.3010 - val_acc: 0.9056\n",
      "Epoch 11/40\n",
      " - 3s - loss: 0.4213 - acc: 0.8684 - val_loss: 0.2784 - val_acc: 0.9085\n",
      "Epoch 12/40\n",
      " - 3s - loss: 0.3972 - acc: 0.8760 - val_loss: 0.2651 - val_acc: 0.9177\n",
      "Epoch 13/40\n",
      " - 3s - loss: 0.3612 - acc: 0.8870 - val_loss: 0.2556 - val_acc: 0.9179\n",
      "Epoch 14/40\n",
      " - 3s - loss: 0.3459 - acc: 0.8907 - val_loss: 0.2728 - val_acc: 0.9139\n",
      "Epoch 15/40\n",
      " - 3s - loss: 0.3150 - acc: 0.8979 - val_loss: 0.2532 - val_acc: 0.9198\n",
      "Epoch 16/40\n",
      " - 3s - loss: 0.3040 - acc: 0.9039 - val_loss: 0.2505 - val_acc: 0.9213\n",
      "Epoch 17/40\n",
      " - 3s - loss: 0.2859 - acc: 0.9087 - val_loss: 0.2431 - val_acc: 0.9238\n",
      "Epoch 18/40\n",
      " - 3s - loss: 0.2785 - acc: 0.9110 - val_loss: 0.2282 - val_acc: 0.9281\n",
      "Epoch 19/40\n",
      " - 3s - loss: 0.2657 - acc: 0.9162 - val_loss: 0.2194 - val_acc: 0.9288\n",
      "Epoch 20/40\n",
      " - 3s - loss: 0.2400 - acc: 0.9217 - val_loss: 0.2033 - val_acc: 0.9357\n",
      "Epoch 21/40\n",
      " - 3s - loss: 0.2258 - acc: 0.9262 - val_loss: 0.2324 - val_acc: 0.9313\n",
      "Epoch 22/40\n",
      " - 3s - loss: 0.2200 - acc: 0.9275 - val_loss: 0.2224 - val_acc: 0.9334\n",
      "Epoch 23/40\n",
      " - 3s - loss: 0.2057 - acc: 0.9339 - val_loss: 0.2235 - val_acc: 0.9321\n",
      "Epoch 24/40\n",
      " - 3s - loss: 0.2041 - acc: 0.9321 - val_loss: 0.2296 - val_acc: 0.9309\n",
      "Epoch 25/40\n",
      " - 3s - loss: 0.1960 - acc: 0.9358 - val_loss: 0.2192 - val_acc: 0.9328\n",
      "Epoch 26/40\n",
      " - 3s - loss: 0.1788 - acc: 0.9378 - val_loss: 0.2294 - val_acc: 0.9311\n",
      "Epoch 27/40\n",
      " - 3s - loss: 0.1735 - acc: 0.9414 - val_loss: 0.2329 - val_acc: 0.9330\n",
      "Epoch 28/40\n",
      " - 3s - loss: 0.1684 - acc: 0.9445 - val_loss: 0.2314 - val_acc: 0.9353\n",
      "Epoch 29/40\n",
      " - 3s - loss: 0.1611 - acc: 0.9448 - val_loss: 0.2352 - val_acc: 0.9336\n",
      "Epoch 30/40\n",
      " - 3s - loss: 0.1634 - acc: 0.9475 - val_loss: 0.2097 - val_acc: 0.9392\n",
      "Epoch 31/40\n",
      " - 3s - loss: 0.1428 - acc: 0.9526 - val_loss: 0.2131 - val_acc: 0.9396\n",
      "Epoch 32/40\n",
      " - 3s - loss: 0.1440 - acc: 0.9525 - val_loss: 0.2144 - val_acc: 0.9396\n",
      "Epoch 33/40\n",
      " - 3s - loss: 0.1349 - acc: 0.9547 - val_loss: 0.2311 - val_acc: 0.9367\n",
      "Epoch 34/40\n",
      " - 3s - loss: 0.1363 - acc: 0.9547 - val_loss: 0.2246 - val_acc: 0.9401\n",
      "Epoch 35/40\n",
      " - 3s - loss: 0.1288 - acc: 0.9569 - val_loss: 0.2434 - val_acc: 0.9376\n",
      "Epoch 36/40\n",
      " - 3s - loss: 0.1194 - acc: 0.9617 - val_loss: 0.2260 - val_acc: 0.9403\n",
      "Epoch 37/40\n",
      " - 3s - loss: 0.1086 - acc: 0.9638 - val_loss: 0.2377 - val_acc: 0.9436\n",
      "Epoch 38/40\n",
      " - 3s - loss: 0.1180 - acc: 0.9612 - val_loss: 0.2421 - val_acc: 0.9367\n",
      "Epoch 39/40\n",
      " - 3s - loss: 0.1038 - acc: 0.9657 - val_loss: 0.2350 - val_acc: 0.9407\n",
      "Epoch 40/40\n",
      " - 3s - loss: 0.1035 - acc: 0.9651 - val_loss: 0.2455 - val_acc: 0.9399\n",
      "Test accuracy: 0.9399462778204144\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 6s - loss: 2.4199 - acc: 0.0928 - val_loss: 2.3978 - val_acc: 0.1182\n",
      "Epoch 2/40\n",
      " - 4s - loss: 2.2899 - acc: 0.1382 - val_loss: 1.9763 - val_acc: 0.2600\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.6554 - acc: 0.4264 - val_loss: 1.0557 - val_acc: 0.6813\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.0424 - acc: 0.6702 - val_loss: 0.6910 - val_acc: 0.7824\n",
      "Epoch 5/40\n",
      " - 4s - loss: 0.7703 - acc: 0.7565 - val_loss: 0.5239 - val_acc: 0.8386\n",
      "Epoch 6/40\n",
      " - 4s - loss: 0.6077 - acc: 0.8108 - val_loss: 0.3921 - val_acc: 0.8772\n",
      "Epoch 7/40\n",
      " - 4s - loss: 0.5135 - acc: 0.8383 - val_loss: 0.3603 - val_acc: 0.8795\n",
      "Epoch 8/40\n",
      " - 4s - loss: 0.4334 - acc: 0.8634 - val_loss: 0.3303 - val_acc: 0.8966\n",
      "Epoch 9/40\n",
      " - 4s - loss: 0.3887 - acc: 0.8765 - val_loss: 0.3088 - val_acc: 0.9033\n",
      "Epoch 10/40\n",
      " - 4s - loss: 0.3530 - acc: 0.8873 - val_loss: 0.2780 - val_acc: 0.9091\n",
      "Epoch 11/40\n",
      " - 4s - loss: 0.3205 - acc: 0.8972 - val_loss: 0.2970 - val_acc: 0.9029\n",
      "Epoch 12/40\n",
      " - 4s - loss: 0.3008 - acc: 0.9042 - val_loss: 0.2611 - val_acc: 0.9165\n",
      "Epoch 13/40\n",
      " - 4s - loss: 0.2689 - acc: 0.9119 - val_loss: 0.2408 - val_acc: 0.9252\n",
      "Epoch 14/40\n",
      " - 4s - loss: 0.2580 - acc: 0.9157 - val_loss: 0.2438 - val_acc: 0.9244\n",
      "Epoch 15/40\n",
      " - 4s - loss: 0.2355 - acc: 0.9222 - val_loss: 0.2531 - val_acc: 0.9211\n",
      "Epoch 16/40\n",
      " - 4s - loss: 0.2252 - acc: 0.9254 - val_loss: 0.2579 - val_acc: 0.9227\n",
      "Epoch 17/40\n",
      " - 4s - loss: 0.2126 - acc: 0.9307 - val_loss: 0.2374 - val_acc: 0.9275\n",
      "Epoch 18/40\n",
      " - 4s - loss: 0.1967 - acc: 0.9360 - val_loss: 0.2288 - val_acc: 0.9273\n",
      "Epoch 19/40\n",
      " - 4s - loss: 0.1767 - acc: 0.9420 - val_loss: 0.2366 - val_acc: 0.9313\n",
      "Epoch 20/40\n",
      " - 4s - loss: 0.1637 - acc: 0.9471 - val_loss: 0.2371 - val_acc: 0.9338\n",
      "Epoch 21/40\n",
      " - 4s - loss: 0.1589 - acc: 0.9459 - val_loss: 0.2450 - val_acc: 0.9311\n",
      "Epoch 22/40\n",
      " - 4s - loss: 0.1559 - acc: 0.9477 - val_loss: 0.2176 - val_acc: 0.9357\n",
      "Epoch 23/40\n",
      " - 4s - loss: 0.1468 - acc: 0.9512 - val_loss: 0.2252 - val_acc: 0.9378\n",
      "Epoch 24/40\n",
      " - 4s - loss: 0.1369 - acc: 0.9546 - val_loss: 0.2682 - val_acc: 0.9271\n",
      "Epoch 25/40\n",
      " - 4s - loss: 0.1301 - acc: 0.9575 - val_loss: 0.2533 - val_acc: 0.9294\n",
      "Epoch 26/40\n",
      " - 4s - loss: 0.1177 - acc: 0.9586 - val_loss: 0.2448 - val_acc: 0.9332\n",
      "Epoch 27/40\n",
      " - 4s - loss: 0.1128 - acc: 0.9623 - val_loss: 0.2471 - val_acc: 0.9357\n",
      "Epoch 28/40\n",
      " - 4s - loss: 0.1055 - acc: 0.9655 - val_loss: 0.2323 - val_acc: 0.9384\n",
      "Epoch 29/40\n",
      " - 4s - loss: 0.1017 - acc: 0.9652 - val_loss: 0.2693 - val_acc: 0.9323\n",
      "Epoch 30/40\n",
      " - 4s - loss: 0.0911 - acc: 0.9698 - val_loss: 0.2594 - val_acc: 0.9371\n",
      "Epoch 31/40\n",
      " - 4s - loss: 0.0903 - acc: 0.9696 - val_loss: 0.2813 - val_acc: 0.9350\n",
      "Epoch 32/40\n",
      " - 4s - loss: 0.0872 - acc: 0.9725 - val_loss: 0.2561 - val_acc: 0.9365\n",
      "Epoch 33/40\n",
      " - 4s - loss: 0.0772 - acc: 0.9746 - val_loss: 0.2645 - val_acc: 0.9363\n",
      "Epoch 34/40\n",
      " - 4s - loss: 0.0854 - acc: 0.9704 - val_loss: 0.2611 - val_acc: 0.9371\n",
      "Epoch 35/40\n",
      " - 4s - loss: 0.0773 - acc: 0.9748 - val_loss: 0.2570 - val_acc: 0.9369\n",
      "Epoch 36/40\n",
      " - 4s - loss: 0.0743 - acc: 0.9758 - val_loss: 0.2761 - val_acc: 0.9378\n",
      "Epoch 37/40\n",
      " - 4s - loss: 0.0665 - acc: 0.9779 - val_loss: 0.2868 - val_acc: 0.9332\n",
      "Epoch 38/40\n",
      " - 4s - loss: 0.0668 - acc: 0.9778 - val_loss: 0.3002 - val_acc: 0.9348\n",
      "Epoch 39/40\n",
      " - 4s - loss: 0.0638 - acc: 0.9791 - val_loss: 0.2831 - val_acc: 0.9409\n",
      "Epoch 40/40\n",
      " - 4s - loss: 0.0601 - acc: 0.9810 - val_loss: 0.2726 - val_acc: 0.9388\n",
      "Test accuracy: 0.938795088120634\n",
      "Train on 20846 samples, validate on 5212 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 2.4720 - acc: 0.0957 - val_loss: 2.3894 - val_acc: 0.1426\n",
      "Epoch 2/40\n",
      " - 2s - loss: 2.3597 - acc: 0.1209 - val_loss: 2.2443 - val_acc: 0.2724\n",
      "Epoch 3/40\n",
      " - 2s - loss: 2.2506 - acc: 0.1676 - val_loss: 2.0836 - val_acc: 0.3695\n",
      "Epoch 4/40\n",
      " - 2s - loss: 2.1385 - acc: 0.2096 - val_loss: 1.8821 - val_acc: 0.4816\n",
      "Epoch 5/40\n",
      " - 2s - loss: 2.0179 - acc: 0.2616 - val_loss: 1.6983 - val_acc: 0.5482\n",
      "Epoch 6/40\n",
      " - 2s - loss: 1.9050 - acc: 0.3087 - val_loss: 1.5409 - val_acc: 0.6153\n",
      "Epoch 7/40\n",
      " - 2s - loss: 1.7885 - acc: 0.3575 - val_loss: 1.3104 - val_acc: 0.6418\n",
      "Epoch 8/40\n",
      " - 2s - loss: 1.6679 - acc: 0.4053 - val_loss: 1.1550 - val_acc: 0.7047\n",
      "Epoch 9/40\n",
      " - 2s - loss: 1.5331 - acc: 0.4516 - val_loss: 0.9731 - val_acc: 0.7467\n",
      "Epoch 10/40\n",
      " - 2s - loss: 1.4349 - acc: 0.4850 - val_loss: 0.8865 - val_acc: 0.7732\n",
      "Epoch 11/40\n",
      " - 2s - loss: 1.3331 - acc: 0.5244 - val_loss: 0.7787 - val_acc: 0.7951\n",
      "Epoch 12/40\n",
      " - 2s - loss: 1.2354 - acc: 0.5626 - val_loss: 0.6856 - val_acc: 0.8037\n",
      "Epoch 13/40\n",
      " - 2s - loss: 1.1624 - acc: 0.5882 - val_loss: 0.6341 - val_acc: 0.8244\n",
      "Epoch 14/40\n",
      " - 2s - loss: 1.0890 - acc: 0.6165 - val_loss: 0.5839 - val_acc: 0.8219\n",
      "Epoch 15/40\n",
      " - 2s - loss: 1.0359 - acc: 0.6366 - val_loss: 0.5242 - val_acc: 0.8461\n",
      "Epoch 16/40\n",
      " - 2s - loss: 0.9820 - acc: 0.6570 - val_loss: 0.5112 - val_acc: 0.8519\n",
      "Epoch 17/40\n",
      " - 2s - loss: 0.9262 - acc: 0.6782 - val_loss: 0.4584 - val_acc: 0.8596\n",
      "Epoch 18/40\n",
      " - 2s - loss: 0.8917 - acc: 0.6878 - val_loss: 0.4423 - val_acc: 0.8674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40\n",
      " - 2s - loss: 0.8495 - acc: 0.7006 - val_loss: 0.4215 - val_acc: 0.8703\n",
      "Epoch 20/40\n",
      " - 2s - loss: 0.8220 - acc: 0.7103 - val_loss: 0.3982 - val_acc: 0.8764\n",
      "Epoch 21/40\n",
      " - 2s - loss: 0.8020 - acc: 0.7186 - val_loss: 0.3793 - val_acc: 0.8830\n",
      "Epoch 22/40\n",
      " - 2s - loss: 0.7784 - acc: 0.7294 - val_loss: 0.3727 - val_acc: 0.8849\n",
      "Epoch 23/40\n",
      " - 2s - loss: 0.7553 - acc: 0.7383 - val_loss: 0.3566 - val_acc: 0.8910\n",
      "Epoch 24/40\n",
      " - 2s - loss: 0.7198 - acc: 0.7503 - val_loss: 0.3526 - val_acc: 0.8929\n",
      "Epoch 25/40\n",
      " - 2s - loss: 0.7105 - acc: 0.7522 - val_loss: 0.3448 - val_acc: 0.8960\n",
      "Epoch 26/40\n",
      " - 2s - loss: 0.6843 - acc: 0.7630 - val_loss: 0.3284 - val_acc: 0.8974\n",
      "Epoch 27/40\n",
      " - 2s - loss: 0.6820 - acc: 0.7624 - val_loss: 0.3297 - val_acc: 0.8956\n",
      "Epoch 28/40\n",
      " - 2s - loss: 0.6681 - acc: 0.7654 - val_loss: 0.3277 - val_acc: 0.9012\n",
      "Epoch 29/40\n",
      " - 2s - loss: 0.6550 - acc: 0.7715 - val_loss: 0.3285 - val_acc: 0.9014\n",
      "Epoch 30/40\n",
      " - 2s - loss: 0.6330 - acc: 0.7798 - val_loss: 0.3103 - val_acc: 0.9004\n",
      "Epoch 31/40\n",
      " - 2s - loss: 0.6235 - acc: 0.7840 - val_loss: 0.3050 - val_acc: 0.9058\n",
      "Epoch 32/40\n",
      " - 2s - loss: 0.6078 - acc: 0.7846 - val_loss: 0.2889 - val_acc: 0.9114\n",
      "Epoch 33/40\n",
      " - 2s - loss: 0.5979 - acc: 0.7876 - val_loss: 0.2942 - val_acc: 0.9102\n",
      "Epoch 34/40\n",
      " - 2s - loss: 0.5838 - acc: 0.7924 - val_loss: 0.2799 - val_acc: 0.9116\n",
      "Epoch 35/40\n",
      " - 2s - loss: 0.5735 - acc: 0.7995 - val_loss: 0.2814 - val_acc: 0.9096\n",
      "Epoch 36/40\n",
      " - 2s - loss: 0.5638 - acc: 0.8027 - val_loss: 0.2698 - val_acc: 0.9139\n",
      "Epoch 37/40\n",
      " - 2s - loss: 0.5547 - acc: 0.8031 - val_loss: 0.2726 - val_acc: 0.9139\n",
      "Epoch 38/40\n",
      " - 2s - loss: 0.5471 - acc: 0.8068 - val_loss: 0.2734 - val_acc: 0.9119\n",
      "Epoch 39/40\n",
      " - 2s - loss: 0.5445 - acc: 0.8073 - val_loss: 0.2715 - val_acc: 0.9154\n",
      "Epoch 40/40\n",
      " - 2s - loss: 0.5247 - acc: 0.8147 - val_loss: 0.2546 - val_acc: 0.9173\n",
      "Test accuracy: 0.9173062162864053\n"
     ]
    }
   ],
   "source": [
    "#from keras.layers.core import Dense, Dropout, Activation\n",
    "trials = Trials()\n",
    "best_run, best_model = optim.minimize(model=create_model, \n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      trials=trials,\n",
    "                                      notebook_name='processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutation of best performing model:\n",
      "5212/5212 [==============================] - 1s 118us/step\n",
      "[14.643393463843251, 0.003837298541826554]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Activation': 1, 'Convolution2D': 2, 'Convolution2D_1': 1, 'Convolution2D_2': 2, 'Dense': 3, 'Dense_1': 1, 'Dropout': 0.026173030939273843, 'Dropout_1': 0.4106653839167337, 'Dropout_2': 0.6173724517497831, 'Dropout_3': 0.28219515663594574, 'batch_size': 0, 'conditional': 0}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_91 (Conv2D)           (None, 64, 95, 10)        1344      \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 64, 95, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 64, 31, 5)         0         \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 64, 31, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 64, 28, 4)         32832     \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 64, 28, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 256, 25, 2)        196864    \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 256, 25, 2)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 256, 12, 1)        0         \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 256, 12, 1)        0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 11)                1111      \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 11)                0         \n",
      "=================================================================\n",
      "Total params: 539,451\n",
      "Trainable params: 539,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "dest_directory = 'model_backup/'\n",
    "'''\n",
    "best_model = load_model(dest_directory + 'best_model.bak')\n",
    "\n",
    "with open(dest_directory+'best_run.pkl', 'rb') as f:  \n",
    "    best_run = pickle.load(f)    \n",
    "'''\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(x_test, y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)\n",
    "best_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "dest_directory_temp =dest_directory + 'bestModel('+now.strftime(\"%m-%d %H.%M\")+\")\"\n",
    "if not os.path.exists(dest_directory_temp):\n",
    "      os.makedirs(dest_directory_temp)\n",
    "best_model.save(dest_directory_temp + '/best_model.bak')\n",
    "with open(dest_directory_temp + '/best_run.pkl', 'wb') as f:  \n",
    "    pickle.dump(best_run, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
