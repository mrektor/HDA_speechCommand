{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python_speech_features in /home/tlc/.local/lib/python3.6/site-packages (0.6)\r\n"
     ]
    }
   ],
   "source": [
    "## save variables\n",
    "import pickle\n",
    "## folder names\n",
    "from glob import glob\n",
    "## wav import\n",
    "from scipy.io import wavfile as readWav\n",
    "## standard libraries\n",
    "import numpy as np\n",
    "## MFCC\n",
    "import sys\n",
    "!{sys.executable} -m pip install python_speech_features --user\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Return the word between two string starting from left\n",
    "def find_between( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreKey = [\"Yes\", \"No\", \"Up\", \"Down\", \"Left\", \"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\",\n",
    "           \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\"]\n",
    "sampleRate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIGNALS\n",
      "Processing  dataset/two/\n",
      "Processing  dataset/yes/\n",
      "Processing  dataset/stop/\n",
      "Processing  dataset/up/\n",
      "Processing  dataset/bird/\n",
      "Processing  dataset/dog/\n",
      "Processing  dataset/house/\n",
      "Processing  dataset/seven/\n",
      "Processing  dataset/off/\n",
      "Processing  dataset/one/\n",
      "Processing  dataset/on/\n",
      "Processing  dataset/zero/\n",
      "Processing  dataset/sheila/\n",
      "Processing  dataset/five/\n",
      "Processing  dataset/happy/\n",
      "Processing  dataset/three/\n",
      "Processing  dataset/nine/\n",
      "Processing  dataset/go/\n",
      "Processing  dataset/four/\n",
      "Processing  dataset/left/\n",
      "Processing  dataset/tree/\n",
      "Processing  dataset/marvin/\n",
      "Processing  dataset/no/\n",
      "Processing  dataset/six/\n",
      "Processing  dataset/bed/\n",
      "Processing  dataset/wow/\n",
      "Processing  dataset/cat/\n",
      "Processing  dataset/right/\n",
      "Processing  dataset/down/\n",
      "Processing  dataset/eight/\n",
      "\n",
      "NOISE\n",
      "Processing  dataset/_background_noise_/doing_the_dishes.wav\n",
      "Processing  dataset/_background_noise_/exercise_bike.wav\n",
      "Processing  dataset/_background_noise_/white_noise.wav\n",
      "Processing  dataset/_background_noise_/dude_miaowing.wav\n",
      "Processing  dataset/_background_noise_/pink_noise.wav\n",
      "Processing  dataset/_background_noise_/running_tap.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tlc/.local/lib/python3.6/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "folders = glob(\"dataset/*/\")\n",
    "folders.remove('dataset/_background_noise_/')\n",
    "print('SIGNALS')\n",
    "rawDict = {}\n",
    "for key in folders:\n",
    "    print('Processing ', key)\n",
    "    dictKey = find_between( key, '/', '/' )\n",
    "    tmpFiles = glob(key+'*')\n",
    "    array = []\n",
    "    for file in tmpFiles:\n",
    "        array.append(readWav.read(file)[1].copy())\n",
    "    rawDict[dictKey] = np.array(array)\n",
    "print('\\nNOISE')\n",
    "noiseDict = {}\n",
    "folders = glob('dataset/_background_noise_/*.wav')\n",
    "for key in folders:\n",
    "    print('Processing ', key)\n",
    "    noiseDict[key[key.rindex('/')+1:len(key)]] = readWav.read(key)[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{verbatim}\n",
    "Parameter         Description\n",
    "signal \t          the audio signal from which to compute features. Should be an N*1 array\n",
    "samplerate \t      the samplerate of the signal we are working with.\n",
    "winlen \t          the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "winstep \t      the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "numcep \t          the number of cepstrum to return, default 13\n",
    "nfilt \t          the number of filters in the filterbank, default 26.\n",
    "nfft \t          the FFT size. Default is 512\n",
    "lowfreq \t      lowest band edge of mel filters. In Hz, default is 0\n",
    "highfreq \t      highest band edge of mel filters. In Hz, default is samplerate/2\\\\\n",
    "preemph \t      apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97\\\\\n",
    "ceplifter \t      apply a lifter to final cepstral coefficients. 0 is no lifter. Default is 22\\\\\n",
    "appendEnergy \t  if this is true, the zeroth cepstral coefficient is replaced with the log of the total frame energy.\\\\\n",
    "returns \t      A numpy array of size (NUMFRAMES by numcep) containing features. Each row holds 1 feature vector.\\\\\n",
    "\\end{verbatim}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mfccDict = {}\n",
    "print('MFCC features')\n",
    "for key in rawDict:\n",
    "    print('Processing ',key)\n",
    "    array = []\n",
    "    for sig in rawDict[key]:\n",
    "        sig.resize(16000, refcheck=False)\n",
    "        mfcc_feat = mfcc(sig,sampleRate)\n",
    "        array.append(mfcc_feat.flatten())\n",
    "    mfccDict[key] = np.vstack(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC features\n",
      "Processing  two\n",
      "Processing  yes\n",
      "Processing  stop\n",
      "Processing  up\n",
      "Processing  bird\n",
      "Processing  dog\n",
      "Processing  house\n",
      "Processing  seven\n",
      "Processing  off\n",
      "Processing  one\n",
      "Processing  on\n",
      "Processing  zero\n",
      "Processing  sheila\n",
      "Processing  five\n",
      "Processing  happy\n",
      "Processing  three\n",
      "Processing  nine\n",
      "Processing  go\n",
      "Processing  four\n",
      "Processing  left\n",
      "Processing  tree\n",
      "Processing  marvin\n",
      "Processing  no\n",
      "Processing  six\n",
      "Processing  bed\n",
      "Processing  wow\n",
      "Processing  cat\n",
      "Processing  right\n",
      "Processing  down\n",
      "Processing  eight\n"
     ]
    }
   ],
   "source": [
    "mfccMatDict = {}\n",
    "print('MFCC features')\n",
    "for key in rawDict:\n",
    "    print('Processing ',key)\n",
    "    array = []\n",
    "    for sig in rawDict[key]:\n",
    "        sig.resize(16000, refcheck=False)\n",
    "        mfcc_feat = mfcc(sig,sampleRate)\n",
    "        array.append(mfcc_feat)\n",
    "    mfccMatDict[key] = np.array(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logFilterBanks features\n",
      "Processing  two\n",
      "Processing  yes\n",
      "Processing  stop\n",
      "Processing  up\n",
      "Processing  bird\n",
      "Processing  dog\n",
      "Processing  house\n",
      "Processing  seven\n",
      "Processing  off\n",
      "Processing  one\n",
      "Processing  on\n",
      "Processing  zero\n",
      "Processing  sheila\n",
      "Processing  five\n",
      "Processing  happy\n",
      "Processing  three\n",
      "Processing  nine\n",
      "Processing  go\n",
      "Processing  four\n",
      "Processing  left\n",
      "Processing  tree\n",
      "Processing  marvin\n",
      "Processing  no\n",
      "Processing  six\n",
      "Processing  bed\n",
      "Processing  wow\n",
      "Processing  cat\n",
      "Processing  right\n",
      "Processing  down\n",
      "Processing  eight\n"
     ]
    }
   ],
   "source": [
    "fbankDict = {}\n",
    "print('logFilterBanks features')\n",
    "for key in rawDict:\n",
    "    print('Processing ',key)\n",
    "    array = []\n",
    "    for sig in rawDict[key]:\n",
    "        sig.resize(16000, refcheck=False)\n",
    "        fbank_feat = logfbank(sig,sampleRate)\n",
    "        array.append(fbank_feat.resize(fbank_feat.shape[0]*mfcc_feat.shape[1]))\n",
    "    fbankDict[key] = np.vstack(array)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('variables/rawDict.pkl', 'wb') as f:  \n",
    "    pickle.dump(rawDict, f)\n",
    "with open('variables/noiseDict.pkl', 'wb') as f:  \n",
    "    pickle.dump(noiseDict, f)    \n",
    "with open('variables/mfccDict.pkl', 'wb') as f:  \n",
    "    pickle.dump(mfccMatDict, f)\n",
    "with open('variables/fbankDict.pkl', 'wb') as f:  \n",
    "    pickle.dump(fbankDict, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
