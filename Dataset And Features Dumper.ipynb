{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: msgpack in c:\\users\\yurin\\appdata\\roaming\\python\\python36\\site-packages (0.5.6)\n",
      "Requirement already satisfied: python_speech_features in c:\\users\\yurin\\appdata\\roaming\\python\\python36\\site-packages (0.6)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "## save variables\n",
    "import pickle\n",
    "## folder names\n",
    "from glob import glob\n",
    "## wav import\n",
    "from scipy.io import wavfile \n",
    "## standard libraries\n",
    "import numpy as np\n",
    "## MFCC\n",
    "#!{sys.executable} -m pip install msgpack --user\n",
    "#!{sys.executable} -m pip install python_speech_features --user\n",
    "\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "import random as rnd\n",
    "import os.path\n",
    "import tarfile\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "\n",
    "#!{sys.executable} -m pip install opencv-python --user\n",
    "#!{sys.executable} -m pip install opencv-contrib-python --user\n",
    "#import cv2\n",
    "#garbage collector\n",
    "import gc\n",
    "#OS detection\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make variables directory if not present\n",
    "dest_directory = 'variables/'\n",
    "if not os.path.exists(dest_directory):\n",
    "      os.makedirs(dest_directory)\n",
    "\n",
    "        #data url from which download the dataset      \n",
    "data_url = 'http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz'\n",
    "\n",
    "#make dataset directory if not present\n",
    "dest_directory = 'dataset/'\n",
    "if not os.path.exists(dest_directory):\n",
    "      os.makedirs(dest_directory)\n",
    "\n",
    "#select the last part of the dataurl (the file name)      \n",
    "filename = data_url.split('/')[-1]\n",
    "filepath = os.path.join(dest_directory, filename)\n",
    "\n",
    "#program the download and extraction if the file doesn't exists\n",
    "if not os.path.exists(filepath):\n",
    "    def progress(count, block_size, total_size):\n",
    "        sys.stdout.write(\n",
    "            '\\r>> Downloading %s %.1f%%' %\n",
    "            (filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "        sys.stdout.flush()\n",
    "    try:\n",
    "        filepath, _ = urllib.request.urlretrieve(data_url, filepath, progress)\n",
    "    except:\n",
    "        print(Error)\n",
    "        \n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Return the word between two string starting from left\n",
    "def find_between( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreKey = [\"Yes\", \"No\", \"Up\", \"Down\", \"Left\", \"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\",\n",
    "           \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\"]\n",
    "sampleRate = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rawDict found\n",
      "rawDict loaded\n",
      "\n",
      "NOISE\n",
      "Processing  dataset/_background_noise_\\doing_the_dishes.wav\n",
      "Processing  dataset/_background_noise_\\dude_miaowing.wav\n",
      "Processing  dataset/_background_noise_\\exercise_bike.wav\n",
      "Processing  dataset/_background_noise_\\pink_noise.wav\n",
      "Processing  dataset/_background_noise_\\running_tap.wav\n",
      "Processing  dataset/_background_noise_\\white_noise.wav\n",
      "noiseDict created and saved to variables/noiseDict.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\io\\wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "#control if the raw data are saved with pickle\n",
    "#if true they will be loaded in rawDict\n",
    "reDo = False\n",
    "if os.path.exists('variables/rawDict.pkl') and not reDo:\n",
    "    print('rawDict found')\n",
    "    with open('variables/rawDict.pkl', 'rb') as f:  \n",
    "        rawDict = pickle.load(f)\n",
    "    print('rawDict loaded')\n",
    "#else they will be loaded from wav files\n",
    "else:\n",
    "    print('Creating rawDict')\n",
    "    folders = glob(\"dataset/*/\")\n",
    "    folders.remove('dataset\\\\_background_noise_\\\\')\n",
    "    print('SIGNALS')\n",
    "    rawDict = {}\n",
    "    for key in folders:\n",
    "        print('Processing ', key)\n",
    "        dictKey = find_between( key, '\\\\', '\\\\' )\n",
    "        tmpFiles = glob(key+'*')\n",
    "        array = []\n",
    "        for file in tmpFiles:\n",
    "            sampleRateTmp, tmp = wavfile.read(file)#[1].copy()\n",
    "            tmp = tmp.copy()\n",
    "            sampleRate.append(sampleRateTmp)\n",
    "            tmp.resize(16000, refcheck=False)\n",
    "            array.append(tmp)\n",
    "        rawDict[dictKey] = np.array(array)\n",
    "    #and saved with pickle\n",
    "    with open('variables/rawDict.pkl', 'wb') as f:  \n",
    "        pickle.dump(rawDict, f)\n",
    "    print('rawDict created and saved to variables/rawDict.pkl')\n",
    "sampleRate = np.mean(sampleRate)\n",
    "reDo = False\n",
    "#the same with noise signals\n",
    "if not os.path.exists('variables/noiseDict.pkl') or reDo:    \n",
    "    print('\\nNOISE')\n",
    "    noiseDict = {}\n",
    "    folders = glob('dataset/_background_noise_/*.wav')\n",
    "    for key in folders:\n",
    "        print('Processing ', key)\n",
    "        noiseDict[key[key.rindex('/')+1:len(key)]] = wavfile.read(key)[1]\n",
    "    with open('variables/noiseDict.pkl', 'wb') as f:  \n",
    "        pickle.dump(noiseDict, f) \n",
    "    print('noiseDict created and saved to variables/noiseDict.pkl')\n",
    "else:\n",
    "    print('noiseDict found')\n",
    "    with open('variables/noiseDict.pkl', 'rb') as f:  \n",
    "        noiseDict = pickle.load(f)\n",
    "    print('noiseDict loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiftVec(signal, value):\n",
    "    initial_length = signal.shape[0]\n",
    "    padded = np.pad(signal, (abs(value),abs(value)), 'constant', constant_values=0)\n",
    "    signal = padded[abs(value)-value:abs(value)+initial_length-value]\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_percentage = 0.1\n",
    "time_shift_max = 100 #[ms]\n",
    "sample_shift_max = round(time_shift_max / 1000 * sampleRate)\n",
    "tot_samples = 0\n",
    "for key in rawDict:\n",
    "    length = rawDict[key].shape[0]\n",
    "    tot_samples+=length\n",
    "    toShift = round(length*shift_percentage)\n",
    "    for i in rnd.sample(range(length),toShift):\n",
    "        shift = rnd.randint(-sample_shift_max, sample_shift_max)\n",
    "        rawDict[key][i] = shiftVec(rawDict[key][i],shift)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiseSelector(noise, nSample):\n",
    "    length = len(noise)\n",
    "    choice = rnd.randint(0, length-1)\n",
    "    key = list(noise.keys())[choice]\n",
    "    start = rnd.randint(0, noise[key].shape[0]-nSample-1)\n",
    "    return noise[key][start:start+nSample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd.seed(1)\n",
    "noise_percentage = 0.1 \n",
    "for key in rawDict:\n",
    "    length = rawDict[key].shape[0]\n",
    "    toNoise = round(length*noise_percentage)\n",
    "    for i in rnd.sample(range(length),toNoise):\n",
    "        noise = noiseSelector(noiseDict, 16000)\n",
    "        rawDict[key][i] += np.array(np.round(np.random.uniform() * noise),dtype='int16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silence creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'silence'\n",
    "silence_percentage = 0.05\n",
    "max_noise_sound = 0.2\n",
    "silence_max = round(tot_samples*silence_percentage)\n",
    "values = []\n",
    "for i in range(silence_max):\n",
    "    noise = noiseSelector(noiseDict, 16000)\n",
    "    sig = noise * np.random.uniform(high = max_noise_sound)\n",
    "    values.append(sig)\n",
    "values = np.array(values)\n",
    "rawDict[key]=values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{verbatim}\n",
    "Parameter         Description\n",
    "signal \t          the audio signal from which to compute features. Should be an N*1 array\n",
    "samplerate \t      the samplerate of the signal we are working with.\n",
    "winlen \t          the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "winstep \t      the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "numcep \t          the number of cepstrum to return, default 13\n",
    "nfilt \t          the number of filters in the filterbank, default 26.\n",
    "nfft \t          the FFT size. Default is 512\n",
    "lowfreq \t      lowest band edge of mel filters. In Hz, default is 0\n",
    "highfreq \t      highest band edge of mel filters. In Hz, default is samplerate/2\\\\\n",
    "preemph \t      apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97\\\\\n",
    "ceplifter \t      apply a lifter to final cepstral coefficients. 0 is no lifter. Default is 22\\\\\n",
    "appendEnergy \t  if this is true, the zeroth cepstral coefficient is replaced with the log of the total frame energy.\\\\\n",
    "returns \t      A numpy array of size (NUMFRAMES by numcep) containing features. Each row holds 1 feature vector.\\\\\n",
    "\\end{verbatim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "variables/mfccDict[nC=13 wL=0.025 wS=0.01].pkl not found\n",
      "Processing  backward  ( 1 / 36 )\n",
      "Processing  bed  ( 2 / 36 )\n",
      "Processing  bird  ( 3 / 36 )\n",
      "Processing  cat  ( 4 / 36 )\n",
      "Processing  dog  ( 5 / 36 )\n",
      "Processing  down  ( 6 / 36 )\n",
      "Processing  eight  ( 7 / 36 )\n",
      "Processing  five  ( 8 / 36 )\n",
      "Processing  follow  ( 9 / 36 )\n",
      "Processing  forward  ( 10 / 36 )\n",
      "Processing  four  ( 11 / 36 )\n",
      "Processing  go  ( 12 / 36 )\n",
      "Processing  happy  ( 13 / 36 )\n",
      "Processing  house  ( 14 / 36 )\n",
      "Processing  learn  ( 15 / 36 )\n",
      "Processing  left  ( 16 / 36 )\n",
      "Processing  marvin  ( 17 / 36 )\n",
      "Processing  nine  ( 18 / 36 )\n",
      "Processing  no  ( 19 / 36 )\n",
      "Processing  off  ( 20 / 36 )\n",
      "Processing  on  ( 21 / 36 )\n",
      "Processing  one  ( 22 / 36 )\n",
      "Processing  right  ( 23 / 36 )\n",
      "Processing  seven  ( 24 / 36 )\n",
      "Processing  sheila  ( 25 / 36 )\n",
      "Processing  six  ( 26 / 36 )\n",
      "Processing  stop  ( 27 / 36 )\n",
      "Processing  three  ( 28 / 36 )\n",
      "Processing  tree  ( 29 / 36 )\n",
      "Processing  two  ( 30 / 36 )\n",
      "Processing  up  ( 31 / 36 )\n",
      "Processing  visual  ( 32 / 36 )\n",
      "Processing  wow  ( 33 / 36 )\n",
      "Processing  yes  ( 34 / 36 )\n",
      "Processing  zero  ( 35 / 36 )\n",
      "Processing  silence  ( 36 / 36 )\n",
      "\n",
      "variables/mfccDict[nC=15 wL=0.025 wS=0.01].pkl not found\n",
      "Processing  backward  ( 1 / 36 )\n",
      "Processing  bed  ( 2 / 36 )\n",
      "Processing  bird  ( 3 / 36 )\n",
      "Processing  cat  ( 4 / 36 )\n",
      "Processing  dog  ( 5 / 36 )\n",
      "Processing  down  ( 6 / 36 )\n",
      "Processing  eight  ( 7 / 36 )\n",
      "Processing  five  ( 8 / 36 )\n",
      "Processing  follow  ( 9 / 36 )\n",
      "Processing  forward  ( 10 / 36 )\n",
      "Processing  four  ( 11 / 36 )\n",
      "Processing  go  ( 12 / 36 )\n",
      "Processing  happy  ( 13 / 36 )\n",
      "Processing  house  ( 14 / 36 )\n",
      "Processing  learn  ( 15 / 36 )\n",
      "Processing  left  ( 16 / 36 )\n",
      "Processing  marvin  ( 17 / 36 )\n",
      "Processing  nine  ( 18 / 36 )\n",
      "Processing  no  ( 19 / 36 )\n",
      "Processing  off  ( 20 / 36 )\n",
      "Processing  on  ( 21 / 36 )\n",
      "Processing  one  ( 22 / 36 )\n",
      "Processing  right  ( 23 / 36 )\n",
      "Processing  seven  ( 24 / 36 )\n",
      "Processing  sheila  ( 25 / 36 )\n",
      "Processing  six  ( 26 / 36 )\n",
      "Processing  stop  ( 27 / 36 )\n",
      "Processing  three  ( 28 / 36 )\n",
      "Processing  tree  ( 29 / 36 )\n",
      "Processing  two  ( 30 / 36 )\n",
      "Processing  up  ( 31 / 36 )\n",
      "Processing  visual  ( 32 / 36 )\n",
      "Processing  wow  ( 33 / 36 )\n",
      "Processing  yes  ( 34 / 36 )\n",
      "Processing  zero  ( 35 / 36 )\n",
      "Processing  silence  ( 36 / 36 )\n",
      "\n",
      "variables/mfccDict[nC=20 wL=0.025 wS=0.01].pkl not found\n",
      "Processing  backward  ( 1 / 36 )\n",
      "Processing  bed  ( 2 / 36 )\n",
      "Processing  bird  ( 3 / 36 )\n",
      "Processing  cat  ( 4 / 36 )\n",
      "Processing  dog  ( 5 / 36 )\n",
      "Processing  down  ( 6 / 36 )\n",
      "Processing  eight  ( 7 / 36 )\n",
      "Processing  five  ( 8 / 36 )\n",
      "Processing  follow  ( 9 / 36 )\n",
      "Processing  forward  ( 10 / 36 )\n",
      "Processing  four  ( 11 / 36 )\n",
      "Processing  go  ( 12 / 36 )\n",
      "Processing  happy  ( 13 / 36 )\n",
      "Processing  house  ( 14 / 36 )\n",
      "Processing  learn  ( 15 / 36 )\n",
      "Processing  left  ( 16 / 36 )\n",
      "Processing  marvin  ( 17 / 36 )\n",
      "Processing  nine  ( 18 / 36 )\n",
      "Processing  no  ( 19 / 36 )\n",
      "Processing  off  ( 20 / 36 )\n",
      "Processing  on  ( 21 / 36 )\n",
      "Processing  one  ( 22 / 36 )\n",
      "Processing  right  ( 23 / 36 )\n",
      "Processing  seven  ( 24 / 36 )\n",
      "Processing  sheila  ( 25 / 36 )\n",
      "Processing  six  ( 26 / 36 )\n",
      "Processing  stop  ( 27 / 36 )\n",
      "Processing  three  ( 28 / 36 )\n",
      "Processing  tree  ( 29 / 36 )\n",
      "Processing  two  ( 30 / 36 )\n",
      "Processing  up  ( 31 / 36 )\n",
      "Processing  visual  ( 32 / 36 )\n",
      "Processing  wow  ( 33 / 36 )\n",
      "Processing  yes  ( 34 / 36 )\n",
      "Processing  zero  ( 35 / 36 )\n",
      "Processing  silence  ( 36 / 36 )\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list with mfcc parameters in order: [numcep, nfilt, winlen, winstep]\n",
    "values = [[13,26,0.025,0.01],[15,30,0.025,0.01], [20,40,0.025,0.01]]\n",
    "with open('variables/mfccValues.pkl', 'wb') as f:  \n",
    "    pickle.dump(values, f)\n",
    "reDo = True\n",
    "\n",
    "plt.figure(2,figsize=(10,3))\n",
    "#look for the already computed mfcc\n",
    "for count, i in enumerate(values):\n",
    "    name = 'variables/mfccDict[nC='+str(i[0])+' wL='+str(i[2])+' wS='+str(i[3])+'].pkl'\n",
    "    if os.path.exists(name) and not reDo:\n",
    "        print('\\n'+name+' found')\n",
    "        with open(name, 'rb') as f:  \n",
    "            mfccDict = pickle.load(f)\n",
    "        plt.subplot(round(len(values)/2)+1, 2, count+1)\n",
    "        plt.imshow(mfccDict['one'][0], cmap='hot', interpolation='nearest')\n",
    "    else:\n",
    "        print('\\n'+name+' not found')\n",
    "        mfccDict = {}\n",
    "        for countKey, key in enumerate(rawDict):\n",
    "            print('Processing ',key, \" (\", countKey+1, \"/\", len(rawDict),\")\" )\n",
    "            array = []\n",
    "            for sig in rawDict[key]:\n",
    "                mfcc_feat = mfcc(sig,sampleRate, numcep = i[0], nfilt = i[1], winlen = i[2], winstep = i[3])\n",
    "                array.append(mfcc_feat)\n",
    "            mfccDict[key] = np.array(array)\n",
    "        with open('variables/mfccDict[nC='+str(i[0])+' wL='+str(i[2])+' wS='+str(i[3])+'].pkl', 'wb') as f:  \n",
    "            pickle.dump(mfccDict, f)\n",
    "        plt.subplot(round(len(values)/2)+1, 2, count+1)\n",
    "        plt.imshow(mfccDict['one'][0], cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
