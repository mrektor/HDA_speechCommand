{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "## save variables\n",
    "import pickle\n",
    "## folder names\n",
    "from glob import glob\n",
    "## wav import\n",
    "from scipy.io import wavfile \n",
    "## standard libraries\n",
    "import numpy as np\n",
    "## MFCC\n",
    "#!{sys.executable} -m pip install msgpack --user\n",
    "#!{sys.executable} -m pip install python_speech_features --user\n",
    "\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "from python_speech_features import delta\n",
    "\n",
    "import random as rnd\n",
    "import os.path\n",
    "import tarfile\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "\n",
    "#!{sys.executable} -m pip install opencv-python --user\n",
    "#!{sys.executable} -m pip install opencv-contrib-python --user\n",
    "#import cv2\n",
    "#garbage collector\n",
    "import gc\n",
    "#OS detection\n",
    "import platform\n",
    "\n",
    "#!{sys.executable} -m pip install librosa --user\n",
    "import librosa\n",
    "\n",
    "#!{sys.executable} -m pip install progressbar2 --user\n",
    "import progressbar\n",
    "\n",
    "from dependencies import functions\n",
    "import functools\n",
    "\n",
    "from multiprocessing.dummy import Pool \n",
    "\n",
    "#!{sys.executable} -m pip install pydub --user\n",
    "#from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make variables directory if not present\n",
    "dest_directory = 'variables/'\n",
    "if not os.path.exists(dest_directory):\n",
    "      os.makedirs(dest_directory)\n",
    "\n",
    "        #data url from which download the dataset      \n",
    "data_url = 'http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz'\n",
    "\n",
    "#make dataset directory if not present\n",
    "dest_directory = 'dataset/'\n",
    "if not os.path.exists(dest_directory):\n",
    "      os.makedirs(dest_directory)\n",
    "\n",
    "#select the last part of the dataurl (the file name)      \n",
    "filename = data_url.split('/')[-1]\n",
    "filepath = os.path.join(dest_directory, filename)\n",
    "\n",
    "#program the download and extraction if the file doesn't exists\n",
    "if not os.path.exists(filepath):\n",
    "    def progress(count, block_size, total_size):\n",
    "        sys.stdout.write(\n",
    "            '\\r>> Downloading %s %.1f%%' %\n",
    "            (filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "        sys.stdout.flush()\n",
    "    try:\n",
    "        filepath, _ = urllib.request.urlretrieve(data_url, filepath, progress)\n",
    "    except:\n",
    "        print(Error)\n",
    "        \n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreKey = ['yes', \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"zero\",\n",
    "           \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
    "sampleRate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rawDict found\n",
      "rawDict loaded\n",
      "\n",
      "NOISE\n",
      "Processing  dataset\\_background_noise_\\doing_the_dishes.wav\n",
      "Processing  dataset\\_background_noise_\\dude_miaowing.wav\n",
      "Processing  dataset\\_background_noise_\\exercise_bike.wav\n",
      "Processing  dataset\\_background_noise_\\pink_noise.wav\n",
      "Processing  dataset\\_background_noise_\\running_tap.wav\n",
      "Processing  dataset\\_background_noise_\\white_noise.wav\n",
      "noiseDict created and saved to variables/noiseDict.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yurin\\Anaconda3\\lib\\site-packages\\scipy\\io\\wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "#control if the raw data are saved with pickle\n",
    "#if true they will be loaded in rawDict\n",
    "reDo = False\n",
    "pathName = {}\n",
    "if os.path.exists('variables/rawDict.pkl') and not reDo:\n",
    "    print('rawDict found')\n",
    "    with open('variables/rawDict.pkl', 'rb') as f:  \n",
    "        rawDict = pickle.load(f)\n",
    "    with open('variables/pathName.pkl', 'rb') as f:  \n",
    "        pathName = pickle.load(f)\n",
    "    print('rawDict loaded')\n",
    "\n",
    "#else they will be loaded from wav files\n",
    "else:\n",
    "    print('Creating rawDict')\n",
    "    folders = glob(os.path.join('dataset', '*', ''))\n",
    "    folders.remove(os.path.join('dataset', '_background_noise_', ''))\n",
    "    print('SIGNALS')\n",
    "    rawDict = {}\n",
    "    for key in folders:\n",
    "        print('Processing ', key)\n",
    "        dictKey = os.path.basename(os.path.dirname(key))\n",
    "        tmpFiles = glob(key+'*')\n",
    "        array = []\n",
    "        pathList = []\n",
    "        for file in tmpFiles:\n",
    "            pathList.append(file)\n",
    "            tmp = wavfile.read(file)[1].copy()\n",
    "            tmp.resize(16000, refcheck=False)\n",
    "            array.append(tmp)\n",
    "        rawDict[dictKey] = np.array(array)\n",
    "        pathName[dictKey] = pathList\n",
    "    #and saved with pickle\n",
    "    with open('variables/rawDict.pkl', 'wb') as f:  \n",
    "        pickle.dump(rawDict, f)\n",
    "    with open('variables/pathName.pkl', 'wb') as f:  \n",
    "        pickle.dump(pathName, f)\n",
    "    print('rawDict created and saved to variables/rawDict.pkl')\n",
    "reDo = True\n",
    "#the same with noise signals\n",
    "if not os.path.exists('variables/noiseDict.pkl') or reDo:    \n",
    "    print('\\nNOISE')\n",
    "    noiseDict = {}\n",
    "    folders = glob(os.path.join('dataset', '_background_noise_', '*.wav'))\n",
    "    for key in folders:\n",
    "        print('Processing ', key)\n",
    "        noiseDict[os.path.basename(key)] = wavfile.read(key)[1]\n",
    "    with open('variables/noiseDict.pkl', 'wb') as f:  \n",
    "        pickle.dump(noiseDict, f) \n",
    "    print('noiseDict created and saved to variables/noiseDict.pkl')\n",
    "else:\n",
    "    print('noiseDict found')\n",
    "    with open('variables/noiseDict.pkl', 'rb') as f:  \n",
    "        noiseDict = pickle.load(f)\n",
    "    print('noiseDict loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 509 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "shift_percentage = 0.1\n",
    "time_shift_max = 100 #[ms]\n",
    "sample_shift_max = round(time_shift_max / 1000 * sampleRate)\n",
    "\n",
    "for key in rawDict:\n",
    "    length = rawDict[key].shape[0]\n",
    "    toShift = round(length*shift_percentage)\n",
    "    for i in rnd.sample(range(length),toShift):\n",
    "        shift = rnd.randint(-sample_shift_max, sample_shift_max)\n",
    "        rawDict[key][i] = functions.shiftVec(rawDict[key][i],shift)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "noise_percentage = 0.1 \n",
    "max_noise = .4\n",
    "for key in rawDict:\n",
    "    length = rawDict[key].shape[0]\n",
    "    toNoise = round(length*noise_percentage)\n",
    "    for i in rnd.sample(range(length),toNoise):\n",
    "        noise = functions.noiseSelector(noiseDict, sampleRate)\n",
    "        rawDict[key][i] += np.array(np.round(np.random.uniform(high = max_noise) * noise),dtype='int16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silence creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 633 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "key = 'silence'\n",
    "silence_percentage = 0.05\n",
    "min_noise_sound = .1\n",
    "max_noise_sound = 0.5\n",
    "#silence_max = round(tot_samples*silence_percentage)\n",
    "silence_max = 5000\n",
    "values = []\n",
    "for i in range(silence_max):\n",
    "    noise = functions.noiseSelector(noiseDict, sampleRate)\n",
    "    sig = noise * np.random.uniform(high = max_noise_sound, low = min_noise_sound)\n",
    "    values.append(sig)\n",
    "values = np.array(values)\n",
    "rawDict[key]=values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def resample(sample, sr = 16000, n_sr = 12000, res_type = 'kaiser_fast', scale = False):\n",
    "    return librosa.core.resample(np.array(sample, dtype = 'float32'), sr, n_sr, res_type = res_type, scale = scale)\n",
    "pool = Pool(4)\n",
    "\n",
    "print('Downsampling rawDict')\n",
    "for count, key in enumerate(rawDict):\n",
    "    print('Processing ',key, \" (\", count+1, \"/\", len(rawDict),\")\" )\n",
    "    resampledKey = []\n",
    "    a = list(rawDict[key])    \n",
    "    results = pool.map(resample, a)\n",
    "    results = np.array(results, dtype='int16')\n",
    "    rawDict[key] = results\n",
    "    \n",
    "print('Downsampling noiseDict')\n",
    "for count, key in enumerate(noiseDict):\n",
    "    print('Processing ',key, \" (\", count+1, \"/\", len(noiseDict),\")\" )\n",
    "    resampledKey = []   \n",
    "    results = np.array(resample(noiseDict[key]), dtype='int16')\n",
    "    noiseDict[key] = results\n",
    "\n",
    "print('Downsampled to:' , rawDict['one'][0].shape[0], ' Hz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainDict = {}\n",
    "validationDict = {}\n",
    "testDict = {}\n",
    "\n",
    "validation_percentage = 15\n",
    "testing_percentage = 15\n",
    "\n",
    "for key in rawDict:\n",
    "    if key == 'silence':\n",
    "        #already random so \n",
    "        trainDict[key]= rawDict[key][0:round(silence_max*(1-validation_percentage/100-testing_percentage/100))]\n",
    "        validationDict[key] = rawDict[key][round(silence_max*(1-validation_percentage/100-testing_percentage/100)):round(silence_max*(1-testing_percentage/100))]\n",
    "        testDict[key] = rawDict[key][round(silence_max*(1-testing_percentage/100)):silence_max]\n",
    "    else:\n",
    "        testTemp = []\n",
    "        trainTemp = []\n",
    "        validTemp = []\n",
    "        for count, sample in enumerate(rawDict[key]):\n",
    "            assign = functions.which_set(pathName[key][count], validation_percentage, testing_percentage, 2**27 - 1)\n",
    "            if assign == 'testing':\n",
    "                testTemp.append(sample)\n",
    "            elif assign == 'training':\n",
    "                trainTemp.append(sample)\n",
    "            elif assign == 'validation':\n",
    "                validTemp.append(sample)\n",
    "        trainDict[key]= np.array(trainTemp)\n",
    "        validationDict[key] = np.array(validTemp)\n",
    "        testDict[key] = np.array(testTemp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "Only on core keys and on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStretch():\n",
    "    low = np.round(np.random.uniform(low = 0.85, high = 0.95), decimals = 2)\n",
    "    high = np.round(np.random.uniform(low = 1.05, high = 1.15), decimals = 2)\n",
    "    return rnd.choice([low,high])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing yes (1/20)  Time:  0:01:14                                          \n",
      "Processing no (2/20)  Time:  0:01:11                                           \n",
      "Processing up (3/20)  Time:  0:01:06                                           \n",
      "Processing down (4/20)  Time:  0:01:10                                         \n",
      "Processing left (5/20)  Time:  0:01:08                                         \n",
      "Processing right (6/20)  Time:  0:01:07                                        \n",
      "Processing on (7/20)  Time:  0:01:10                                           \n",
      "Processing off (8/20)  Time:  0:01:06                                          \n",
      "Processing stop (9/20)  Time:  0:01:10                                         \n",
      "Processing go (10/20)  Time:  0:01:10                                          \n",
      "Processing zero (11/20)  Time:  0:01:13                                        \n",
      "Processing one (12/20)  Time:  0:01:10                                         \n",
      "Processing two (13/20)  Time:  0:01:11                                         \n",
      "Processing three (14/20)  Time:  0:01:06                                       \n",
      "Processing four (15/20)  Time:  0:01:06                                        \n",
      "Processing five (16/20)  Time:  0:01:12                                        \n",
      "Processing six (17/20)  Time:  0:01:09                                         \n",
      "Processing seven (18/20)  Time:  0:01:12                                       \n",
      "Processing eight (19/20)  Time:  0:01:07                                       \n",
      "Processing nine (20/20)  Time:  0:01:11                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import progressbar\n",
    "\n",
    "rnd.seed(1)\n",
    "\n",
    "augmented_percentage = 1\n",
    "\n",
    "def newSample(sample, max_noise = .2, sampleRate = 16000, time_shift_max = 50):\n",
    "    new_sample = functions.stretch(np.array(sample,dtype='float32') , getStretch())\n",
    "    new_sample = np.array(librosa.effects.pitch_shift(new_sample, sampleRate, n_steps = rnd.choice([-11, -8, -5, -3, 3, 5, 8, 11])), dtype = 'int16')\n",
    "    return sample\n",
    "    \n",
    "pool = Pool(2)\n",
    "trainDictAugmented = {}\n",
    "for countKey, key in enumerate(coreKey):\n",
    "    length = trainDict[key].shape[0]\n",
    "    toAugment = round(length*augmented_percentage)\n",
    "    new_bunch_of_samples = []\n",
    "    iterate = rnd.sample(range(length),toAugment)\n",
    "    widgets = [\n",
    "        'Processing ' +str(key)+ \" (\"+ str(countKey+1) + \"/\" + str(len(coreKey)) + \")\",\n",
    "        '  ', progressbar.ETA()\n",
    "        \n",
    "    ]\n",
    "    bar = progressbar.ProgressBar(widgets=widgets, max_value=len(iterate))\n",
    "    bar.start()\n",
    "    samples = trainDict[key][iterate]\n",
    "    results = np.array(pool.map(newSample, samples))\n",
    "    bar.finish()\n",
    "    trainDictAugmented[key] = results\n",
    "\n",
    "key = 'silence'\n",
    "silence_percentage = 0.05\n",
    "min_noise_sound = .1\n",
    "max_noise_sound = 0.5\n",
    "#silence_max = round(tot_samples*silence_percentage)\n",
    "silence_max = 4000\n",
    "values = []\n",
    "for i in range(silence_max):\n",
    "    noise = functions.noiseSelector(noiseDict, sampleRate)\n",
    "    sig = noise * np.random.uniform(high = max_noise_sound, low = min_noise_sound)\n",
    "    values.append(sig)\n",
    "values = np.array(values)\n",
    "trainDictAugmented[key]=values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with mfcc parameters in order: [numcep, nfilt, winlen, winstep]+\n",
    "valuesMFCC = [[14,40,0.025,0.01,512]]\n",
    "with open('variables/mfccValues.pkl', 'wb') as f:  \n",
    "    pickle.dump(valuesMFCC,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{verbatim}\n",
    "Parameter         Description\n",
    "signal \t          the audio signal from which to compute features. Should be an N*1 array\n",
    "samplerate \t      the samplerate of the signal we are working with.\n",
    "winlen \t          the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "winstep \t      the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "numcep \t          the number of cepstrum to return, default 13\n",
    "nfilt \t          the number of filters in the filterbank, default 26.\n",
    "nfft \t          the FFT size. Default is 512\n",
    "lowfreq \t      lowest band edge of mel filters. In Hz, default is 0\n",
    "highfreq \t      highest band edge of mel filters. In Hz, default is samplerate/2\\\\\n",
    "preemph \t      apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97\\\\\n",
    "ceplifter \t      apply a lifter to final cepstral coefficients. 0 is no lifter. Default is 22\\\\\n",
    "appendEnergy \t  if this is true, the zeroth cepstral coefficient is replaced with the log of the total frame energy.\\\\\n",
    "returns \t      A numpy array of size (NUMFRAMES by numcep) containing features. Each row holds 1 feature vector.\\\\\n",
    "\\end{verbatim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMFCC(data, output, i, sampleRate = 8000):\n",
    "    for sig in data:\n",
    "        mfcc_feat = mfcc(sig,sampleRate, preemph = 0.97, numcep = i[0], nfilt = i[1], winlen = i[2], winstep = i[3], nfft = i[4], appendEnergy = False)\n",
    "        output.append(mfcc_feat)\n",
    "def computeLogF(data, output, i, sampleRate = 8000):\n",
    "    for sig in data:\n",
    "        lfilt_feat = logfbank(sig,sampleRate, preemph = 0.97, nfilt = i[0], winlen = i[1], winstep = i[2], nfft = i[3])\n",
    "        output.append(lfilt_feat)\n",
    "def computeDelta(mfccValues, N = 2):\n",
    "    temp = []\n",
    "    for count, _ in enumerate(mfccValues):\n",
    "        delt = delta(mfccValues[count], N)\n",
    "        temp.append(delt)\n",
    "    return temp        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#####Coumputing Train Set#####\n",
      "Processing  backward  ( 1 / 36 )\n",
      "Processing  bed  ( 2 / 36 )\n",
      "Processing  bird  ( 3 / 36 )\n",
      "Processing  cat  ( 4 / 36 )\n",
      "Processing  dog  ( 5 / 36 )\n",
      "Processing  down  ( 6 / 36 )\n",
      "Processing  eight  ( 7 / 36 )\n",
      "Processing  five  ( 8 / 36 )\n",
      "Processing  follow  ( 9 / 36 )\n",
      "Processing  forward  ( 10 / 36 )\n",
      "Processing  four  ( 11 / 36 )\n",
      "Processing  go  ( 12 / 36 )\n",
      "Processing  happy  ( 13 / 36 )\n",
      "Processing  house  ( 14 / 36 )\n",
      "Processing  learn  ( 15 / 36 )\n",
      "Processing  left  ( 16 / 36 )\n",
      "Processing  marvin  ( 17 / 36 )\n",
      "Processing  nine  ( 18 / 36 )\n",
      "Processing  no  ( 19 / 36 )\n",
      "Processing  off  ( 20 / 36 )\n",
      "Processing  on  ( 21 / 36 )\n",
      "Processing  one  ( 22 / 36 )\n",
      "Processing  right  ( 23 / 36 )\n",
      "Processing  seven  ( 24 / 36 )\n",
      "Processing  sheila  ( 25 / 36 )\n",
      "Processing  six  ( 26 / 36 )\n",
      "Processing  stop  ( 27 / 36 )\n",
      "Processing  three  ( 28 / 36 )\n",
      "Processing  tree  ( 29 / 36 )\n",
      "Processing  two  ( 30 / 36 )\n",
      "Processing  up  ( 31 / 36 )\n",
      "Processing  visual  ( 32 / 36 )\n",
      "Processing  wow  ( 33 / 36 )\n",
      "Processing  yes  ( 34 / 36 )\n",
      "Processing  zero  ( 35 / 36 )\n",
      "Processing  silence  ( 36 / 36 )\n",
      "\n",
      "  Processing delta and delta-delta\n",
      "Processing  backward  ( 1 / 36 )\n",
      "Processing  bed  ( 2 / 36 )\n",
      "Processing  bird  ( 3 / 36 )\n",
      "Processing  cat  ( 4 / 36 )\n",
      "Processing  dog  ( 5 / 36 )\n",
      "Processing  down  ( 6 / 36 )\n",
      "Processing  eight  ( 7 / 36 )\n",
      "Processing  five  ( 8 / 36 )\n",
      "Processing  follow  ( 9 / 36 )\n",
      "Processing  forward  ( 10 / 36 )\n",
      "Processing  four  ( 11 / 36 )\n",
      "Processing  go  ( 12 / 36 )\n",
      "Processing  happy  ( 13 / 36 )\n",
      "Processing  house  ( 14 / 36 )\n",
      "Processing  learn  ( 15 / 36 )\n",
      "Processing  left  ( 16 / 36 )\n",
      "Processing  marvin  ( 17 / 36 )\n",
      "Processing  nine  ( 18 / 36 )\n",
      "Processing  no  ( 19 / 36 )\n",
      "Processing  off  ( 20 / 36 )\n",
      "Processing  on  ( 21 / 36 )\n",
      "Processing  one  ( 22 / 36 )\n",
      "Processing  right  ( 23 / 36 )\n",
      "Processing  seven  ( 24 / 36 )\n",
      "Processing  sheila  ( 25 / 36 )\n",
      "Processing  six  ( 26 / 36 )\n",
      "Processing  stop  ( 27 / 36 )\n",
      "Processing  three  ( 28 / 36 )\n",
      "Processing  tree  ( 29 / 36 )\n",
      "Processing  two  ( 30 / 36 )\n",
      "Processing  up  ( 31 / 36 )\n",
      "Processing  visual  ( 32 / 36 )\n",
      "Processing  wow  ( 33 / 36 )\n",
      "Processing  yes  ( 34 / 36 )\n",
      "Processing  zero  ( 35 / 36 )\n",
      "Processing  silence  ( 36 / 36 )\n",
      "\n",
      "#####Coumputing Test Set#####\n",
      "Processing  backward  ( 1 / 36 )\n",
      "Processing  bed  ( 2 / 36 )\n",
      "Processing  bird  ( 3 / 36 )\n",
      "Processing  cat  ( 4 / 36 )\n",
      "Processing  dog  ( 5 / 36 )\n",
      "Processing  down  ( 6 / 36 )\n",
      "Processing  eight  ( 7 / 36 )\n",
      "Processing  five  ( 8 / 36 )\n",
      "Processing  follow  ( 9 / 36 )\n",
      "Processing  forward  ( 10 / 36 )\n",
      "Processing  four  ( 11 / 36 )\n",
      "Processing  go  ( 12 / 36 )\n",
      "Processing  happy  ( 13 / 36 )\n",
      "Processing  house  ( 14 / 36 )\n",
      "Processing  learn  ( 15 / 36 )\n",
      "Processing  left  ( 16 / 36 )\n",
      "Processing  marvin  ( 17 / 36 )\n",
      "Processing  nine  ( 18 / 36 )\n",
      "Processing  no  ( 19 / 36 )\n",
      "Processing  off  ( 20 / 36 )\n",
      "Processing  on  ( 21 / 36 )\n",
      "Processing  one  ( 22 / 36 )\n",
      "Processing  right  ( 23 / 36 )\n",
      "Processing  seven  ( 24 / 36 )\n",
      "Processing  sheila  ( 25 / 36 )\n",
      "Processing  six  ( 26 / 36 )\n",
      "Processing  stop  ( 27 / 36 )\n",
      "Processing  three  ( 28 / 36 )\n",
      "Processing  tree  ( 29 / 36 )\n",
      "Processing  two  ( 30 / 36 )\n",
      "Processing  up  ( 31 / 36 )\n",
      "Processing  visual  ( 32 / 36 )\n",
      "Processing  wow  ( 33 / 36 )\n",
      "Processing  yes  ( 34 / 36 )\n",
      "Processing  zero  ( 35 / 36 )\n",
      "Processing  silence  ( 36 / 36 )\n",
      "\n",
      "  Processing delta and delta-delta\n",
      "Processing  backward  ( 1 / 36 )\n",
      "Processing  bed  ( 2 / 36 )\n",
      "Processing  bird  ( 3 / 36 )\n",
      "Processing  cat  ( 4 / 36 )\n",
      "Processing  dog  ( 5 / 36 )\n",
      "Processing  down  ( 6 / 36 )\n",
      "Processing  eight  ( 7 / 36 )\n",
      "Processing  five  ( 8 / 36 )\n",
      "Processing  follow  ( 9 / 36 )\n",
      "Processing  forward  ( 10 / 36 )\n",
      "Processing  four  ( 11 / 36 )\n",
      "Processing  go  ( 12 / 36 )\n",
      "Processing  happy  ( 13 / 36 )\n",
      "Processing  house  ( 14 / 36 )\n",
      "Processing  learn  ( 15 / 36 )\n",
      "Processing  left  ( 16 / 36 )\n",
      "Processing  marvin  ( 17 / 36 )\n",
      "Processing  nine  ( 18 / 36 )\n",
      "Processing  no  ( 19 / 36 )\n",
      "Processing  off  ( 20 / 36 )\n",
      "Processing  on  ( 21 / 36 )\n",
      "Processing  one  ( 22 / 36 )\n",
      "Processing  right  ( 23 / 36 )\n",
      "Processing  seven  ( 24 / 36 )\n",
      "Processing  sheila  ( 25 / 36 )\n",
      "Processing  six  ( 26 / 36 )\n",
      "Processing  stop  ( 27 / 36 )\n",
      "Processing  three  ( 28 / 36 )\n",
      "Processing  tree  ( 29 / 36 )\n",
      "Processing  two  ( 30 / 36 )\n",
      "Processing  up  ( 31 / 36 )\n",
      "Processing  visual  ( 32 / 36 )\n",
      "Processing  wow  ( 33 / 36 )\n",
      "Processing  yes  ( 34 / 36 )\n",
      "Processing  zero  ( 35 / 36 )\n",
      "Processing  silence  ( 36 / 36 )\n",
      "\n",
      "#####Coumputing Validation Set#####\n",
      "Processing  backward  ( 1 / 36 )\n",
      "Processing  bed  ( 2 / 36 )\n",
      "Processing  bird  ( 3 / 36 )\n",
      "Processing  cat  ( 4 / 36 )\n",
      "Processing  dog  ( 5 / 36 )\n",
      "Processing  down  ( 6 / 36 )\n",
      "Processing  eight  ( 7 / 36 )\n",
      "Processing  five  ( 8 / 36 )\n",
      "Processing  follow  ( 9 / 36 )\n",
      "Processing  forward  ( 10 / 36 )\n",
      "Processing  four  ( 11 / 36 )\n",
      "Processing  go  ( 12 / 36 )\n",
      "Processing  happy  ( 13 / 36 )\n",
      "Processing  house  ( 14 / 36 )\n",
      "Processing  learn  ( 15 / 36 )\n",
      "Processing  left  ( 16 / 36 )\n",
      "Processing  marvin  ( 17 / 36 )\n",
      "Processing  nine  ( 18 / 36 )\n",
      "Processing  no  ( 19 / 36 )\n",
      "Processing  off  ( 20 / 36 )\n",
      "Processing  on  ( 21 / 36 )\n",
      "Processing  one  ( 22 / 36 )\n",
      "Processing  right  ( 23 / 36 )\n",
      "Processing  seven  ( 24 / 36 )\n",
      "Processing  sheila  ( 25 / 36 )\n",
      "Processing  six  ( 26 / 36 )\n",
      "Processing  stop  ( 27 / 36 )\n",
      "Processing  three  ( 28 / 36 )\n",
      "Processing  tree  ( 29 / 36 )\n",
      "Processing  two  ( 30 / 36 )\n",
      "Processing  up  ( 31 / 36 )\n",
      "Processing  visual  ( 32 / 36 )\n",
      "Processing  wow  ( 33 / 36 )\n",
      "Processing  yes  ( 34 / 36 )\n",
      "Processing  zero  ( 35 / 36 )\n",
      "Processing  silence  ( 36 / 36 )\n",
      "\n",
      "  Processing delta and delta-delta\n",
      "Processing  backward  ( 1 / 36 )\n",
      "Processing  bed  ( 2 / 36 )\n",
      "Processing  bird  ( 3 / 36 )\n",
      "Processing  cat  ( 4 / 36 )\n",
      "Processing  dog  ( 5 / 36 )\n",
      "Processing  down  ( 6 / 36 )\n",
      "Processing  eight  ( 7 / 36 )\n",
      "Processing  five  ( 8 / 36 )\n",
      "Processing  follow  ( 9 / 36 )\n",
      "Processing  forward  ( 10 / 36 )\n",
      "Processing  four  ( 11 / 36 )\n",
      "Processing  go  ( 12 / 36 )\n",
      "Processing  happy  ( 13 / 36 )\n",
      "Processing  house  ( 14 / 36 )\n",
      "Processing  learn  ( 15 / 36 )\n",
      "Processing  left  ( 16 / 36 )\n",
      "Processing  marvin  ( 17 / 36 )\n",
      "Processing  nine  ( 18 / 36 )\n",
      "Processing  no  ( 19 / 36 )\n",
      "Processing  off  ( 20 / 36 )\n",
      "Processing  on  ( 21 / 36 )\n",
      "Processing  one  ( 22 / 36 )\n",
      "Processing  right  ( 23 / 36 )\n",
      "Processing  seven  ( 24 / 36 )\n",
      "Processing  sheila  ( 25 / 36 )\n",
      "Processing  six  ( 26 / 36 )\n",
      "Processing  stop  ( 27 / 36 )\n",
      "Processing  three  ( 28 / 36 )\n",
      "Processing  tree  ( 29 / 36 )\n",
      "Processing  two  ( 30 / 36 )\n",
      "Processing  up  ( 31 / 36 )\n",
      "Processing  visual  ( 32 / 36 )\n",
      "Processing  wow  ( 33 / 36 )\n",
      "Processing  yes  ( 34 / 36 )\n",
      "Processing  zero  ( 35 / 36 )\n",
      "Processing  silence  ( 36 / 36 )\n",
      "\n",
      "#####Coumputing AugmentedTrain Set#####\n",
      "Processing  yes  ( 1 / 21 )\n",
      "Processing  no  ( 2 / 21 )\n",
      "Processing  up  ( 3 / 21 )\n",
      "Processing  down  ( 4 / 21 )\n",
      "Processing  left  ( 5 / 21 )\n",
      "Processing  right  ( 6 / 21 )\n",
      "Processing  on  ( 7 / 21 )\n",
      "Processing  off  ( 8 / 21 )\n",
      "Processing  stop  ( 9 / 21 )\n",
      "Processing  go  ( 10 / 21 )\n",
      "Processing  zero  ( 11 / 21 )\n",
      "Processing  one  ( 12 / 21 )\n",
      "Processing  two  ( 13 / 21 )\n",
      "Processing  three  ( 14 / 21 )\n",
      "Processing  four  ( 15 / 21 )\n",
      "Processing  five  ( 16 / 21 )\n",
      "Processing  six  ( 17 / 21 )\n",
      "Processing  seven  ( 18 / 21 )\n",
      "Processing  eight  ( 19 / 21 )\n",
      "Processing  nine  ( 20 / 21 )\n",
      "Processing  silence  ( 21 / 21 )\n",
      "\n",
      "  Processing delta and delta-delta\n",
      "Processing  yes  ( 1 / 21 )\n",
      "Processing  no  ( 2 / 21 )\n",
      "Processing  up  ( 3 / 21 )\n",
      "Processing  down  ( 4 / 21 )\n",
      "Processing  left  ( 5 / 21 )\n",
      "Processing  right  ( 6 / 21 )\n",
      "Processing  on  ( 7 / 21 )\n",
      "Processing  off  ( 8 / 21 )\n",
      "Processing  stop  ( 9 / 21 )\n",
      "Processing  go  ( 10 / 21 )\n",
      "Processing  zero  ( 11 / 21 )\n",
      "Processing  one  ( 12 / 21 )\n",
      "Processing  two  ( 13 / 21 )\n",
      "Processing  three  ( 14 / 21 )\n",
      "Processing  four  ( 15 / 21 )\n",
      "Processing  five  ( 16 / 21 )\n",
      "Processing  six  ( 17 / 21 )\n",
      "Processing  seven  ( 18 / 21 )\n",
      "Processing  eight  ( 19 / 21 )\n",
      "Processing  nine  ( 20 / 21 )\n",
      "Processing  silence  ( 21 / 21 )\n",
      "Wall time: 8min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def getName(index):\n",
    "    if index == 0:\n",
    "        return 'Train'\n",
    "    elif index == 1:\n",
    "        return 'Test'\n",
    "    elif index == 2:\n",
    "        return 'Validation'\n",
    "    elif index == 3:\n",
    "        return 'AugmentedTrain'\n",
    "    \n",
    "#look for the already computed mfcc\n",
    "dictionaries = [trainDict, testDict, validationDict, trainDictAugmented]\n",
    "for count, i in enumerate(valuesMFCC):\n",
    "    for index, dictionary in enumerate(dictionaries):\n",
    "        print('\\n#####Coumputing '+getName(index)+ ' Set#####')\n",
    "        nameMFCC = 'variables/mfccDict'+functions.getName(index)+'[nC='+str(i[0])+' wL='+str(i[2])+' wS='+str(i[3])+'].pkl'\n",
    "        nameDelta = 'variables/mfccDictDD'+functions.getName(index)+'[nC='+str(i[0])+' wL='+str(i[2])+' wS='+str(i[3])+'].pkl'\n",
    "        mfccDict = {}\n",
    "        for countKey, key in enumerate(dictionary):\n",
    "            print('Processing ',key, \" (\", countKey+1, \"/\", len(dictionary),\")\" )\n",
    "            array = []\n",
    "            computeMFCC(dictionary[key], array, i, sampleRate = sampleRate)            \n",
    "            mfccDict[key] = np.array(array)\n",
    "        \n",
    "        with open(nameMFCC, 'wb') as f:  \n",
    "            pickle.dump(mfccDict, f)\n",
    "            \n",
    "        print(\"\\n  Processing delta and delta-delta\")\n",
    "        for countKey, key in enumerate(mfccDict):\n",
    "            print('Processing ',key, \" (\", countKey+1, \"/\", len(mfccDict),\")\" )\n",
    "            delt = np.array(computeDelta(mfccDict[key]))\n",
    "            deltdelt = np.array(computeDelta(delt))\n",
    "            mfccDict[key] = np.stack([mfccDict[key],delt,deltdelt], axis = -1)\n",
    "        \n",
    "        with open(nameDelta, 'wb') as f:  \n",
    "            pickle.dump(mfccDict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogFilter with delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuesLF = [[26,0.025,0.01,512]]\n",
    "with open('variables/lfValues.pkl', 'wb') as f:  \n",
    "    pickle.dump(valuesLF,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#####Coumputing Train Set#####\n",
      "Processing  backward  ( 1 / 36 )\n",
      "Processing  bed  ( 2 / 36 )\n",
      "Processing  bird  ( 3 / 36 )\n",
      "Processing  cat  ( 4 / 36 )\n",
      "Processing  dog  ( 5 / 36 )\n",
      "Processing  down  ( 6 / 36 )\n",
      "Processing  eight  ( 7 / 36 )\n",
      "Processing  five  ( 8 / 36 )\n",
      "Processing  follow  ( 9 / 36 )\n",
      "Processing  forward  ( 10 / 36 )\n",
      "Processing  four  ( 11 / 36 )\n",
      "Processing  go  ( 12 / 36 )\n",
      "Processing  happy  ( 13 / 36 )\n",
      "Processing  house  ( 14 / 36 )\n",
      "Processing  learn  ( 15 / 36 )\n",
      "Processing  left  ( 16 / 36 )\n",
      "Processing  marvin  ( 17 / 36 )\n",
      "Processing  nine  ( 18 / 36 )\n",
      "Processing  no  ( 19 / 36 )\n",
      "Processing  off  ( 20 / 36 )\n",
      "Processing  on  ( 21 / 36 )\n",
      "Processing  one  ( 22 / 36 )\n",
      "Processing  right  ( 23 / 36 )\n",
      "Processing  seven  ( 24 / 36 )\n",
      "Processing  sheila  ( 25 / 36 )\n",
      "Processing  six  ( 26 / 36 )\n",
      "Processing  stop  ( 27 / 36 )\n",
      "Processing  three  ( 28 / 36 )\n",
      "Processing  tree  ( 29 / 36 )\n",
      "Processing  two  ( 30 / 36 )\n",
      "Processing  up  ( 31 / 36 )\n",
      "Processing  visual  ( 32 / 36 )\n",
      "Processing  wow  ( 33 / 36 )\n",
      "Processing  yes  ( 34 / 36 )\n",
      "Processing  zero  ( 35 / 36 )\n",
      "Processing  silence  ( 36 / 36 )\n",
      "\n",
      "#####Coumputing Test Set#####\n",
      "Processing  backward  ( 1 / 36 )\n",
      "Processing  bed  ( 2 / 36 )\n",
      "Processing  bird  ( 3 / 36 )\n",
      "Processing  cat  ( 4 / 36 )\n",
      "Processing  dog  ( 5 / 36 )\n",
      "Processing  down  ( 6 / 36 )\n",
      "Processing  eight  ( 7 / 36 )\n",
      "Processing  five  ( 8 / 36 )\n",
      "Processing  follow  ( 9 / 36 )\n",
      "Processing  forward  ( 10 / 36 )\n",
      "Processing  four  ( 11 / 36 )\n",
      "Processing  go  ( 12 / 36 )\n",
      "Processing  happy  ( 13 / 36 )\n",
      "Processing  house  ( 14 / 36 )\n",
      "Processing  learn  ( 15 / 36 )\n",
      "Processing  left  ( 16 / 36 )\n",
      "Processing  marvin  ( 17 / 36 )\n",
      "Processing  nine  ( 18 / 36 )\n",
      "Processing  no  ( 19 / 36 )\n",
      "Processing  off  ( 20 / 36 )\n",
      "Processing  on  ( 21 / 36 )\n",
      "Processing  one  ( 22 / 36 )\n",
      "Processing  right  ( 23 / 36 )\n",
      "Processing  seven  ( 24 / 36 )\n",
      "Processing  sheila  ( 25 / 36 )\n",
      "Processing  six  ( 26 / 36 )\n",
      "Processing  stop  ( 27 / 36 )\n",
      "Processing  three  ( 28 / 36 )\n",
      "Processing  tree  ( 29 / 36 )\n",
      "Processing  two  ( 30 / 36 )\n",
      "Processing  up  ( 31 / 36 )\n",
      "Processing  visual  ( 32 / 36 )\n",
      "Processing  wow  ( 33 / 36 )\n",
      "Processing  yes  ( 34 / 36 )\n",
      "Processing  zero  ( 35 / 36 )\n",
      "Processing  silence  ( 36 / 36 )\n",
      "\n",
      "#####Coumputing Validation Set#####\n",
      "Processing  backward  ( 1 / 36 )\n",
      "Processing  bed  ( 2 / 36 )\n",
      "Processing  bird  ( 3 / 36 )\n",
      "Processing  cat  ( 4 / 36 )\n",
      "Processing  dog  ( 5 / 36 )\n",
      "Processing  down  ( 6 / 36 )\n",
      "Processing  eight  ( 7 / 36 )\n",
      "Processing  five  ( 8 / 36 )\n",
      "Processing  follow  ( 9 / 36 )\n",
      "Processing  forward  ( 10 / 36 )\n",
      "Processing  four  ( 11 / 36 )\n",
      "Processing  go  ( 12 / 36 )\n",
      "Processing  happy  ( 13 / 36 )\n",
      "Processing  house  ( 14 / 36 )\n",
      "Processing  learn  ( 15 / 36 )\n",
      "Processing  left  ( 16 / 36 )\n",
      "Processing  marvin  ( 17 / 36 )\n",
      "Processing  nine  ( 18 / 36 )\n",
      "Processing  no  ( 19 / 36 )\n",
      "Processing  off  ( 20 / 36 )\n",
      "Processing  on  ( 21 / 36 )\n",
      "Processing  one  ( 22 / 36 )\n",
      "Processing  right  ( 23 / 36 )\n",
      "Processing  seven  ( 24 / 36 )\n",
      "Processing  sheila  ( 25 / 36 )\n",
      "Processing  six  ( 26 / 36 )\n",
      "Processing  stop  ( 27 / 36 )\n",
      "Processing  three  ( 28 / 36 )\n",
      "Processing  tree  ( 29 / 36 )\n",
      "Processing  two  ( 30 / 36 )\n",
      "Processing  up  ( 31 / 36 )\n",
      "Processing  visual  ( 32 / 36 )\n",
      "Processing  wow  ( 33 / 36 )\n",
      "Processing  yes  ( 34 / 36 )\n",
      "Processing  zero  ( 35 / 36 )\n",
      "Processing  silence  ( 36 / 36 )\n",
      "\n",
      "#####Coumputing AugmentedTrain Set#####\n",
      "Processing  yes  ( 1 / 36 )\n",
      "Processing  no  ( 2 / 36 )\n",
      "Processing  up  ( 3 / 36 )\n",
      "Processing  down  ( 4 / 36 )\n",
      "Processing  left  ( 5 / 36 )\n",
      "Processing  right  ( 6 / 36 )\n",
      "Processing  on  ( 7 / 36 )\n",
      "Processing  off  ( 8 / 36 )\n",
      "Processing  stop  ( 9 / 36 )\n",
      "Processing  go  ( 10 / 36 )\n",
      "Processing  zero  ( 11 / 36 )\n",
      "Processing  one  ( 12 / 36 )\n",
      "Processing  two  ( 13 / 36 )\n",
      "Processing  three  ( 14 / 36 )\n",
      "Processing  four  ( 15 / 36 )\n",
      "Processing  five  ( 16 / 36 )\n",
      "Processing  six  ( 17 / 36 )\n",
      "Processing  seven  ( 18 / 36 )\n",
      "Processing  eight  ( 19 / 36 )\n",
      "Processing  nine  ( 20 / 36 )\n",
      "Processing  silence  ( 21 / 36 )\n",
      "Wall time: 4min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for count, i in enumerate(valuesLF):\n",
    "    for index, dictionary in enumerate(dictionaries):\n",
    "        print('\\n#####Coumputing '+functions.getName(index)+ ' Set#####')\n",
    "        nameLog = 'variables/logfiltDict'+functions.getName(index)+'[nF='+str(i[0])+' wL='+str(i[1])+' wS='+str(i[2])+'].pkl'\n",
    "        nameLogDD = 'variables/logfiltDictDD'+functions.getName(index)+'[nF='+str(i[0])+' wL='+str(i[1])+' wS='+str(i[2])+'].pkl'\n",
    "        logFDict = {}\n",
    "        for countKey, key in enumerate(dictionary):\n",
    "            print('Processing ',key, \" (\", countKey+1, \"/\", len(rawDict),\")\" )\n",
    "            array = []\n",
    "            computeLogF(dictionary[key], array, i, sampleRate = sampleRate)            \n",
    "            logFDict[key] = np.array(array)\n",
    "        \n",
    "        with open(nameLog, 'wb') as f:  \n",
    "            pickle.dump(logFDict, f)\n",
    "        '''   \n",
    "        print(\"\\n  Processing delta and delta-delta\")\n",
    "        \n",
    "        for countKey, key in enumerate(logFDict):\n",
    "            print('Processing ',key, \" (\", countKey+1, \"/\", len(logFDict),\")\" )\n",
    "            delt = np.array(computeDelta(logFDict[key]))\n",
    "            deltdelt = np.array(computeDelta(delt))\n",
    "            logFDict[key] = np.stack([logFDict[key],delt,deltdelt], axis = -1)\n",
    "        \n",
    "        with open(nameLogDD, 'wb') as f:  \n",
    "            pickle.dump(logFDict, f)\n",
    "        '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
